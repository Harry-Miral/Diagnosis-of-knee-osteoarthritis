{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "452b9946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T12:59:35.081622Z",
     "start_time": "2022-07-05T12:59:35.077621Z"
    }
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf216bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:46.997604Z",
     "start_time": "2022-07-07T13:19:42.857680Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from pandas import read_csv, unique\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import mode\n",
    "from scipy import interp\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,roc_curve,auc\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow import stack\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling1D, BatchNormalization, MaxPool1D, Reshape, Activation\n",
    "from keras.layers import Conv1D, LSTM\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56be0860",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f4351ece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:47.013608Z",
     "start_time": "2022-07-07T13:19:46.998607Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(filepath):\n",
    "    df = read_csv(filepath, header=None, names=['user-id',\n",
    "                                               'activity',\n",
    "                                               'timestamp',\n",
    "                                               'sex',\n",
    "                                               'age',\n",
    "                                               'BMI',\n",
    "                                               'A',\n",
    "                                               'B',\n",
    "                                               'C',\n",
    "                                               'X',\n",
    "                                               'Y',\n",
    "                                               'Z'])\n",
    "    ## removing ';' from last column and converting it to float\n",
    "    df['Z'].replace(regex=True, inplace=True, to_replace=r';', value=r'')\n",
    "    df['Z'] = df['Z'].apply(convert_to_float)\n",
    "#     df.dropna(axis=0, how='any', inplace=True)\n",
    "    return df\n",
    "\n",
    "def convert_to_float(x):\n",
    "    try:\n",
    "        return np.float64(x)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fe14cbaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:48.655211Z",
     "start_time": "2022-07-07T13:19:47.014608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.842623</td>\n",
       "      <td>170.059424</td>\n",
       "      <td>171.885206</td>\n",
       "      <td>164.917391</td>\n",
       "      <td>165.412991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.642798</td>\n",
       "      <td>170.228278</td>\n",
       "      <td>172.175605</td>\n",
       "      <td>164.844014</td>\n",
       "      <td>165.337399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.442973</td>\n",
       "      <td>170.397132</td>\n",
       "      <td>172.466004</td>\n",
       "      <td>164.770636</td>\n",
       "      <td>165.261807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.392961</td>\n",
       "      <td>170.137725</td>\n",
       "      <td>171.981197</td>\n",
       "      <td>164.342390</td>\n",
       "      <td>165.068027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.342949</td>\n",
       "      <td>169.878317</td>\n",
       "      <td>171.496389</td>\n",
       "      <td>163.914143</td>\n",
       "      <td>164.874246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285595</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>795</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>395.0</td>\n",
       "      <td>53.054386</td>\n",
       "      <td>101.282433</td>\n",
       "      <td>98.437307</td>\n",
       "      <td>91.694820</td>\n",
       "      <td>95.570696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285596</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>796</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>396.0</td>\n",
       "      <td>51.566923</td>\n",
       "      <td>104.802220</td>\n",
       "      <td>100.029568</td>\n",
       "      <td>98.373605</td>\n",
       "      <td>98.261446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285597</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>797</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>397.0</td>\n",
       "      <td>50.444408</td>\n",
       "      <td>106.489055</td>\n",
       "      <td>101.999649</td>\n",
       "      <td>101.329230</td>\n",
       "      <td>100.532071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285598</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>798</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>398.0</td>\n",
       "      <td>50.424259</td>\n",
       "      <td>106.749087</td>\n",
       "      <td>102.629601</td>\n",
       "      <td>101.878083</td>\n",
       "      <td>101.378611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285599</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>799</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>399.0</td>\n",
       "      <td>50.404110</td>\n",
       "      <td>107.009119</td>\n",
       "      <td>103.259553</td>\n",
       "      <td>102.426936</td>\n",
       "      <td>102.225152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285600 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp  sex  age        BMI      A          B  \\\n",
       "0             1      Yes          0    1   57  24.212293    0.0  23.842623   \n",
       "1             1      Yes          1    1   57  24.212293    1.0  23.642798   \n",
       "2             1      Yes          2    1   57  24.212293    2.0  23.442973   \n",
       "3             1      Yes          3    1   57  24.212293    3.0  23.392961   \n",
       "4             1      Yes          4    1   57  24.212293    4.0  23.342949   \n",
       "...         ...      ...        ...  ...  ...        ...    ...        ...   \n",
       "285595      357      Yes        795    1   54  25.402816  395.0  53.054386   \n",
       "285596      357      Yes        796    1   54  25.402816  396.0  51.566923   \n",
       "285597      357      Yes        797    1   54  25.402816  397.0  50.444408   \n",
       "285598      357      Yes        798    1   54  25.402816  398.0  50.424259   \n",
       "285599      357      Yes        799    1   54  25.402816  399.0  50.404110   \n",
       "\n",
       "                 C           X           Y           Z  \n",
       "0       170.059424  171.885206  164.917391  165.412991  \n",
       "1       170.228278  172.175605  164.844014  165.337399  \n",
       "2       170.397132  172.466004  164.770636  165.261807  \n",
       "3       170.137725  171.981197  164.342390  165.068027  \n",
       "4       169.878317  171.496389  163.914143  164.874246  \n",
       "...            ...         ...         ...         ...  \n",
       "285595  101.282433   98.437307   91.694820   95.570696  \n",
       "285596  104.802220  100.029568   98.373605   98.261446  \n",
       "285597  106.489055  101.999649  101.329230  100.532071  \n",
       "285598  106.749087  102.629601  101.878083  101.378611  \n",
       "285599  107.009119  103.259553  102.426936  102.225152  \n",
       "\n",
       "[285600 rows x 12 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_data('Dataset/Angel_and_Baseline/Angel_data_order.txt')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cfc0f2",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "78699eb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.436290Z",
     "start_time": "2022-07-07T13:19:50.281071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>activityEncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.842623</td>\n",
       "      <td>170.059424</td>\n",
       "      <td>171.885206</td>\n",
       "      <td>164.917391</td>\n",
       "      <td>165.412991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.642798</td>\n",
       "      <td>170.228278</td>\n",
       "      <td>172.175605</td>\n",
       "      <td>164.844014</td>\n",
       "      <td>165.337399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.442973</td>\n",
       "      <td>170.397132</td>\n",
       "      <td>172.466004</td>\n",
       "      <td>164.770636</td>\n",
       "      <td>165.261807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.392961</td>\n",
       "      <td>170.137725</td>\n",
       "      <td>171.981197</td>\n",
       "      <td>164.342390</td>\n",
       "      <td>165.068027</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.342949</td>\n",
       "      <td>169.878317</td>\n",
       "      <td>171.496389</td>\n",
       "      <td>163.914143</td>\n",
       "      <td>164.874246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285595</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>795</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>395.0</td>\n",
       "      <td>53.054386</td>\n",
       "      <td>101.282433</td>\n",
       "      <td>98.437307</td>\n",
       "      <td>91.694820</td>\n",
       "      <td>95.570696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285596</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>796</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>396.0</td>\n",
       "      <td>51.566923</td>\n",
       "      <td>104.802220</td>\n",
       "      <td>100.029568</td>\n",
       "      <td>98.373605</td>\n",
       "      <td>98.261446</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285597</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>797</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>397.0</td>\n",
       "      <td>50.444408</td>\n",
       "      <td>106.489055</td>\n",
       "      <td>101.999649</td>\n",
       "      <td>101.329230</td>\n",
       "      <td>100.532071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285598</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>798</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>398.0</td>\n",
       "      <td>50.424259</td>\n",
       "      <td>106.749087</td>\n",
       "      <td>102.629601</td>\n",
       "      <td>101.878083</td>\n",
       "      <td>101.378611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285599</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>799</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>399.0</td>\n",
       "      <td>50.404110</td>\n",
       "      <td>107.009119</td>\n",
       "      <td>103.259553</td>\n",
       "      <td>102.426936</td>\n",
       "      <td>102.225152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285600 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp  sex  age        BMI      A          B  \\\n",
       "0             1      Yes          0    1   57  24.212293    0.0  23.842623   \n",
       "1             1      Yes          1    1   57  24.212293    1.0  23.642798   \n",
       "2             1      Yes          2    1   57  24.212293    2.0  23.442973   \n",
       "3             1      Yes          3    1   57  24.212293    3.0  23.392961   \n",
       "4             1      Yes          4    1   57  24.212293    4.0  23.342949   \n",
       "...         ...      ...        ...  ...  ...        ...    ...        ...   \n",
       "285595      357      Yes        795    1   54  25.402816  395.0  53.054386   \n",
       "285596      357      Yes        796    1   54  25.402816  396.0  51.566923   \n",
       "285597      357      Yes        797    1   54  25.402816  397.0  50.444408   \n",
       "285598      357      Yes        798    1   54  25.402816  398.0  50.424259   \n",
       "285599      357      Yes        799    1   54  25.402816  399.0  50.404110   \n",
       "\n",
       "                 C           X           Y           Z  activityEncode  \n",
       "0       170.059424  171.885206  164.917391  165.412991               1  \n",
       "1       170.228278  172.175605  164.844014  165.337399               1  \n",
       "2       170.397132  172.466004  164.770636  165.261807               1  \n",
       "3       170.137725  171.981197  164.342390  165.068027               1  \n",
       "4       169.878317  171.496389  163.914143  164.874246               1  \n",
       "...            ...         ...         ...         ...             ...  \n",
       "285595  101.282433   98.437307   91.694820   95.570696               1  \n",
       "285596  104.802220  100.029568   98.373605   98.261446               1  \n",
       "285597  106.489055  101.999649  101.329230  100.532071               1  \n",
       "285598  106.749087  102.629601  101.878083  101.378611               1  \n",
       "285599  107.009119  103.259553  102.426936  102.225152               1  \n",
       "\n",
       "[285600 rows x 13 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encode = LabelEncoder()\n",
    "df['activityEncode'] = label_encode.fit_transform(df['activity'].values.ravel())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3be5152",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T16:53:26.834976Z",
     "start_time": "2022-07-04T16:53:26.823973Z"
    }
   },
   "source": [
    "## Linear Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "7951cd31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.484301Z",
     "start_time": "2022-07-07T13:19:50.437290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user-id           0\n",
       "activity          0\n",
       "timestamp         0\n",
       "sex               0\n",
       "age               0\n",
       "BMI               0\n",
       "A                 0\n",
       "B                 0\n",
       "C                 0\n",
       "X                 0\n",
       "Y                 0\n",
       "Z                 0\n",
       "activityEncode    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "b6d9e58d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.532284Z",
     "start_time": "2022-07-07T13:19:50.485302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scipy.interpolate._interpolate.interp1d at 0x2007a64ef20>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation_fn = interp1d(df['activityEncode'] ,df['Z'], kind='linear')\n",
    "interpolation_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "4f8ea8cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.548288Z",
     "start_time": "2022-07-07T13:19:50.534285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_list = df[df['Z'].isnull()].index.tolist()\n",
    "null_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f002bca0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.580295Z",
     "start_time": "2022-07-07T13:19:50.549289Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in null_list:\n",
    "    y = df['activityEncode'][i]\n",
    "    value = interpolation_fn(y)\n",
    "    df['Z']=df['Z'].fillna(value)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "b4349e1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.627795Z",
     "start_time": "2022-07-07T13:19:50.581295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user-id           0\n",
       "activity          0\n",
       "timestamp         0\n",
       "sex               0\n",
       "age               0\n",
       "BMI               0\n",
       "A                 0\n",
       "B                 0\n",
       "C                 0\n",
       "X                 0\n",
       "Y                 0\n",
       "Z                 0\n",
       "activityEncode    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69abe57c",
   "metadata": {},
   "source": [
    "## Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a24a047f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>activityEncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209557</td>\n",
       "      <td>0.924607</td>\n",
       "      <td>0.933212</td>\n",
       "      <td>0.888332</td>\n",
       "      <td>0.886692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.206448</td>\n",
       "      <td>0.925895</td>\n",
       "      <td>0.935667</td>\n",
       "      <td>0.887787</td>\n",
       "      <td>0.886036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.203339</td>\n",
       "      <td>0.927182</td>\n",
       "      <td>0.938121</td>\n",
       "      <td>0.887241</td>\n",
       "      <td>0.885379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.202561</td>\n",
       "      <td>0.925204</td>\n",
       "      <td>0.934024</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.883695</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>0.201782</td>\n",
       "      <td>0.923227</td>\n",
       "      <td>0.929926</td>\n",
       "      <td>0.880875</td>\n",
       "      <td>0.882012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285595</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.989975</td>\n",
       "      <td>0.664060</td>\n",
       "      <td>0.400242</td>\n",
       "      <td>0.312480</td>\n",
       "      <td>0.344084</td>\n",
       "      <td>0.279896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285596</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.992481</td>\n",
       "      <td>0.640917</td>\n",
       "      <td>0.427078</td>\n",
       "      <td>0.325937</td>\n",
       "      <td>0.393726</td>\n",
       "      <td>0.303273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285597</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.994987</td>\n",
       "      <td>0.623451</td>\n",
       "      <td>0.439938</td>\n",
       "      <td>0.342587</td>\n",
       "      <td>0.415694</td>\n",
       "      <td>0.323001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285598</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.997494</td>\n",
       "      <td>0.623138</td>\n",
       "      <td>0.441921</td>\n",
       "      <td>0.347911</td>\n",
       "      <td>0.419774</td>\n",
       "      <td>0.330355</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285599</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622824</td>\n",
       "      <td>0.443904</td>\n",
       "      <td>0.353234</td>\n",
       "      <td>0.423853</td>\n",
       "      <td>0.337710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285600 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp  sex       age       BMI         A  \\\n",
       "0             1      Yes          0  0.0  0.225806  0.398781  0.000000   \n",
       "1             1      Yes          1  0.0  0.225806  0.398781  0.002506   \n",
       "2             1      Yes          2  0.0  0.225806  0.398781  0.005013   \n",
       "3             1      Yes          3  0.0  0.225806  0.398781  0.007519   \n",
       "4             1      Yes          4  0.0  0.225806  0.398781  0.010025   \n",
       "...         ...      ...        ...  ...       ...       ...       ...   \n",
       "285595      357      Yes        795  0.0  0.129032  0.460572  0.989975   \n",
       "285596      357      Yes        796  0.0  0.129032  0.460572  0.992481   \n",
       "285597      357      Yes        797  0.0  0.129032  0.460572  0.994987   \n",
       "285598      357      Yes        798  0.0  0.129032  0.460572  0.997494   \n",
       "285599      357      Yes        799  0.0  0.129032  0.460572  1.000000   \n",
       "\n",
       "               B         C         X         Y         Z  activityEncode  \n",
       "0       0.209557  0.924607  0.933212  0.888332  0.886692               1  \n",
       "1       0.206448  0.925895  0.935667  0.887787  0.886036               1  \n",
       "2       0.203339  0.927182  0.938121  0.887241  0.885379               1  \n",
       "3       0.202561  0.925204  0.934024  0.884058  0.883695               1  \n",
       "4       0.201782  0.923227  0.929926  0.880875  0.882012               1  \n",
       "...          ...       ...       ...       ...       ...             ...  \n",
       "285595  0.664060  0.400242  0.312480  0.344084  0.279896               1  \n",
       "285596  0.640917  0.427078  0.325937  0.393726  0.303273               1  \n",
       "285597  0.623451  0.439938  0.342587  0.415694  0.323001               1  \n",
       "285598  0.623138  0.441921  0.347911  0.419774  0.330355               1  \n",
       "285599  0.622824  0.443904  0.353234  0.423853  0.337710               1  \n",
       "\n",
       "[285600 rows x 13 columns]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'] = (df['age']-df['age'].min())/(df['age'].max()-df['age'].min())\n",
    "df['BMI'] = (df['BMI']-df['BMI'].min())/(df['BMI'].max()-df['BMI'].min())\n",
    "df['A'] = (df['A']-df['A'].min())/(df['A'].max()-df['A'].min())\n",
    "df['B'] = (df['B']-df['B'].min())/(df['B'].max()-df['B'].min())\n",
    "df['C'] = (df['C']-df['C'].min())/(df['C'].max()-df['C'].min())\n",
    "df['X'] = (df['X']-df['X'].min())/(df['X'].max()-df['X'].min())\n",
    "df['Y'] = (df['Y']-df['Y'].min())/(df['Y'].max()-df['Y'].min())\n",
    "df['Z'] = (df['Z']-df['Z'].min())/(df['Z'].max()-df['Z'].min())\n",
    "df['sex'] = (df['sex']-df['sex'].min())/(df['sex'].max()-df['sex'].min())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a31ec3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segments(df, time_steps, step, label_name):\n",
    "    N_FEATURES = 9\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "        xs = df['X'].values[i:i+time_steps]\n",
    "        ys = df['Y'].values[i:i+time_steps]\n",
    "        zs = df['Z'].values[i:i+time_steps]\n",
    "        aas = df['A'].values[i:i+time_steps]\n",
    "        bs = df['B'].values[i:i+time_steps]\n",
    "        cs = df['C'].values[i:i+time_steps]\n",
    "        sexs = df['sex'].values[i:i+time_steps]\n",
    "        ages = df['age'].values[i:i+time_steps]\n",
    "        bmis = df['BMI'].values[i:i+time_steps]\n",
    "        label = mode(df[label_name][i:i+time_steps])[0][0]\n",
    "        segments.append([sexs,ages,bmis,aas,bs,cs,xs, ys, zs])\n",
    "        labels.append(label)\n",
    "    reshaped_segments = np.asarray(segments, dtype=np.float32).reshape(-1, time_steps, N_FEATURES)\n",
    "    labels = np.asarray(labels)\n",
    "    return reshaped_segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "987cccea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>activityEncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209557</td>\n",
       "      <td>0.924607</td>\n",
       "      <td>0.933212</td>\n",
       "      <td>0.888332</td>\n",
       "      <td>0.886692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.206448</td>\n",
       "      <td>0.925895</td>\n",
       "      <td>0.935667</td>\n",
       "      <td>0.887787</td>\n",
       "      <td>0.886036</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.203339</td>\n",
       "      <td>0.927182</td>\n",
       "      <td>0.938121</td>\n",
       "      <td>0.887241</td>\n",
       "      <td>0.885379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.202561</td>\n",
       "      <td>0.925204</td>\n",
       "      <td>0.934024</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.883695</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>0.201782</td>\n",
       "      <td>0.923227</td>\n",
       "      <td>0.929926</td>\n",
       "      <td>0.880875</td>\n",
       "      <td>0.882012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285595</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.989975</td>\n",
       "      <td>0.664060</td>\n",
       "      <td>0.400242</td>\n",
       "      <td>0.312480</td>\n",
       "      <td>0.344084</td>\n",
       "      <td>0.279896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285596</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.992481</td>\n",
       "      <td>0.640917</td>\n",
       "      <td>0.427078</td>\n",
       "      <td>0.325937</td>\n",
       "      <td>0.393726</td>\n",
       "      <td>0.303273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285597</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.994987</td>\n",
       "      <td>0.623451</td>\n",
       "      <td>0.439938</td>\n",
       "      <td>0.342587</td>\n",
       "      <td>0.415694</td>\n",
       "      <td>0.323001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285598</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.997494</td>\n",
       "      <td>0.623138</td>\n",
       "      <td>0.441921</td>\n",
       "      <td>0.347911</td>\n",
       "      <td>0.419774</td>\n",
       "      <td>0.330355</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285599</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>799</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622824</td>\n",
       "      <td>0.443904</td>\n",
       "      <td>0.353234</td>\n",
       "      <td>0.423853</td>\n",
       "      <td>0.337710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285600 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp  sex       age       BMI         A  \\\n",
       "0             1      Yes          0  0.0  0.225806  0.398781  0.000000   \n",
       "1             1      Yes          1  0.0  0.225806  0.398781  0.002506   \n",
       "2             1      Yes          2  0.0  0.225806  0.398781  0.005013   \n",
       "3             1      Yes          3  0.0  0.225806  0.398781  0.007519   \n",
       "4             1      Yes          4  0.0  0.225806  0.398781  0.010025   \n",
       "...         ...      ...        ...  ...       ...       ...       ...   \n",
       "285595      357      Yes        795  0.0  0.129032  0.460572  0.989975   \n",
       "285596      357      Yes        796  0.0  0.129032  0.460572  0.992481   \n",
       "285597      357      Yes        797  0.0  0.129032  0.460572  0.994987   \n",
       "285598      357      Yes        798  0.0  0.129032  0.460572  0.997494   \n",
       "285599      357      Yes        799  0.0  0.129032  0.460572  1.000000   \n",
       "\n",
       "               B         C         X         Y         Z  activityEncode  \n",
       "0       0.209557  0.924607  0.933212  0.888332  0.886692               1  \n",
       "1       0.206448  0.925895  0.935667  0.887787  0.886036               1  \n",
       "2       0.203339  0.927182  0.938121  0.887241  0.885379               1  \n",
       "3       0.202561  0.925204  0.934024  0.884058  0.883695               1  \n",
       "4       0.201782  0.923227  0.929926  0.880875  0.882012               1  \n",
       "...          ...       ...       ...       ...       ...             ...  \n",
       "285595  0.664060  0.400242  0.312480  0.344084  0.279896               1  \n",
       "285596  0.640917  0.427078  0.325937  0.393726  0.303273               1  \n",
       "285597  0.623451  0.439938  0.342587  0.415694  0.323001               1  \n",
       "285598  0.623138  0.441921  0.347911  0.419774  0.330355               1  \n",
       "285599  0.622824  0.443904  0.353234  0.423853  0.337710               1  \n",
       "\n",
       "[285600 rows x 13 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7b783875",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_PERIOD = 80\n",
    "STEP_DISTANCE = 40\n",
    "LABEL = 'activityEncode'\n",
    "\n",
    "df1=df[df['user-id']>70]\n",
    "df2=df[df['user-id']>140]\n",
    "df3=df[df['user-id']>210]\n",
    "df4=df[df['user-id']>280]\n",
    "\n",
    "a1=df.shape[0]\n",
    "b2=df1.shape[0]\n",
    "c3=df2.shape[0]\n",
    "d4=df3.shape[0]\n",
    "e5=df4.shape[0]\n",
    "\n",
    "df_test0 = df.iloc[0:a1-b2,:]\n",
    "df_train0 = df.iloc[a1-b2:a1,:]\n",
    "x_train0, y_train0 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test0, y_test0 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train0.shape[1], x_train0.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train0 = x_train0.reshape(x_train0.shape[0], input_shape)\n",
    "x_train0 = x_train0.astype('float32')\n",
    "y_train0=np.asarray(y_train0).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test0.shape[1], x_test0.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test0 = x_test0.reshape(x_test0.shape[0], input_shape)\n",
    "x_test0 = x_test0.astype('float32')\n",
    "y_test0=np.asarray(y_test0).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test1 = df.iloc[a1-b2:a1-c3,:]\n",
    "df_train1 = pd.concat([df_test0,df.iloc[a1-c3:a1,]])\n",
    "x_train1, y_train1 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test1, y_test1 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train1.shape[1], x_train1.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train1 = x_train1.reshape(x_train1.shape[0], input_shape)\n",
    "x_train1 = x_train1.astype('float32')\n",
    "y_train1=np.asarray(y_train1).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test1.shape[1], x_test1.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test1 = x_test1.reshape(x_test1.shape[0], input_shape)\n",
    "x_test1 = x_test1.astype('float32')\n",
    "y_test1=np.asarray(y_test1).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test2 = df.iloc[a1-c3:a1-d4,:]\n",
    "df_train2 = pd.concat([df.iloc[0:a1-c3,:],df.iloc[a1-d4:a1,]])\n",
    "x_train2, y_train2 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test2, y_test2 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train2.shape[1], x_train2.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train2 = x_train2.reshape(x_train2.shape[0], input_shape)\n",
    "x_train2 = x_train2.astype('float32')\n",
    "y_train2=np.asarray(y_train2).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test2.shape[1], x_test2.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test2 = x_test2.reshape(x_test2.shape[0], input_shape)\n",
    "x_test2 = x_test2.astype('float32')\n",
    "y_test2=np.asarray(y_test2).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test3 = df.iloc[a1-d4:a1-e5,:]\n",
    "df_train3 = pd.concat([df.iloc[0:a1-d4,:],df.iloc[a1-e5:a1,]])\n",
    "x_train3, y_train3 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test3, y_test3 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train3.shape[1], x_train3.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train3 = x_train3.reshape(x_train3.shape[0], input_shape)\n",
    "x_train3 = x_train3.astype('float32')\n",
    "y_train3=np.asarray(y_train3).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test3.shape[1], x_test3.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test3 = x_test3.reshape(x_test3.shape[0], input_shape)\n",
    "x_test3 = x_test3.astype('float32')\n",
    "y_test3=np.asarray(y_test3).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test4 = df.iloc[a1-e5:a1,:]\n",
    "df_train4 = df.iloc[0:a1-e5,:]\n",
    "x_train4, y_train4 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test4, y_test4 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train4.shape[1], x_train4.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train4 = x_train4.reshape(x_train4.shape[0], input_shape)\n",
    "x_train4 = x_train4.astype('float32')\n",
    "y_train4=np.asarray(y_train4).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test4.shape[1], x_test4.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test4 = x_test4.reshape(x_test4.shape[0], input_shape)\n",
    "x_test4 = x_test4.astype('float32')\n",
    "y_test4=np.asarray(y_test4).astype('float32').reshape((-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "40c9e344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_84 (LSTM)              (None, 720, 32)           4352      \n",
      "                                                                 \n",
      " lstm_85 (LSTM)              (None, 720, 32)           8320      \n",
      "                                                                 \n",
      " reshape_126 (Reshape)       (None, 1, 720, 32)        0         \n",
      "                                                                 \n",
      " conv1d_84 (Conv1D)          (None, 1, 360, 64)        4160      \n",
      "                                                                 \n",
      " reshape_127 (Reshape)       (None, 360, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d_42 (MaxPoolin  (None, 90, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_85 (Conv1D)          (None, 89, 192)           24768     \n",
      "                                                                 \n",
      " reshape_128 (Reshape)       (None, 89, 192)           0         \n",
      "                                                                 \n",
      " global_average_pooling1d_42  (None, 192)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " batch_normalization_42 (Bat  (None, 192)              768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 1)                 193       \n",
      "                                                                 \n",
      " activation_42 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,561\n",
      "Trainable params: 42,177\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model.add(Reshape((1, 720, 32)))\n",
    "model.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model.add(Reshape((360, 64)))\n",
    "model.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model.add(Reshape((89, 192)))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(BatchNormalization(epsilon=1e-06))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f1538a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_metric(optimizer):  # printing the value of the learning rate\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "def step_decay(epoch):\n",
    "\tinitial_lrate = 0.001\n",
    "\tdrop = 0.5\n",
    "\tepochs_drop = 5.0\n",
    "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lrate\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "sgd = SGD(lr=0.0, momentum=0.9, decay=0.0, nesterov=False)\n",
    "adam=optimizers.Adam(lr=0.00004, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=False)\n",
    "#lr_metric = get_lr_metric(adam)\n",
    "lr_metric = get_lr_metric(adam)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "model1 = Sequential()\n",
    "model1.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model1.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model1.add(Reshape((1, 720, 32)))\n",
    "model1.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model1.add(Reshape((360, 64)))\n",
    "model1.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model1.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model1.add(Reshape((89, 192)))\n",
    "model1.add(GlobalAveragePooling1D())\n",
    "model1.add(BatchNormalization(epsilon=1e-06))\n",
    "model1.add(Dense(1))\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model2.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model2.add(Reshape((1, 720, 32)))\n",
    "model2.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model2.add(Reshape((360, 64)))\n",
    "model2.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model2.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model2.add(Reshape((89, 192)))\n",
    "model2.add(GlobalAveragePooling1D())\n",
    "model2.add(BatchNormalization(epsilon=1e-06))\n",
    "model2.add(Dense(1))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model3.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model3.add(Reshape((1, 720, 32)))\n",
    "model3.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model3.add(Reshape((360, 64)))\n",
    "model3.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model3.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model3.add(Reshape((89, 192)))\n",
    "model3.add(GlobalAveragePooling1D())\n",
    "model3.add(BatchNormalization(epsilon=1e-06))\n",
    "model3.add(Dense(1))\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model4.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model4.add(Reshape((1, 720, 32)))\n",
    "model4.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model4.add(Reshape((360, 64)))\n",
    "model4.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model4.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model4.add(Reshape((89, 192)))\n",
    "model4.add(GlobalAveragePooling1D())\n",
    "model4.add(BatchNormalization(epsilon=1e-06))\n",
    "model4.add(Dense(1))\n",
    "model4.add(Activation('sigmoid'))\n",
    "model4.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model5.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model5.add(Reshape((1, 720, 32)))\n",
    "model5.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model5.add(Reshape((360, 64)))\n",
    "model5.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model5.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model5.add(Reshape((89, 192)))\n",
    "model5.add(GlobalAveragePooling1D())\n",
    "model5.add(BatchNormalization(epsilon=1e-06))\n",
    "model5.add(Dense(1))\n",
    "model5.add(Activation('sigmoid'))\n",
    "model5.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "2047136b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "58/58 [==============================] - 22s 354ms/step - loss: 0.6942 - accuracy: 0.5582 - lr: 4.0000e-05\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 21s 361ms/step - loss: 0.5999 - accuracy: 0.6765 - lr: 4.0000e-05\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 21s 359ms/step - loss: 0.5850 - accuracy: 0.6875 - lr: 4.0000e-05\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 21s 357ms/step - loss: 0.5736 - accuracy: 0.7037 - lr: 4.0000e-05\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 22s 378ms/step - loss: 0.5628 - accuracy: 0.7074 - lr: 4.0000e-05\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 22s 375ms/step - loss: 0.5539 - accuracy: 0.7138 - lr: 4.0000e-05\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 22s 372ms/step - loss: 0.5467 - accuracy: 0.7203 - lr: 4.0000e-05\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 22s 377ms/step - loss: 0.5360 - accuracy: 0.7311 - lr: 4.0000e-05\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 22s 375ms/step - loss: 0.5272 - accuracy: 0.7374 - lr: 4.0000e-05\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 22s 378ms/step - loss: 0.5190 - accuracy: 0.7398 - lr: 4.0000e-05\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 22s 382ms/step - loss: 0.5136 - accuracy: 0.7407 - lr: 4.0000e-05\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 22s 375ms/step - loss: 0.5063 - accuracy: 0.7480 - lr: 4.0000e-05\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 22s 377ms/step - loss: 0.5013 - accuracy: 0.7551 - lr: 4.0000e-05\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 22s 378ms/step - loss: 0.4954 - accuracy: 0.7506 - lr: 4.0000e-05\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 22s 378ms/step - loss: 0.4893 - accuracy: 0.7607 - lr: 4.0000e-05\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 22s 376ms/step - loss: 0.4850 - accuracy: 0.7654 - lr: 4.0000e-05\n",
      "Epoch 17/100\n",
      "58/58 [==============================] - 22s 379ms/step - loss: 0.4804 - accuracy: 0.7658 - lr: 4.0000e-05\n",
      "Epoch 18/100\n",
      "58/58 [==============================] - 22s 377ms/step - loss: 0.4763 - accuracy: 0.7684 - lr: 4.0000e-05\n",
      "Epoch 19/100\n",
      "58/58 [==============================] - 22s 378ms/step - loss: 0.4717 - accuracy: 0.7672 - lr: 4.0000e-05\n",
      "Epoch 20/100\n",
      "58/58 [==============================] - 22s 378ms/step - loss: 0.4683 - accuracy: 0.7726 - lr: 4.0000e-05\n",
      "Epoch 21/100\n",
      "58/58 [==============================] - 22s 380ms/step - loss: 0.4658 - accuracy: 0.7745 - lr: 4.0000e-05\n",
      "Epoch 22/100\n",
      "58/58 [==============================] - 22s 378ms/step - loss: 0.4617 - accuracy: 0.7734 - lr: 4.0000e-05\n",
      "Epoch 23/100\n",
      "58/58 [==============================] - 22s 378ms/step - loss: 0.4563 - accuracy: 0.7830 - lr: 4.0000e-05\n",
      "Epoch 24/100\n",
      "58/58 [==============================] - 22s 381ms/step - loss: 0.4531 - accuracy: 0.7841 - lr: 4.0000e-05\n",
      "Epoch 25/100\n",
      "58/58 [==============================] - 22s 376ms/step - loss: 0.4506 - accuracy: 0.7862 - lr: 4.0000e-05\n",
      "Epoch 26/100\n",
      "58/58 [==============================] - 22s 376ms/step - loss: 0.4480 - accuracy: 0.7863 - lr: 4.0000e-05\n",
      "Epoch 27/100\n",
      "58/58 [==============================] - 22s 383ms/step - loss: 0.4434 - accuracy: 0.7853 - lr: 4.0000e-05\n",
      "Epoch 28/100\n",
      "58/58 [==============================] - 22s 376ms/step - loss: 0.4408 - accuracy: 0.7914 - lr: 4.0000e-05\n",
      "Epoch 29/100\n",
      "58/58 [==============================] - 22s 377ms/step - loss: 0.4388 - accuracy: 0.7886 - lr: 4.0000e-05\n",
      "Epoch 30/100\n",
      "58/58 [==============================] - 22s 379ms/step - loss: 0.4365 - accuracy: 0.7930 - lr: 4.0000e-05\n",
      "Epoch 31/100\n",
      "58/58 [==============================] - 22s 378ms/step - loss: 0.4322 - accuracy: 0.7902 - lr: 4.0000e-05\n",
      "Epoch 32/100\n",
      "58/58 [==============================] - 22s 379ms/step - loss: 0.4319 - accuracy: 0.7919 - lr: 4.0000e-05\n",
      "Epoch 33/100\n",
      "58/58 [==============================] - 22s 376ms/step - loss: 0.4263 - accuracy: 0.7923 - lr: 4.0000e-05\n",
      "Epoch 34/100\n",
      "58/58 [==============================] - 22s 377ms/step - loss: 0.4214 - accuracy: 0.7970 - lr: 4.0000e-05\n",
      "Epoch 35/100\n",
      "58/58 [==============================] - 22s 380ms/step - loss: 0.4216 - accuracy: 0.7985 - lr: 4.0000e-05\n",
      "Epoch 36/100\n",
      "58/58 [==============================] - 22s 379ms/step - loss: 0.4199 - accuracy: 0.7959 - lr: 4.0000e-05\n",
      "Epoch 37/100\n",
      "58/58 [==============================] - 22s 379ms/step - loss: 0.4186 - accuracy: 0.7991 - lr: 4.0000e-05\n",
      "Epoch 38/100\n",
      "58/58 [==============================] - 22s 384ms/step - loss: 0.4128 - accuracy: 0.8032 - lr: 4.0000e-05\n",
      "Epoch 39/100\n",
      "58/58 [==============================] - 22s 378ms/step - loss: 0.4081 - accuracy: 0.8048 - lr: 4.0000e-05\n",
      "Epoch 40/100\n",
      "58/58 [==============================] - 22s 381ms/step - loss: 0.4099 - accuracy: 0.8052 - lr: 4.0000e-05\n",
      "Epoch 41/100\n",
      "58/58 [==============================] - 22s 376ms/step - loss: 0.4057 - accuracy: 0.8074 - lr: 4.0000e-05\n",
      "Epoch 42/100\n",
      "58/58 [==============================] - 22s 377ms/step - loss: 0.4064 - accuracy: 0.8025 - lr: 4.0000e-05\n",
      "Epoch 43/100\n",
      "58/58 [==============================] - 22s 379ms/step - loss: 0.3992 - accuracy: 0.8109 - lr: 4.0000e-05\n",
      "Epoch 44/100\n",
      "58/58 [==============================] - 22s 379ms/step - loss: 0.3954 - accuracy: 0.8153 - lr: 4.0000e-05\n",
      "Epoch 45/100\n",
      "58/58 [==============================] - 22s 376ms/step - loss: 0.3926 - accuracy: 0.8107 - lr: 4.0000e-05\n",
      "Epoch 46/100\n",
      "58/58 [==============================] - 22s 380ms/step - loss: 0.3916 - accuracy: 0.8165 - lr: 4.0000e-05\n",
      "Epoch 47/100\n",
      "58/58 [==============================] - 22s 380ms/step - loss: 0.3852 - accuracy: 0.8167 - lr: 4.0000e-05\n",
      "Epoch 48/100\n",
      "58/58 [==============================] - 22s 376ms/step - loss: 0.3843 - accuracy: 0.8243 - lr: 4.0000e-05\n",
      "Epoch 49/100\n",
      "58/58 [==============================] - 22s 379ms/step - loss: 0.3817 - accuracy: 0.8254 - lr: 4.0000e-05\n",
      "Epoch 50/100\n",
      "58/58 [==============================] - 22s 381ms/step - loss: 0.3816 - accuracy: 0.8212 - lr: 4.0000e-05\n",
      "Epoch 51/100\n",
      "58/58 [==============================] - 22s 379ms/step - loss: 0.3773 - accuracy: 0.8269 - lr: 4.0000e-05\n",
      "Epoch 52/100\n",
      "58/58 [==============================] - 22s 378ms/step - loss: 0.3746 - accuracy: 0.8250 - lr: 4.0000e-05\n",
      "Epoch 53/100\n",
      "58/58 [==============================] - 22s 376ms/step - loss: 0.3705 - accuracy: 0.8294 - lr: 4.0000e-05\n",
      "Epoch 54/100\n",
      "58/58 [==============================] - 22s 379ms/step - loss: 0.3690 - accuracy: 0.8296 - lr: 4.0000e-05\n",
      "Epoch 55/100\n",
      "58/58 [==============================] - 22s 375ms/step - loss: 0.3685 - accuracy: 0.8294 - lr: 4.0000e-05\n",
      "Epoch 56/100\n",
      "58/58 [==============================] - 22s 377ms/step - loss: 0.3657 - accuracy: 0.8339 - lr: 4.0000e-05\n",
      "Epoch 57/100\n",
      "58/58 [==============================] - 22s 381ms/step - loss: 0.3624 - accuracy: 0.8360 - lr: 4.0000e-05\n",
      "Epoch 58/100\n",
      "58/58 [==============================] - 22s 378ms/step - loss: 0.3601 - accuracy: 0.8351 - lr: 4.0000e-05\n",
      "Epoch 59/100\n",
      "58/58 [==============================] - 22s 381ms/step - loss: 0.3614 - accuracy: 0.8323 - lr: 4.0000e-05\n",
      "Epoch 60/100\n",
      "58/58 [==============================] - 22s 381ms/step - loss: 0.3571 - accuracy: 0.8384 - lr: 4.0000e-05\n",
      "Epoch 61/100\n",
      "58/58 [==============================] - 22s 378ms/step - loss: 0.3560 - accuracy: 0.8348 - lr: 4.0000e-05\n",
      "Epoch 62/100\n",
      "58/58 [==============================] - 22s 381ms/step - loss: 0.3531 - accuracy: 0.8416 - lr: 4.0000e-05\n",
      "Epoch 63/100\n",
      "58/58 [==============================] - 22s 380ms/step - loss: 0.3598 - accuracy: 0.8374 - lr: 4.0000e-05\n",
      "Epoch 64/100\n",
      "58/58 [==============================] - 22s 383ms/step - loss: 0.3540 - accuracy: 0.8343 - lr: 4.0000e-05\n",
      "Epoch 65/100\n",
      "58/58 [==============================] - 22s 382ms/step - loss: 0.3499 - accuracy: 0.8371 - lr: 4.0000e-05\n",
      "Epoch 66/100\n",
      "58/58 [==============================] - 22s 379ms/step - loss: 0.3491 - accuracy: 0.8404 - lr: 4.0000e-05\n",
      "Epoch 67/100\n",
      "58/58 [==============================] - 22s 381ms/step - loss: 0.3506 - accuracy: 0.8374 - lr: 4.0000e-05\n",
      "Epoch 68/100\n",
      "58/58 [==============================] - 22s 381ms/step - loss: 0.3452 - accuracy: 0.8411 - lr: 4.0000e-05\n",
      "Epoch 69/100\n",
      "58/58 [==============================] - 22s 384ms/step - loss: 0.3461 - accuracy: 0.8395 - lr: 4.0000e-05\n",
      "Epoch 70/100\n",
      "58/58 [==============================] - 22s 383ms/step - loss: 0.3444 - accuracy: 0.8416 - lr: 4.0000e-05\n",
      "Epoch 71/100\n",
      "58/58 [==============================] - 22s 380ms/step - loss: 0.3484 - accuracy: 0.8360 - lr: 4.0000e-05\n",
      "Epoch 72/100\n",
      "58/58 [==============================] - 22s 380ms/step - loss: 0.3436 - accuracy: 0.8484 - lr: 4.0000e-05\n",
      "Epoch 73/100\n",
      "58/58 [==============================] - 22s 379ms/step - loss: 0.3395 - accuracy: 0.8468 - lr: 4.0000e-05\n",
      "Epoch 74/100\n",
      "58/58 [==============================] - 22s 378ms/step - loss: 0.3380 - accuracy: 0.8430 - lr: 4.0000e-05\n",
      "Epoch 75/100\n",
      "58/58 [==============================] - 22s 382ms/step - loss: 0.3389 - accuracy: 0.8449 - lr: 4.0000e-05\n",
      "Epoch 76/100\n",
      "58/58 [==============================] - 22s 377ms/step - loss: 0.3413 - accuracy: 0.8445 - lr: 4.0000e-05\n",
      "Epoch 77/100\n",
      "58/58 [==============================] - 22s 378ms/step - loss: 0.3378 - accuracy: 0.8452 - lr: 4.0000e-05\n",
      "Epoch 78/100\n",
      "58/58 [==============================] - 22s 380ms/step - loss: 0.3347 - accuracy: 0.8463 - lr: 4.0000e-05\n",
      "Epoch 79/100\n",
      "58/58 [==============================] - 22s 375ms/step - loss: 0.3364 - accuracy: 0.8482 - lr: 4.0000e-05\n",
      "Epoch 80/100\n",
      "58/58 [==============================] - 22s 379ms/step - loss: 0.3346 - accuracy: 0.8480 - lr: 4.0000e-05\n",
      "Epoch 81/100\n",
      "58/58 [==============================] - 22s 376ms/step - loss: 0.3308 - accuracy: 0.8503 - lr: 4.0000e-05\n",
      "Epoch 82/100\n",
      "58/58 [==============================] - 22s 380ms/step - loss: 0.3297 - accuracy: 0.8505 - lr: 4.0000e-05\n",
      "Epoch 83/100\n",
      "58/58 [==============================] - 22s 382ms/step - loss: 0.3298 - accuracy: 0.8475 - lr: 4.0000e-05\n",
      "Epoch 84/100\n",
      "58/58 [==============================] - 22s 373ms/step - loss: 0.3285 - accuracy: 0.8489 - lr: 4.0000e-05\n",
      "Epoch 85/100\n",
      "58/58 [==============================] - 22s 381ms/step - loss: 0.3310 - accuracy: 0.8487 - lr: 4.0000e-05\n",
      "Epoch 86/100\n",
      "58/58 [==============================] - 22s 382ms/step - loss: 0.3289 - accuracy: 0.8489 - lr: 4.0000e-05\n",
      "Epoch 87/100\n",
      "58/58 [==============================] - 22s 377ms/step - loss: 0.3258 - accuracy: 0.8470 - lr: 4.0000e-05\n",
      "Epoch 88/100\n",
      "58/58 [==============================] - 22s 380ms/step - loss: 0.3274 - accuracy: 0.8505 - lr: 4.0000e-05\n",
      "Epoch 89/100\n",
      "58/58 [==============================] - 22s 380ms/step - loss: 0.3281 - accuracy: 0.8475 - lr: 4.0000e-05\n",
      "Epoch 90/100\n",
      "58/58 [==============================] - 22s 381ms/step - loss: 0.3278 - accuracy: 0.8447 - lr: 4.0000e-05\n",
      "Epoch 91/100\n",
      "58/58 [==============================] - 22s 383ms/step - loss: 0.3262 - accuracy: 0.8491 - lr: 4.0000e-05\n",
      "Epoch 92/100\n",
      "58/58 [==============================] - 22s 379ms/step - loss: 0.3263 - accuracy: 0.8465 - lr: 4.0000e-05\n",
      "Epoch 93/100\n",
      "58/58 [==============================] - 22s 380ms/step - loss: 0.3248 - accuracy: 0.8486 - lr: 4.0000e-05\n",
      "Epoch 94/100\n",
      "58/58 [==============================] - 22s 383ms/step - loss: 0.3252 - accuracy: 0.8494 - lr: 4.0000e-05\n",
      "Epoch 95/100\n",
      "58/58 [==============================] - 22s 381ms/step - loss: 0.3207 - accuracy: 0.8503 - lr: 4.0000e-05\n",
      "Epoch 96/100\n",
      "58/58 [==============================] - 22s 381ms/step - loss: 0.3248 - accuracy: 0.8533 - lr: 4.0000e-05\n",
      "Epoch 97/100\n",
      "58/58 [==============================] - 22s 383ms/step - loss: 0.3181 - accuracy: 0.8538 - lr: 4.0000e-05\n",
      "Epoch 98/100\n",
      "58/58 [==============================] - 22s 382ms/step - loss: 0.3207 - accuracy: 0.8543 - lr: 4.0000e-05\n",
      "Epoch 99/100\n",
      "58/58 [==============================] - 22s 386ms/step - loss: 0.3179 - accuracy: 0.8538 - lr: 4.0000e-05\n",
      "Epoch 100/100\n",
      "58/58 [==============================] - 22s 384ms/step - loss: 0.3164 - accuracy: 0.8552 - lr: 4.0000e-05\n",
      "44/44 [==============================] - 3s 54ms/step - loss: 0.2837 - accuracy: 0.8798 - lr: 4.0000e-05\n",
      "44/44 [==============================] - 3s 56ms/step\n",
      "44/44 [==============================] - 2s 56ms/step\n",
      "Epoch 1/100\n",
      "58/58 [==============================] - 27s 430ms/step - loss: 0.5904 - accuracy: 0.6809 - lr: 4.0000e-05\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 25s 435ms/step - loss: 0.5427 - accuracy: 0.7232 - lr: 4.0000e-05\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 25s 427ms/step - loss: 0.5151 - accuracy: 0.7443 - lr: 4.0000e-05\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 25s 429ms/step - loss: 0.4967 - accuracy: 0.7583 - lr: 4.0000e-05\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 25s 432ms/step - loss: 0.4822 - accuracy: 0.7705 - lr: 4.0000e-05\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 25s 430ms/step - loss: 0.4671 - accuracy: 0.7783 - lr: 4.0000e-05\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 25s 431ms/step - loss: 0.4549 - accuracy: 0.7877 - lr: 4.0000e-05\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 25s 427ms/step - loss: 0.4420 - accuracy: 0.7975 - lr: 4.0000e-05\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 25s 428ms/step - loss: 0.4287 - accuracy: 0.8072 - lr: 4.0000e-05\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 25s 427ms/step - loss: 0.4120 - accuracy: 0.8174 - lr: 4.0000e-05\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 25s 432ms/step - loss: 0.4048 - accuracy: 0.8196 - lr: 4.0000e-05\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 25s 430ms/step - loss: 0.3926 - accuracy: 0.8208 - lr: 4.0000e-05\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 25s 431ms/step - loss: 0.3867 - accuracy: 0.8299 - lr: 4.0000e-05\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 25s 431ms/step - loss: 0.3785 - accuracy: 0.8320 - lr: 4.0000e-05\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 25s 429ms/step - loss: 0.3692 - accuracy: 0.8423 - lr: 4.0000e-05\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 25s 429ms/step - loss: 0.3601 - accuracy: 0.8412 - lr: 4.0000e-05\n",
      "Epoch 17/100\n",
      "58/58 [==============================] - 25s 428ms/step - loss: 0.3613 - accuracy: 0.8367 - lr: 4.0000e-05\n",
      "Epoch 18/100\n",
      "58/58 [==============================] - 25s 427ms/step - loss: 0.3520 - accuracy: 0.8465 - lr: 4.0000e-05\n",
      "Epoch 19/100\n",
      "58/58 [==============================] - 25s 429ms/step - loss: 0.3499 - accuracy: 0.8480 - lr: 4.0000e-05\n",
      "Epoch 20/100\n",
      "58/58 [==============================] - 25s 432ms/step - loss: 0.3424 - accuracy: 0.8524 - lr: 4.0000e-05\n",
      "Epoch 21/100\n",
      "58/58 [==============================] - 25s 429ms/step - loss: 0.3397 - accuracy: 0.8524 - lr: 4.0000e-05\n",
      "Epoch 22/100\n",
      "58/58 [==============================] - 25s 433ms/step - loss: 0.3342 - accuracy: 0.8526 - lr: 4.0000e-05\n",
      "Epoch 23/100\n",
      "58/58 [==============================] - 25s 429ms/step - loss: 0.3352 - accuracy: 0.8545 - lr: 4.0000e-05\n",
      "Epoch 24/100\n",
      "58/58 [==============================] - 25s 430ms/step - loss: 0.3286 - accuracy: 0.8547 - lr: 4.0000e-05\n",
      "Epoch 25/100\n",
      "58/58 [==============================] - 25s 431ms/step - loss: 0.3251 - accuracy: 0.8576 - lr: 4.0000e-05\n",
      "Epoch 26/100\n",
      "58/58 [==============================] - 25s 428ms/step - loss: 0.3216 - accuracy: 0.8567 - lr: 4.0000e-05\n",
      "Epoch 27/100\n",
      "58/58 [==============================] - 25s 430ms/step - loss: 0.3237 - accuracy: 0.8602 - lr: 4.0000e-05\n",
      "Epoch 28/100\n",
      "58/58 [==============================] - 25s 431ms/step - loss: 0.3196 - accuracy: 0.8602 - lr: 4.0000e-05\n",
      "Epoch 29/100\n",
      "58/58 [==============================] - 25s 437ms/step - loss: 0.3207 - accuracy: 0.8592 - lr: 4.0000e-05\n",
      "Epoch 30/100\n",
      "58/58 [==============================] - 25s 432ms/step - loss: 0.3155 - accuracy: 0.8642 - lr: 4.0000e-05\n",
      "Epoch 31/100\n",
      "58/58 [==============================] - 25s 430ms/step - loss: 0.3143 - accuracy: 0.8644 - lr: 4.0000e-05\n",
      "Epoch 32/100\n",
      "58/58 [==============================] - 25s 431ms/step - loss: 0.3091 - accuracy: 0.8674 - lr: 4.0000e-05\n",
      "Epoch 33/100\n",
      "58/58 [==============================] - 25s 425ms/step - loss: 0.3078 - accuracy: 0.8660 - lr: 4.0000e-05\n",
      "Epoch 34/100\n",
      "58/58 [==============================] - 25s 435ms/step - loss: 0.3071 - accuracy: 0.8649 - lr: 4.0000e-05\n",
      "Epoch 35/100\n",
      "58/58 [==============================] - 25s 433ms/step - loss: 0.3084 - accuracy: 0.8630 - lr: 4.0000e-05\n",
      "Epoch 36/100\n",
      "58/58 [==============================] - 25s 431ms/step - loss: 0.3086 - accuracy: 0.8689 - lr: 4.0000e-05\n",
      "Epoch 37/100\n",
      "58/58 [==============================] - 25s 433ms/step - loss: 0.3073 - accuracy: 0.8662 - lr: 4.0000e-05\n",
      "Epoch 38/100\n",
      "58/58 [==============================] - 25s 429ms/step - loss: 0.3032 - accuracy: 0.8682 - lr: 4.0000e-05\n",
      "Epoch 39/100\n",
      "58/58 [==============================] - 25s 436ms/step - loss: 0.3049 - accuracy: 0.8648 - lr: 4.0000e-05\n",
      "Epoch 40/100\n",
      "58/58 [==============================] - 25s 432ms/step - loss: 0.3032 - accuracy: 0.8642 - lr: 4.0000e-05\n",
      "Epoch 41/100\n",
      "58/58 [==============================] - 25s 428ms/step - loss: 0.2990 - accuracy: 0.8689 - lr: 4.0000e-05\n",
      "Epoch 42/100\n",
      "58/58 [==============================] - 25s 430ms/step - loss: 0.2983 - accuracy: 0.8721 - lr: 4.0000e-05\n",
      "Epoch 43/100\n",
      "58/58 [==============================] - 25s 433ms/step - loss: 0.2961 - accuracy: 0.8691 - lr: 4.0000e-05\n",
      "Epoch 44/100\n",
      "58/58 [==============================] - 25s 435ms/step - loss: 0.2953 - accuracy: 0.8764 - lr: 4.0000e-05\n",
      "Epoch 45/100\n",
      "58/58 [==============================] - 25s 433ms/step - loss: 0.2959 - accuracy: 0.8717 - lr: 4.0000e-05\n",
      "Epoch 46/100\n",
      "58/58 [==============================] - 25s 434ms/step - loss: 0.2971 - accuracy: 0.8728 - lr: 4.0000e-05\n",
      "Epoch 47/100\n",
      "58/58 [==============================] - 25s 425ms/step - loss: 0.3006 - accuracy: 0.8674 - lr: 4.0000e-05\n",
      "Epoch 48/100\n",
      "58/58 [==============================] - 25s 434ms/step - loss: 0.3019 - accuracy: 0.8644 - lr: 4.0000e-05\n",
      "Epoch 49/100\n",
      "58/58 [==============================] - 25s 431ms/step - loss: 0.2929 - accuracy: 0.8723 - lr: 4.0000e-05\n",
      "Epoch 50/100\n",
      "58/58 [==============================] - 25s 431ms/step - loss: 0.2948 - accuracy: 0.8688 - lr: 4.0000e-05\n",
      "Epoch 51/100\n",
      "58/58 [==============================] - 25s 435ms/step - loss: 0.2917 - accuracy: 0.8736 - lr: 4.0000e-05\n",
      "Epoch 52/100\n",
      "58/58 [==============================] - 25s 427ms/step - loss: 0.2967 - accuracy: 0.8679 - lr: 4.0000e-05\n",
      "Epoch 53/100\n",
      "58/58 [==============================] - 25s 427ms/step - loss: 0.2929 - accuracy: 0.8693 - lr: 4.0000e-05\n",
      "Epoch 54/100\n",
      "58/58 [==============================] - 25s 431ms/step - loss: 0.2881 - accuracy: 0.8749 - lr: 4.0000e-05\n",
      "Epoch 55/100\n",
      "58/58 [==============================] - 25s 430ms/step - loss: 0.2921 - accuracy: 0.8735 - lr: 4.0000e-05\n",
      "Epoch 56/100\n",
      "58/58 [==============================] - 24s 418ms/step - loss: 0.2910 - accuracy: 0.8724 - lr: 4.0000e-05\n",
      "Epoch 57/100\n",
      "58/58 [==============================] - 25s 428ms/step - loss: 0.2895 - accuracy: 0.8726 - lr: 4.0000e-05\n",
      "Epoch 58/100\n",
      "58/58 [==============================] - 25s 428ms/step - loss: 0.2885 - accuracy: 0.8728 - lr: 4.0000e-05\n",
      "Epoch 59/100\n",
      "58/58 [==============================] - 25s 434ms/step - loss: 0.2882 - accuracy: 0.8747 - lr: 4.0000e-05\n",
      "Epoch 60/100\n",
      "58/58 [==============================] - 25s 430ms/step - loss: 0.2925 - accuracy: 0.8691 - lr: 4.0000e-05\n",
      "Epoch 61/100\n",
      "58/58 [==============================] - 25s 433ms/step - loss: 0.2855 - accuracy: 0.8740 - lr: 4.0000e-05\n",
      "Epoch 62/100\n",
      "58/58 [==============================] - 25s 430ms/step - loss: 0.2892 - accuracy: 0.8738 - lr: 4.0000e-05\n",
      "Epoch 63/100\n",
      "58/58 [==============================] - 25s 428ms/step - loss: 0.2880 - accuracy: 0.8773 - lr: 4.0000e-05\n",
      "Epoch 64/100\n",
      "58/58 [==============================] - 25s 433ms/step - loss: 0.2868 - accuracy: 0.8733 - lr: 4.0000e-05\n",
      "Epoch 65/100\n",
      "58/58 [==============================] - 25s 436ms/step - loss: 0.2876 - accuracy: 0.8721 - lr: 4.0000e-05\n",
      "Epoch 66/100\n",
      "58/58 [==============================] - 26s 450ms/step - loss: 0.2840 - accuracy: 0.8757 - lr: 4.0000e-05\n",
      "Epoch 67/100\n",
      "58/58 [==============================] - 26s 453ms/step - loss: 0.2820 - accuracy: 0.8773 - lr: 4.0000e-05\n",
      "Epoch 68/100\n",
      "58/58 [==============================] - 26s 440ms/step - loss: 0.2809 - accuracy: 0.8750 - lr: 4.0000e-05\n",
      "Epoch 69/100\n",
      "58/58 [==============================] - 26s 440ms/step - loss: 0.2845 - accuracy: 0.8757 - lr: 4.0000e-05\n",
      "Epoch 70/100\n",
      "58/58 [==============================] - 25s 433ms/step - loss: 0.2851 - accuracy: 0.8775 - lr: 4.0000e-05\n",
      "Epoch 71/100\n",
      "58/58 [==============================] - 25s 436ms/step - loss: 0.2938 - accuracy: 0.8703 - lr: 4.0000e-05\n",
      "Epoch 72/100\n",
      "58/58 [==============================] - 25s 431ms/step - loss: 0.2807 - accuracy: 0.8759 - lr: 4.0000e-05\n",
      "Epoch 73/100\n",
      "58/58 [==============================] - 25s 435ms/step - loss: 0.2877 - accuracy: 0.8721 - lr: 4.0000e-05\n",
      "Epoch 74/100\n",
      "58/58 [==============================] - 25s 436ms/step - loss: 0.2847 - accuracy: 0.8735 - lr: 4.0000e-05\n",
      "Epoch 75/100\n",
      "58/58 [==============================] - 25s 434ms/step - loss: 0.2760 - accuracy: 0.8829 - lr: 4.0000e-05\n",
      "Epoch 76/100\n",
      "58/58 [==============================] - 25s 434ms/step - loss: 0.2819 - accuracy: 0.8759 - lr: 4.0000e-05\n",
      "Epoch 77/100\n",
      "58/58 [==============================] - 25s 432ms/step - loss: 0.2813 - accuracy: 0.8770 - lr: 4.0000e-05\n",
      "Epoch 78/100\n",
      "58/58 [==============================] - 25s 432ms/step - loss: 0.2819 - accuracy: 0.8792 - lr: 4.0000e-05\n",
      "Epoch 79/100\n",
      "58/58 [==============================] - 25s 436ms/step - loss: 0.2785 - accuracy: 0.8778 - lr: 4.0000e-05\n",
      "Epoch 80/100\n",
      "58/58 [==============================] - 25s 435ms/step - loss: 0.2793 - accuracy: 0.8766 - lr: 4.0000e-05\n",
      "Epoch 81/100\n",
      "58/58 [==============================] - 25s 435ms/step - loss: 0.2753 - accuracy: 0.8803 - lr: 4.0000e-05\n",
      "Epoch 82/100\n",
      "58/58 [==============================] - 25s 432ms/step - loss: 0.2753 - accuracy: 0.8803 - lr: 4.0000e-05\n",
      "Epoch 83/100\n",
      "58/58 [==============================] - 25s 437ms/step - loss: 0.2744 - accuracy: 0.8832 - lr: 4.0000e-05\n",
      "Epoch 84/100\n",
      "58/58 [==============================] - 25s 430ms/step - loss: 0.2747 - accuracy: 0.8778 - lr: 4.0000e-05\n",
      "Epoch 85/100\n",
      "58/58 [==============================] - 25s 436ms/step - loss: 0.2772 - accuracy: 0.8782 - lr: 4.0000e-05\n",
      "Epoch 86/100\n",
      "58/58 [==============================] - 25s 431ms/step - loss: 0.2769 - accuracy: 0.8784 - lr: 4.0000e-05\n",
      "Epoch 87/100\n",
      "58/58 [==============================] - 25s 433ms/step - loss: 0.2729 - accuracy: 0.8804 - lr: 4.0000e-05\n",
      "Epoch 88/100\n",
      "58/58 [==============================] - 25s 435ms/step - loss: 0.2737 - accuracy: 0.8796 - lr: 4.0000e-05\n",
      "Epoch 89/100\n",
      "58/58 [==============================] - 25s 433ms/step - loss: 0.2753 - accuracy: 0.8789 - lr: 4.0000e-05\n",
      "Epoch 90/100\n",
      "58/58 [==============================] - 25s 437ms/step - loss: 0.2790 - accuracy: 0.8768 - lr: 4.0000e-05\n",
      "Epoch 91/100\n",
      "58/58 [==============================] - 25s 428ms/step - loss: 0.2768 - accuracy: 0.8784 - lr: 4.0000e-05\n",
      "Epoch 92/100\n",
      "58/58 [==============================] - 25s 436ms/step - loss: 0.2758 - accuracy: 0.8824 - lr: 4.0000e-05\n",
      "Epoch 93/100\n",
      "58/58 [==============================] - 25s 436ms/step - loss: 0.2715 - accuracy: 0.8832 - lr: 4.0000e-05\n",
      "Epoch 94/100\n",
      "58/58 [==============================] - 25s 432ms/step - loss: 0.2794 - accuracy: 0.8782 - lr: 4.0000e-05\n",
      "Epoch 95/100\n",
      "58/58 [==============================] - 25s 434ms/step - loss: 0.2805 - accuracy: 0.8775 - lr: 4.0000e-05\n",
      "Epoch 96/100\n",
      "58/58 [==============================] - 25s 430ms/step - loss: 0.2766 - accuracy: 0.8794 - lr: 4.0000e-05\n",
      "Epoch 97/100\n",
      "58/58 [==============================] - 25s 434ms/step - loss: 0.2730 - accuracy: 0.8796 - lr: 4.0000e-05\n",
      "Epoch 98/100\n",
      "58/58 [==============================] - 25s 435ms/step - loss: 0.2738 - accuracy: 0.8806 - lr: 4.0000e-05\n",
      "Epoch 99/100\n",
      "58/58 [==============================] - 25s 433ms/step - loss: 0.2728 - accuracy: 0.8815 - lr: 4.0000e-05\n",
      "Epoch 100/100\n",
      "58/58 [==============================] - 25s 436ms/step - loss: 0.2712 - accuracy: 0.8825 - lr: 4.0000e-05\n",
      "44/44 [==============================] - 3s 65ms/step - loss: 0.2512 - accuracy: 0.8991 - lr: 4.0000e-05\n",
      "44/44 [==============================] - 3s 62ms/step\n",
      "44/44 [==============================] - 3s 62ms/step\n",
      "Epoch 1/100\n",
      "58/58 [==============================] - 26s 426ms/step - loss: 0.5982 - accuracy: 0.6792 - lr: 4.0000e-05\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 24s 420ms/step - loss: 0.5493 - accuracy: 0.7224 - lr: 4.0000e-05\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 24s 422ms/step - loss: 0.5243 - accuracy: 0.7447 - lr: 4.0000e-05\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 25s 425ms/step - loss: 0.5098 - accuracy: 0.7504 - lr: 4.0000e-05\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 24s 421ms/step - loss: 0.4978 - accuracy: 0.7534 - lr: 4.0000e-05\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 24s 421ms/step - loss: 0.4917 - accuracy: 0.7595 - lr: 4.0000e-05\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 25s 426ms/step - loss: 0.4825 - accuracy: 0.7637 - lr: 4.0000e-05\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 24s 421ms/step - loss: 0.4800 - accuracy: 0.7623 - lr: 4.0000e-05\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 25s 424ms/step - loss: 0.4732 - accuracy: 0.7649 - lr: 4.0000e-05\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 25s 422ms/step - loss: 0.4704 - accuracy: 0.7686 - lr: 4.0000e-05\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 25s 424ms/step - loss: 0.4657 - accuracy: 0.7712 - lr: 4.0000e-05\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 24s 422ms/step - loss: 0.4636 - accuracy: 0.7785 - lr: 4.0000e-05\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 25s 424ms/step - loss: 0.4584 - accuracy: 0.7776 - lr: 4.0000e-05\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 25s 424ms/step - loss: 0.4557 - accuracy: 0.7774 - lr: 4.0000e-05\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 25s 422ms/step - loss: 0.4518 - accuracy: 0.7741 - lr: 4.0000e-05\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 25s 428ms/step - loss: 0.4494 - accuracy: 0.7785 - lr: 4.0000e-05\n",
      "Epoch 17/100\n",
      "58/58 [==============================] - 25s 423ms/step - loss: 0.4466 - accuracy: 0.7806 - lr: 4.0000e-05\n",
      "Epoch 18/100\n",
      "58/58 [==============================] - 24s 420ms/step - loss: 0.4439 - accuracy: 0.7806 - lr: 4.0000e-05\n",
      "Epoch 19/100\n",
      "58/58 [==============================] - 24s 419ms/step - loss: 0.4387 - accuracy: 0.7876 - lr: 4.0000e-05\n",
      "Epoch 20/100\n",
      "58/58 [==============================] - 24s 422ms/step - loss: 0.4376 - accuracy: 0.7910 - lr: 4.0000e-05\n",
      "Epoch 21/100\n",
      "58/58 [==============================] - 25s 423ms/step - loss: 0.4304 - accuracy: 0.7921 - lr: 4.0000e-05\n",
      "Epoch 22/100\n",
      "58/58 [==============================] - 25s 426ms/step - loss: 0.4262 - accuracy: 0.7959 - lr: 4.0000e-05\n",
      "Epoch 23/100\n",
      "58/58 [==============================] - 25s 427ms/step - loss: 0.4228 - accuracy: 0.7991 - lr: 4.0000e-05\n",
      "Epoch 24/100\n",
      "58/58 [==============================] - 25s 425ms/step - loss: 0.4172 - accuracy: 0.8020 - lr: 4.0000e-05\n",
      "Epoch 25/100\n",
      "58/58 [==============================] - 24s 420ms/step - loss: 0.4153 - accuracy: 0.8020 - lr: 4.0000e-05\n",
      "Epoch 26/100\n",
      "58/58 [==============================] - 25s 423ms/step - loss: 0.4137 - accuracy: 0.8027 - lr: 4.0000e-05\n",
      "Epoch 27/100\n",
      "58/58 [==============================] - 25s 423ms/step - loss: 0.4115 - accuracy: 0.8046 - lr: 4.0000e-05\n",
      "Epoch 28/100\n",
      "58/58 [==============================] - 25s 422ms/step - loss: 0.4026 - accuracy: 0.8107 - lr: 4.0000e-05\n",
      "Epoch 29/100\n",
      "58/58 [==============================] - 25s 424ms/step - loss: 0.3969 - accuracy: 0.8182 - lr: 4.0000e-05\n",
      "Epoch 30/100\n",
      "58/58 [==============================] - 24s 421ms/step - loss: 0.3953 - accuracy: 0.8174 - lr: 4.0000e-05\n",
      "Epoch 31/100\n",
      "58/58 [==============================] - 25s 429ms/step - loss: 0.3884 - accuracy: 0.8207 - lr: 4.0000e-05\n",
      "Epoch 32/100\n",
      "58/58 [==============================] - 24s 421ms/step - loss: 0.3835 - accuracy: 0.8294 - lr: 4.0000e-05\n",
      "Epoch 33/100\n",
      "58/58 [==============================] - 25s 423ms/step - loss: 0.3815 - accuracy: 0.8271 - lr: 4.0000e-05\n",
      "Epoch 34/100\n",
      "58/58 [==============================] - 24s 422ms/step - loss: 0.3805 - accuracy: 0.8242 - lr: 4.0000e-05\n",
      "Epoch 35/100\n",
      "58/58 [==============================] - 25s 426ms/step - loss: 0.3758 - accuracy: 0.8320 - lr: 4.0000e-05\n",
      "Epoch 36/100\n",
      "58/58 [==============================] - 24s 422ms/step - loss: 0.3764 - accuracy: 0.8247 - lr: 4.0000e-05\n",
      "Epoch 37/100\n",
      "58/58 [==============================] - 25s 423ms/step - loss: 0.3711 - accuracy: 0.8313 - lr: 4.0000e-05\n",
      "Epoch 38/100\n",
      "58/58 [==============================] - 25s 424ms/step - loss: 0.3671 - accuracy: 0.8334 - lr: 4.0000e-05\n",
      "Epoch 39/100\n",
      "58/58 [==============================] - 25s 428ms/step - loss: 0.3659 - accuracy: 0.8322 - lr: 4.0000e-05\n",
      "Epoch 40/100\n",
      "58/58 [==============================] - 25s 425ms/step - loss: 0.3610 - accuracy: 0.8386 - lr: 4.0000e-05\n",
      "Epoch 41/100\n",
      "58/58 [==============================] - 25s 424ms/step - loss: 0.3570 - accuracy: 0.8426 - lr: 4.0000e-05\n",
      "Epoch 42/100\n",
      "58/58 [==============================] - 25s 427ms/step - loss: 0.3598 - accuracy: 0.8379 - lr: 4.0000e-05\n",
      "Epoch 43/100\n",
      "58/58 [==============================] - 25s 425ms/step - loss: 0.3580 - accuracy: 0.8358 - lr: 4.0000e-05\n",
      "Epoch 44/100\n",
      "58/58 [==============================] - 25s 426ms/step - loss: 0.3558 - accuracy: 0.8383 - lr: 4.0000e-05\n",
      "Epoch 45/100\n",
      "58/58 [==============================] - 25s 422ms/step - loss: 0.3514 - accuracy: 0.8404 - lr: 4.0000e-05\n",
      "Epoch 46/100\n",
      "58/58 [==============================] - 25s 425ms/step - loss: 0.3487 - accuracy: 0.8454 - lr: 4.0000e-05\n",
      "Epoch 47/100\n",
      "58/58 [==============================] - 24s 422ms/step - loss: 0.3482 - accuracy: 0.8381 - lr: 4.0000e-05\n",
      "Epoch 48/100\n",
      "58/58 [==============================] - 25s 424ms/step - loss: 0.3484 - accuracy: 0.8421 - lr: 4.0000e-05\n",
      "Epoch 49/100\n",
      "58/58 [==============================] - 25s 423ms/step - loss: 0.3446 - accuracy: 0.8468 - lr: 4.0000e-05\n",
      "Epoch 50/100\n",
      "58/58 [==============================] - 25s 427ms/step - loss: 0.3455 - accuracy: 0.8409 - lr: 4.0000e-05\n",
      "Epoch 51/100\n",
      "58/58 [==============================] - 25s 426ms/step - loss: 0.3473 - accuracy: 0.8416 - lr: 4.0000e-05\n",
      "Epoch 52/100\n",
      "58/58 [==============================] - 25s 428ms/step - loss: 0.3468 - accuracy: 0.8416 - lr: 4.0000e-05\n",
      "Epoch 53/100\n",
      "58/58 [==============================] - 25s 426ms/step - loss: 0.3417 - accuracy: 0.8444 - lr: 4.0000e-05\n",
      "Epoch 54/100\n",
      "58/58 [==============================] - 25s 426ms/step - loss: 0.3384 - accuracy: 0.8452 - lr: 4.0000e-05\n",
      "Epoch 55/100\n",
      "58/58 [==============================] - 25s 429ms/step - loss: 0.3420 - accuracy: 0.8426 - lr: 4.0000e-05\n",
      "Epoch 56/100\n",
      "58/58 [==============================] - 25s 424ms/step - loss: 0.3387 - accuracy: 0.8468 - lr: 4.0000e-05\n",
      "Epoch 57/100\n",
      "58/58 [==============================] - 24s 420ms/step - loss: 0.3365 - accuracy: 0.8480 - lr: 4.0000e-05\n",
      "Epoch 58/100\n",
      "58/58 [==============================] - 25s 422ms/step - loss: 0.3377 - accuracy: 0.8463 - lr: 4.0000e-05\n",
      "Epoch 59/100\n",
      "58/58 [==============================] - 24s 422ms/step - loss: 0.3353 - accuracy: 0.8496 - lr: 4.0000e-05\n",
      "Epoch 60/100\n",
      "58/58 [==============================] - 25s 423ms/step - loss: 0.3327 - accuracy: 0.8479 - lr: 4.0000e-05\n",
      "Epoch 61/100\n",
      "58/58 [==============================] - 25s 427ms/step - loss: 0.3277 - accuracy: 0.8513 - lr: 4.0000e-05\n",
      "Epoch 62/100\n",
      "58/58 [==============================] - 24s 421ms/step - loss: 0.3288 - accuracy: 0.8526 - lr: 4.0000e-05\n",
      "Epoch 63/100\n",
      "58/58 [==============================] - 25s 424ms/step - loss: 0.3291 - accuracy: 0.8506 - lr: 4.0000e-05\n",
      "Epoch 64/100\n",
      "58/58 [==============================] - 25s 426ms/step - loss: 0.3283 - accuracy: 0.8531 - lr: 4.0000e-05\n",
      "Epoch 65/100\n",
      "58/58 [==============================] - 25s 426ms/step - loss: 0.3311 - accuracy: 0.8505 - lr: 4.0000e-05\n",
      "Epoch 66/100\n",
      "58/58 [==============================] - 25s 429ms/step - loss: 0.3267 - accuracy: 0.8519 - lr: 4.0000e-05\n",
      "Epoch 67/100\n",
      "58/58 [==============================] - 25s 425ms/step - loss: 0.3267 - accuracy: 0.8489 - lr: 4.0000e-05\n",
      "Epoch 68/100\n",
      "58/58 [==============================] - 25s 427ms/step - loss: 0.3263 - accuracy: 0.8480 - lr: 4.0000e-05\n",
      "Epoch 69/100\n",
      "58/58 [==============================] - 25s 422ms/step - loss: 0.3268 - accuracy: 0.8526 - lr: 4.0000e-05\n",
      "Epoch 70/100\n",
      "58/58 [==============================] - 25s 426ms/step - loss: 0.3249 - accuracy: 0.8520 - lr: 4.0000e-05\n",
      "Epoch 71/100\n",
      "58/58 [==============================] - 24s 422ms/step - loss: 0.3283 - accuracy: 0.8522 - lr: 4.0000e-05\n",
      "Epoch 72/100\n",
      "58/58 [==============================] - 25s 424ms/step - loss: 0.3257 - accuracy: 0.8496 - lr: 4.0000e-05\n",
      "Epoch 73/100\n",
      "58/58 [==============================] - 24s 422ms/step - loss: 0.3201 - accuracy: 0.8555 - lr: 4.0000e-05\n",
      "Epoch 74/100\n",
      "58/58 [==============================] - 25s 427ms/step - loss: 0.3239 - accuracy: 0.8515 - lr: 4.0000e-05\n",
      "Epoch 75/100\n",
      "58/58 [==============================] - 24s 421ms/step - loss: 0.3236 - accuracy: 0.8540 - lr: 4.0000e-05\n",
      "Epoch 76/100\n",
      "58/58 [==============================] - 25s 427ms/step - loss: 0.3195 - accuracy: 0.8567 - lr: 4.0000e-05\n",
      "Epoch 77/100\n",
      "58/58 [==============================] - 24s 422ms/step - loss: 0.3190 - accuracy: 0.8566 - lr: 4.0000e-05\n",
      "Epoch 78/100\n",
      "58/58 [==============================] - 25s 425ms/step - loss: 0.3188 - accuracy: 0.8543 - lr: 4.0000e-05\n",
      "Epoch 79/100\n",
      "58/58 [==============================] - 25s 429ms/step - loss: 0.3190 - accuracy: 0.8559 - lr: 4.0000e-05\n",
      "Epoch 80/100\n",
      "58/58 [==============================] - 25s 423ms/step - loss: 0.3158 - accuracy: 0.8599 - lr: 4.0000e-05\n",
      "Epoch 81/100\n",
      "58/58 [==============================] - 25s 426ms/step - loss: 0.3211 - accuracy: 0.8513 - lr: 4.0000e-05\n",
      "Epoch 82/100\n",
      "58/58 [==============================] - 25s 423ms/step - loss: 0.3193 - accuracy: 0.8559 - lr: 4.0000e-05\n",
      "Epoch 83/100\n",
      "58/58 [==============================] - 25s 428ms/step - loss: 0.3183 - accuracy: 0.8547 - lr: 4.0000e-05\n",
      "Epoch 84/100\n",
      "58/58 [==============================] - 25s 423ms/step - loss: 0.3182 - accuracy: 0.8564 - lr: 4.0000e-05\n",
      "Epoch 85/100\n",
      "58/58 [==============================] - 25s 427ms/step - loss: 0.3116 - accuracy: 0.8587 - lr: 4.0000e-05\n",
      "Epoch 86/100\n",
      "58/58 [==============================] - 25s 427ms/step - loss: 0.3196 - accuracy: 0.8562 - lr: 4.0000e-05\n",
      "Epoch 87/100\n",
      "58/58 [==============================] - 25s 428ms/step - loss: 0.3187 - accuracy: 0.8513 - lr: 4.0000e-05\n",
      "Epoch 88/100\n",
      "58/58 [==============================] - 25s 426ms/step - loss: 0.3116 - accuracy: 0.8601 - lr: 4.0000e-05\n",
      "Epoch 89/100\n",
      "58/58 [==============================] - 25s 426ms/step - loss: 0.3158 - accuracy: 0.8513 - lr: 4.0000e-05\n",
      "Epoch 90/100\n",
      "58/58 [==============================] - 25s 427ms/step - loss: 0.3097 - accuracy: 0.8581 - lr: 4.0000e-05\n",
      "Epoch 91/100\n",
      "58/58 [==============================] - 24s 421ms/step - loss: 0.3108 - accuracy: 0.8594 - lr: 4.0000e-05\n",
      "Epoch 92/100\n",
      "58/58 [==============================] - 25s 426ms/step - loss: 0.3097 - accuracy: 0.8623 - lr: 4.0000e-05\n",
      "Epoch 93/100\n",
      "58/58 [==============================] - 24s 421ms/step - loss: 0.3099 - accuracy: 0.8618 - lr: 4.0000e-05\n",
      "Epoch 94/100\n",
      "58/58 [==============================] - 25s 424ms/step - loss: 0.3106 - accuracy: 0.8592 - lr: 4.0000e-05\n",
      "Epoch 95/100\n",
      "58/58 [==============================] - 25s 425ms/step - loss: 0.3114 - accuracy: 0.8571 - lr: 4.0000e-05\n",
      "Epoch 96/100\n",
      "58/58 [==============================] - 25s 427ms/step - loss: 0.3067 - accuracy: 0.8632 - lr: 4.0000e-05\n",
      "Epoch 97/100\n",
      "58/58 [==============================] - 25s 425ms/step - loss: 0.3086 - accuracy: 0.8588 - lr: 4.0000e-05\n",
      "Epoch 98/100\n",
      "58/58 [==============================] - 25s 423ms/step - loss: 0.3113 - accuracy: 0.8594 - lr: 4.0000e-05\n",
      "Epoch 99/100\n",
      "58/58 [==============================] - 24s 419ms/step - loss: 0.3078 - accuracy: 0.8606 - lr: 4.0000e-05\n",
      "Epoch 100/100\n",
      "58/58 [==============================] - 25s 429ms/step - loss: 0.3060 - accuracy: 0.8639 - lr: 4.0000e-05\n",
      "44/44 [==============================] - 3s 62ms/step - loss: 0.2575 - accuracy: 0.8927 - lr: 4.0000e-05\n",
      "44/44 [==============================] - 3s 62ms/step\n",
      "44/44 [==============================] - 3s 64ms/step\n",
      "Epoch 1/100\n",
      "58/58 [==============================] - 25s 411ms/step - loss: 0.5993 - accuracy: 0.6819 - lr: 4.0000e-05\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 24s 414ms/step - loss: 0.5518 - accuracy: 0.7210 - lr: 4.0000e-05\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 24s 409ms/step - loss: 0.5264 - accuracy: 0.7365 - lr: 4.0000e-05\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 24s 420ms/step - loss: 0.5123 - accuracy: 0.7450 - lr: 4.0000e-05\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 24s 410ms/step - loss: 0.4997 - accuracy: 0.7537 - lr: 4.0000e-05\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 24s 416ms/step - loss: 0.4876 - accuracy: 0.7642 - lr: 4.0000e-05\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 24s 413ms/step - loss: 0.4790 - accuracy: 0.7644 - lr: 4.0000e-05\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 24s 414ms/step - loss: 0.4715 - accuracy: 0.7668 - lr: 4.0000e-05\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 24s 413ms/step - loss: 0.4640 - accuracy: 0.7736 - lr: 4.0000e-05\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 24s 415ms/step - loss: 0.4545 - accuracy: 0.7834 - lr: 4.0000e-05\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 24s 416ms/step - loss: 0.4468 - accuracy: 0.7886 - lr: 4.0000e-05\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 24s 412ms/step - loss: 0.4415 - accuracy: 0.7902 - lr: 4.0000e-05\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 24s 411ms/step - loss: 0.4354 - accuracy: 0.7910 - lr: 4.0000e-05\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 24s 416ms/step - loss: 0.4258 - accuracy: 0.8012 - lr: 4.0000e-05\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 24s 416ms/step - loss: 0.4214 - accuracy: 0.8012 - lr: 4.0000e-05\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 24s 415ms/step - loss: 0.4119 - accuracy: 0.8088 - lr: 4.0000e-05\n",
      "Epoch 17/100\n",
      "58/58 [==============================] - 24s 412ms/step - loss: 0.4065 - accuracy: 0.8095 - lr: 4.0000e-05\n",
      "Epoch 18/100\n",
      "58/58 [==============================] - 24s 414ms/step - loss: 0.4019 - accuracy: 0.8146 - lr: 4.0000e-05\n",
      "Epoch 19/100\n",
      "58/58 [==============================] - 24s 413ms/step - loss: 0.4008 - accuracy: 0.8151 - lr: 4.0000e-05\n",
      "Epoch 20/100\n",
      "58/58 [==============================] - 24s 418ms/step - loss: 0.3909 - accuracy: 0.8182 - lr: 4.0000e-05\n",
      "Epoch 21/100\n",
      "58/58 [==============================] - 24s 414ms/step - loss: 0.3878 - accuracy: 0.8236 - lr: 4.0000e-05\n",
      "Epoch 22/100\n",
      "58/58 [==============================] - 24s 417ms/step - loss: 0.3810 - accuracy: 0.8299 - lr: 4.0000e-05\n",
      "Epoch 23/100\n",
      "58/58 [==============================] - 24s 414ms/step - loss: 0.3808 - accuracy: 0.8249 - lr: 4.0000e-05\n",
      "Epoch 24/100\n",
      "58/58 [==============================] - 24s 418ms/step - loss: 0.3801 - accuracy: 0.8278 - lr: 4.0000e-05\n",
      "Epoch 25/100\n",
      "58/58 [==============================] - 24s 413ms/step - loss: 0.3735 - accuracy: 0.8311 - lr: 4.0000e-05\n",
      "Epoch 26/100\n",
      "58/58 [==============================] - 24s 419ms/step - loss: 0.3693 - accuracy: 0.8348 - lr: 4.0000e-05\n",
      "Epoch 27/100\n",
      "58/58 [==============================] - 24s 412ms/step - loss: 0.3634 - accuracy: 0.8350 - lr: 4.0000e-05\n",
      "Epoch 28/100\n",
      "58/58 [==============================] - 24s 416ms/step - loss: 0.3651 - accuracy: 0.8310 - lr: 4.0000e-05\n",
      "Epoch 29/100\n",
      "58/58 [==============================] - 24s 413ms/step - loss: 0.3628 - accuracy: 0.8304 - lr: 4.0000e-05\n",
      "Epoch 30/100\n",
      "58/58 [==============================] - 24s 415ms/step - loss: 0.3596 - accuracy: 0.8336 - lr: 4.0000e-05\n",
      "Epoch 31/100\n",
      "58/58 [==============================] - 24s 415ms/step - loss: 0.3543 - accuracy: 0.8371 - lr: 4.0000e-05\n",
      "Epoch 32/100\n",
      "58/58 [==============================] - 24s 419ms/step - loss: 0.3509 - accuracy: 0.8409 - lr: 4.0000e-05\n",
      "Epoch 33/100\n",
      "58/58 [==============================] - 24s 414ms/step - loss: 0.3494 - accuracy: 0.8437 - lr: 4.0000e-05\n",
      "Epoch 34/100\n",
      "58/58 [==============================] - 24s 420ms/step - loss: 0.3453 - accuracy: 0.8440 - lr: 4.0000e-05\n",
      "Epoch 35/100\n",
      "58/58 [==============================] - 24s 411ms/step - loss: 0.3416 - accuracy: 0.8486 - lr: 4.0000e-05\n",
      "Epoch 36/100\n",
      "58/58 [==============================] - 24s 418ms/step - loss: 0.3397 - accuracy: 0.8459 - lr: 4.0000e-05\n",
      "Epoch 37/100\n",
      "58/58 [==============================] - 24s 416ms/step - loss: 0.3418 - accuracy: 0.8435 - lr: 4.0000e-05\n",
      "Epoch 38/100\n",
      "58/58 [==============================] - 24s 417ms/step - loss: 0.3415 - accuracy: 0.8461 - lr: 4.0000e-05\n",
      "Epoch 39/100\n",
      "58/58 [==============================] - 24s 419ms/step - loss: 0.3378 - accuracy: 0.8482 - lr: 4.0000e-05\n",
      "Epoch 40/100\n",
      "58/58 [==============================] - 24s 415ms/step - loss: 0.3369 - accuracy: 0.8456 - lr: 4.0000e-05\n",
      "Epoch 41/100\n",
      "58/58 [==============================] - 24s 416ms/step - loss: 0.3268 - accuracy: 0.8519 - lr: 4.0000e-05\n",
      "Epoch 42/100\n",
      "58/58 [==============================] - 24s 414ms/step - loss: 0.3257 - accuracy: 0.8559 - lr: 4.0000e-05\n",
      "Epoch 43/100\n",
      "58/58 [==============================] - 24s 415ms/step - loss: 0.3234 - accuracy: 0.8564 - lr: 4.0000e-05\n",
      "Epoch 44/100\n",
      "58/58 [==============================] - 24s 415ms/step - loss: 0.3284 - accuracy: 0.8515 - lr: 4.0000e-05\n",
      "Epoch 45/100\n",
      "58/58 [==============================] - 24s 411ms/step - loss: 0.3226 - accuracy: 0.8536 - lr: 4.0000e-05\n",
      "Epoch 46/100\n",
      "58/58 [==============================] - 24s 414ms/step - loss: 0.3255 - accuracy: 0.8513 - lr: 4.0000e-05\n",
      "Epoch 47/100\n",
      "58/58 [==============================] - 24s 412ms/step - loss: 0.3237 - accuracy: 0.8526 - lr: 4.0000e-05\n",
      "Epoch 48/100\n",
      "58/58 [==============================] - 24s 420ms/step - loss: 0.3212 - accuracy: 0.8540 - lr: 4.0000e-05\n",
      "Epoch 49/100\n",
      "58/58 [==============================] - 24s 420ms/step - loss: 0.3203 - accuracy: 0.8545 - lr: 4.0000e-05\n",
      "Epoch 50/100\n",
      "58/58 [==============================] - 24s 415ms/step - loss: 0.3152 - accuracy: 0.8576 - lr: 4.0000e-05\n",
      "Epoch 51/100\n",
      "58/58 [==============================] - 24s 415ms/step - loss: 0.3133 - accuracy: 0.8576 - lr: 4.0000e-05\n",
      "Epoch 52/100\n",
      "58/58 [==============================] - 24s 415ms/step - loss: 0.3197 - accuracy: 0.8552 - lr: 4.0000e-05\n",
      "Epoch 53/100\n",
      "58/58 [==============================] - 24s 413ms/step - loss: 0.3122 - accuracy: 0.8594 - lr: 4.0000e-05\n",
      "Epoch 54/100\n",
      "58/58 [==============================] - 24s 416ms/step - loss: 0.3111 - accuracy: 0.8569 - lr: 4.0000e-05\n",
      "Epoch 55/100\n",
      "58/58 [==============================] - 24s 410ms/step - loss: 0.3193 - accuracy: 0.8566 - lr: 4.0000e-05\n",
      "Epoch 56/100\n",
      "58/58 [==============================] - 24s 414ms/step - loss: 0.3123 - accuracy: 0.8588 - lr: 4.0000e-05\n",
      "Epoch 57/100\n",
      "58/58 [==============================] - 24s 413ms/step - loss: 0.3089 - accuracy: 0.8599 - lr: 4.0000e-05\n",
      "Epoch 58/100\n",
      "58/58 [==============================] - 24s 412ms/step - loss: 0.3184 - accuracy: 0.8547 - lr: 4.0000e-05\n",
      "Epoch 59/100\n",
      "58/58 [==============================] - 24s 414ms/step - loss: 0.3232 - accuracy: 0.8534 - lr: 4.0000e-05\n",
      "Epoch 60/100\n",
      "58/58 [==============================] - 24s 415ms/step - loss: 0.3137 - accuracy: 0.8526 - lr: 4.0000e-05\n",
      "Epoch 61/100\n",
      "58/58 [==============================] - 23s 404ms/step - loss: 0.3090 - accuracy: 0.8569 - lr: 4.0000e-05\n",
      "Epoch 62/100\n",
      "58/58 [==============================] - 20s 340ms/step - loss: 0.3068 - accuracy: 0.8642 - lr: 4.0000e-05\n",
      "Epoch 63/100\n",
      "58/58 [==============================] - 20s 338ms/step - loss: 0.3021 - accuracy: 0.8609 - lr: 4.0000e-05\n",
      "Epoch 64/100\n",
      "58/58 [==============================] - 20s 338ms/step - loss: 0.2994 - accuracy: 0.8682 - lr: 4.0000e-05\n",
      "Epoch 65/100\n",
      "58/58 [==============================] - 20s 337ms/step - loss: 0.3042 - accuracy: 0.8628 - lr: 4.0000e-05\n",
      "Epoch 66/100\n",
      "58/58 [==============================] - 20s 337ms/step - loss: 0.3084 - accuracy: 0.8587 - lr: 4.0000e-05\n",
      "Epoch 67/100\n",
      "58/58 [==============================] - 20s 337ms/step - loss: 0.3058 - accuracy: 0.8627 - lr: 4.0000e-05\n",
      "Epoch 68/100\n",
      "58/58 [==============================] - 19s 336ms/step - loss: 0.2999 - accuracy: 0.8651 - lr: 4.0000e-05\n",
      "Epoch 69/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.3039 - accuracy: 0.8628 - lr: 4.0000e-05\n",
      "Epoch 70/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.2988 - accuracy: 0.8677 - lr: 4.0000e-05\n",
      "Epoch 71/100\n",
      "58/58 [==============================] - 20s 338ms/step - loss: 0.3003 - accuracy: 0.8637 - lr: 4.0000e-05\n",
      "Epoch 72/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.3048 - accuracy: 0.8634 - lr: 4.0000e-05\n",
      "Epoch 73/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.3019 - accuracy: 0.8648 - lr: 4.0000e-05\n",
      "Epoch 74/100\n",
      "58/58 [==============================] - 20s 337ms/step - loss: 0.2984 - accuracy: 0.8637 - lr: 4.0000e-05\n",
      "Epoch 75/100\n",
      "58/58 [==============================] - 19s 336ms/step - loss: 0.3039 - accuracy: 0.8588 - lr: 4.0000e-05\n",
      "Epoch 76/100\n",
      "58/58 [==============================] - 20s 338ms/step - loss: 0.2991 - accuracy: 0.8656 - lr: 4.0000e-05\n",
      "Epoch 77/100\n",
      "58/58 [==============================] - 20s 338ms/step - loss: 0.2958 - accuracy: 0.8691 - lr: 4.0000e-05\n",
      "Epoch 78/100\n",
      "58/58 [==============================] - 20s 338ms/step - loss: 0.2954 - accuracy: 0.8682 - lr: 4.0000e-05\n",
      "Epoch 79/100\n",
      "58/58 [==============================] - 20s 338ms/step - loss: 0.2958 - accuracy: 0.8632 - lr: 4.0000e-05\n",
      "Epoch 80/100\n",
      "58/58 [==============================] - 20s 338ms/step - loss: 0.2996 - accuracy: 0.8663 - lr: 4.0000e-05\n",
      "Epoch 81/100\n",
      "58/58 [==============================] - 20s 337ms/step - loss: 0.2956 - accuracy: 0.8674 - lr: 4.0000e-05\n",
      "Epoch 82/100\n",
      "58/58 [==============================] - 20s 336ms/step - loss: 0.2886 - accuracy: 0.8679 - lr: 4.0000e-05\n",
      "Epoch 83/100\n",
      "58/58 [==============================] - 20s 337ms/step - loss: 0.2939 - accuracy: 0.8730 - lr: 4.0000e-05\n",
      "Epoch 84/100\n",
      "58/58 [==============================] - 19s 336ms/step - loss: 0.2917 - accuracy: 0.8682 - lr: 4.0000e-05\n",
      "Epoch 85/100\n",
      "58/58 [==============================] - 20s 337ms/step - loss: 0.2901 - accuracy: 0.8705 - lr: 4.0000e-05\n",
      "Epoch 86/100\n",
      "58/58 [==============================] - 20s 336ms/step - loss: 0.2887 - accuracy: 0.8723 - lr: 4.0000e-05\n",
      "Epoch 87/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.2881 - accuracy: 0.8740 - lr: 4.0000e-05\n",
      "Epoch 88/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.2891 - accuracy: 0.8693 - lr: 4.0000e-05\n",
      "Epoch 89/100\n",
      "58/58 [==============================] - 19s 336ms/step - loss: 0.2896 - accuracy: 0.8667 - lr: 4.0000e-05\n",
      "Epoch 90/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.2898 - accuracy: 0.8686 - lr: 4.0000e-05\n",
      "Epoch 91/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.2894 - accuracy: 0.8686 - lr: 4.0000e-05\n",
      "Epoch 92/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.2905 - accuracy: 0.8714 - lr: 4.0000e-05\n",
      "Epoch 93/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.2878 - accuracy: 0.8717 - lr: 4.0000e-05\n",
      "Epoch 94/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.2911 - accuracy: 0.8679 - lr: 4.0000e-05\n",
      "Epoch 95/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.2968 - accuracy: 0.8675 - lr: 4.0000e-05\n",
      "Epoch 96/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.2894 - accuracy: 0.8719 - lr: 4.0000e-05\n",
      "Epoch 97/100\n",
      "58/58 [==============================] - 19s 332ms/step - loss: 0.2870 - accuracy: 0.8696 - lr: 4.0000e-05\n",
      "Epoch 98/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.2874 - accuracy: 0.8724 - lr: 4.0000e-05\n",
      "Epoch 99/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.2891 - accuracy: 0.8696 - lr: 4.0000e-05\n",
      "Epoch 100/100\n",
      "58/58 [==============================] - 19s 336ms/step - loss: 0.2848 - accuracy: 0.8730 - lr: 4.0000e-05\n",
      "44/44 [==============================] - 2s 49ms/step - loss: 0.3214 - accuracy: 0.8505 - lr: 4.0000e-05\n",
      "44/44 [==============================] - 2s 48ms/step\n",
      "44/44 [==============================] - 2s 48ms/step\n",
      "Epoch 1/100\n",
      "58/58 [==============================] - 21s 334ms/step - loss: 0.6000 - accuracy: 0.6711 - lr: 4.0000e-05\n",
      "Epoch 2/100\n",
      "58/58 [==============================] - 19s 332ms/step - loss: 0.5463 - accuracy: 0.7203 - lr: 4.0000e-05\n",
      "Epoch 3/100\n",
      "58/58 [==============================] - 19s 332ms/step - loss: 0.5234 - accuracy: 0.7375 - lr: 4.0000e-05\n",
      "Epoch 4/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.5058 - accuracy: 0.7548 - lr: 4.0000e-05\n",
      "Epoch 5/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.4971 - accuracy: 0.7536 - lr: 4.0000e-05\n",
      "Epoch 6/100\n",
      "58/58 [==============================] - 20s 341ms/step - loss: 0.4869 - accuracy: 0.7586 - lr: 4.0000e-05\n",
      "Epoch 7/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.4785 - accuracy: 0.7625 - lr: 4.0000e-05\n",
      "Epoch 8/100\n",
      "58/58 [==============================] - 19s 336ms/step - loss: 0.4708 - accuracy: 0.7720 - lr: 4.0000e-05\n",
      "Epoch 9/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.4642 - accuracy: 0.7733 - lr: 4.0000e-05\n",
      "Epoch 10/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.4570 - accuracy: 0.7781 - lr: 4.0000e-05\n",
      "Epoch 11/100\n",
      "58/58 [==============================] - 19s 336ms/step - loss: 0.4496 - accuracy: 0.7829 - lr: 4.0000e-05\n",
      "Epoch 12/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.4444 - accuracy: 0.7855 - lr: 4.0000e-05\n",
      "Epoch 13/100\n",
      "58/58 [==============================] - 19s 336ms/step - loss: 0.4402 - accuracy: 0.7888 - lr: 4.0000e-05\n",
      "Epoch 14/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.4332 - accuracy: 0.7964 - lr: 4.0000e-05\n",
      "Epoch 15/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.4286 - accuracy: 0.7940 - lr: 4.0000e-05\n",
      "Epoch 16/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.4245 - accuracy: 0.7956 - lr: 4.0000e-05\n",
      "Epoch 17/100\n",
      "58/58 [==============================] - 19s 336ms/step - loss: 0.4189 - accuracy: 0.7999 - lr: 4.0000e-05\n",
      "Epoch 18/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.4120 - accuracy: 0.8053 - lr: 4.0000e-05\n",
      "Epoch 19/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.4010 - accuracy: 0.8120 - lr: 4.0000e-05\n",
      "Epoch 20/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.3985 - accuracy: 0.8186 - lr: 4.0000e-05\n",
      "Epoch 21/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.3936 - accuracy: 0.8149 - lr: 4.0000e-05\n",
      "Epoch 22/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.3877 - accuracy: 0.8186 - lr: 4.0000e-05\n",
      "Epoch 23/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.3847 - accuracy: 0.8297 - lr: 4.0000e-05\n",
      "Epoch 24/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.3771 - accuracy: 0.8303 - lr: 4.0000e-05\n",
      "Epoch 25/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.3708 - accuracy: 0.8323 - lr: 4.0000e-05\n",
      "Epoch 26/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.3669 - accuracy: 0.8329 - lr: 4.0000e-05\n",
      "Epoch 27/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.3568 - accuracy: 0.8437 - lr: 4.0000e-05\n",
      "Epoch 28/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.3551 - accuracy: 0.8405 - lr: 4.0000e-05\n",
      "Epoch 29/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.3504 - accuracy: 0.8449 - lr: 4.0000e-05\n",
      "Epoch 30/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.3485 - accuracy: 0.8459 - lr: 4.0000e-05\n",
      "Epoch 31/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.3488 - accuracy: 0.8414 - lr: 4.0000e-05\n",
      "Epoch 32/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.3433 - accuracy: 0.8459 - lr: 4.0000e-05\n",
      "Epoch 33/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.3397 - accuracy: 0.8480 - lr: 4.0000e-05\n",
      "Epoch 34/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.3350 - accuracy: 0.8499 - lr: 4.0000e-05\n",
      "Epoch 35/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.3292 - accuracy: 0.8534 - lr: 4.0000e-05\n",
      "Epoch 36/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.3313 - accuracy: 0.8527 - lr: 4.0000e-05\n",
      "Epoch 37/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.3257 - accuracy: 0.8538 - lr: 4.0000e-05\n",
      "Epoch 38/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.3234 - accuracy: 0.8595 - lr: 4.0000e-05\n",
      "Epoch 39/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.3250 - accuracy: 0.8548 - lr: 4.0000e-05\n",
      "Epoch 40/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.3311 - accuracy: 0.8515 - lr: 4.0000e-05\n",
      "Epoch 41/100\n",
      "58/58 [==============================] - 19s 336ms/step - loss: 0.3205 - accuracy: 0.8587 - lr: 4.0000e-05\n",
      "Epoch 42/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.3218 - accuracy: 0.8526 - lr: 4.0000e-05\n",
      "Epoch 43/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.3223 - accuracy: 0.8566 - lr: 4.0000e-05\n",
      "Epoch 44/100\n",
      "58/58 [==============================] - 19s 336ms/step - loss: 0.3191 - accuracy: 0.8571 - lr: 4.0000e-05\n",
      "Epoch 45/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.3159 - accuracy: 0.8592 - lr: 4.0000e-05\n",
      "Epoch 46/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.3137 - accuracy: 0.8604 - lr: 4.0000e-05\n",
      "Epoch 47/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.3121 - accuracy: 0.8587 - lr: 4.0000e-05\n",
      "Epoch 48/100\n",
      "58/58 [==============================] - 20s 344ms/step - loss: 0.3143 - accuracy: 0.8560 - lr: 4.0000e-05\n",
      "Epoch 49/100\n",
      "58/58 [==============================] - 21s 358ms/step - loss: 0.3122 - accuracy: 0.8601 - lr: 4.0000e-05\n",
      "Epoch 50/100\n",
      "58/58 [==============================] - 20s 336ms/step - loss: 0.3171 - accuracy: 0.8569 - lr: 4.0000e-05\n",
      "Epoch 51/100\n",
      "58/58 [==============================] - 20s 340ms/step - loss: 0.3096 - accuracy: 0.8590 - lr: 4.0000e-05\n",
      "Epoch 52/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.3062 - accuracy: 0.8635 - lr: 4.0000e-05\n",
      "Epoch 53/100\n",
      "58/58 [==============================] - 19s 332ms/step - loss: 0.3057 - accuracy: 0.8644 - lr: 4.0000e-05\n",
      "Epoch 54/100\n",
      "58/58 [==============================] - 19s 332ms/step - loss: 0.3050 - accuracy: 0.8632 - lr: 4.0000e-05\n",
      "Epoch 55/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.3156 - accuracy: 0.8564 - lr: 4.0000e-05\n",
      "Epoch 56/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.3044 - accuracy: 0.8670 - lr: 4.0000e-05\n",
      "Epoch 57/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.3071 - accuracy: 0.8656 - lr: 4.0000e-05\n",
      "Epoch 58/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.3019 - accuracy: 0.8646 - lr: 4.0000e-05\n",
      "Epoch 59/100\n",
      "58/58 [==============================] - 19s 331ms/step - loss: 0.3030 - accuracy: 0.8658 - lr: 4.0000e-05\n",
      "Epoch 60/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.3004 - accuracy: 0.8677 - lr: 4.0000e-05\n",
      "Epoch 61/100\n",
      "58/58 [==============================] - 19s 332ms/step - loss: 0.3025 - accuracy: 0.8648 - lr: 4.0000e-05\n",
      "Epoch 62/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.2951 - accuracy: 0.8681 - lr: 4.0000e-05\n",
      "Epoch 63/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.3028 - accuracy: 0.8608 - lr: 4.0000e-05\n",
      "Epoch 64/100\n",
      "58/58 [==============================] - 19s 332ms/step - loss: 0.2973 - accuracy: 0.8634 - lr: 4.0000e-05\n",
      "Epoch 65/100\n",
      "58/58 [==============================] - 19s 332ms/step - loss: 0.2971 - accuracy: 0.8672 - lr: 4.0000e-05\n",
      "Epoch 66/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.3000 - accuracy: 0.8649 - lr: 4.0000e-05\n",
      "Epoch 67/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.2951 - accuracy: 0.8663 - lr: 4.0000e-05\n",
      "Epoch 68/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.2939 - accuracy: 0.8730 - lr: 4.0000e-05\n",
      "Epoch 69/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.2981 - accuracy: 0.8639 - lr: 4.0000e-05\n",
      "Epoch 70/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.2922 - accuracy: 0.8731 - lr: 4.0000e-05\n",
      "Epoch 71/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.2939 - accuracy: 0.8689 - lr: 4.0000e-05\n",
      "Epoch 72/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.2919 - accuracy: 0.8703 - lr: 4.0000e-05\n",
      "Epoch 73/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.2960 - accuracy: 0.8689 - lr: 4.0000e-05\n",
      "Epoch 74/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.2923 - accuracy: 0.8686 - lr: 4.0000e-05\n",
      "Epoch 75/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.2908 - accuracy: 0.8709 - lr: 4.0000e-05\n",
      "Epoch 76/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.2918 - accuracy: 0.8717 - lr: 4.0000e-05\n",
      "Epoch 77/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.2915 - accuracy: 0.8707 - lr: 4.0000e-05\n",
      "Epoch 78/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.2910 - accuracy: 0.8730 - lr: 4.0000e-05\n",
      "Epoch 79/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.2931 - accuracy: 0.8684 - lr: 4.0000e-05\n",
      "Epoch 80/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.2945 - accuracy: 0.8693 - lr: 4.0000e-05\n",
      "Epoch 81/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.2897 - accuracy: 0.8717 - lr: 4.0000e-05\n",
      "Epoch 82/100\n",
      "58/58 [==============================] - 19s 332ms/step - loss: 0.2945 - accuracy: 0.8688 - lr: 4.0000e-05\n",
      "Epoch 83/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.2901 - accuracy: 0.8695 - lr: 4.0000e-05\n",
      "Epoch 84/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.2836 - accuracy: 0.8761 - lr: 4.0000e-05\n",
      "Epoch 85/100\n",
      "58/58 [==============================] - 19s 334ms/step - loss: 0.2880 - accuracy: 0.8745 - lr: 4.0000e-05\n",
      "Epoch 86/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.2956 - accuracy: 0.8682 - lr: 4.0000e-05\n",
      "Epoch 87/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.2904 - accuracy: 0.8728 - lr: 4.0000e-05\n",
      "Epoch 88/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.2840 - accuracy: 0.8743 - lr: 4.0000e-05\n",
      "Epoch 89/100\n",
      "58/58 [==============================] - 19s 332ms/step - loss: 0.2864 - accuracy: 0.8750 - lr: 4.0000e-05\n",
      "Epoch 90/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.2855 - accuracy: 0.8756 - lr: 4.0000e-05\n",
      "Epoch 91/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.2878 - accuracy: 0.8710 - lr: 4.0000e-05\n",
      "Epoch 92/100\n",
      "58/58 [==============================] - 19s 333ms/step - loss: 0.2862 - accuracy: 0.8757 - lr: 4.0000e-05\n",
      "Epoch 93/100\n",
      "58/58 [==============================] - 19s 332ms/step - loss: 0.2878 - accuracy: 0.8764 - lr: 4.0000e-05\n",
      "Epoch 94/100\n",
      "58/58 [==============================] - 19s 331ms/step - loss: 0.2811 - accuracy: 0.8736 - lr: 4.0000e-05\n",
      "Epoch 95/100\n",
      "58/58 [==============================] - 19s 332ms/step - loss: 0.2860 - accuracy: 0.8726 - lr: 4.0000e-05\n",
      "Epoch 96/100\n",
      "58/58 [==============================] - 19s 331ms/step - loss: 0.2850 - accuracy: 0.8705 - lr: 4.0000e-05\n",
      "Epoch 97/100\n",
      "58/58 [==============================] - 19s 332ms/step - loss: 0.2809 - accuracy: 0.8773 - lr: 4.0000e-05\n",
      "Epoch 98/100\n",
      "58/58 [==============================] - 19s 331ms/step - loss: 0.2829 - accuracy: 0.8777 - lr: 4.0000e-05\n",
      "Epoch 99/100\n",
      "58/58 [==============================] - 19s 332ms/step - loss: 0.2826 - accuracy: 0.8747 - lr: 4.0000e-05\n",
      "Epoch 100/100\n",
      "58/58 [==============================] - 19s 335ms/step - loss: 0.2826 - accuracy: 0.8749 - lr: 4.0000e-05\n",
      "44/44 [==============================] - 2s 47ms/step - loss: 0.3445 - accuracy: 0.8548 - lr: 4.0000e-05\n",
      "44/44 [==============================] - 2s 47ms/step\n",
      "44/44 [==============================] - 2s 47ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "tprs=[]\n",
    "mean_fpr=np.linspace(0,1,100)\n",
    "auck=[0,0,0,0,0]\n",
    "Recalls=[]\n",
    "F1score=[]\n",
    "specificity=[]\n",
    "accuracys = []\n",
    "for i in range(5):\n",
    "    if i==0:\n",
    "        x_train, y_train = x_train0,y_train0\n",
    "        x_test, y_test = x_test0,y_test0\n",
    "        model.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model.predict(x_test))\n",
    "        y_pred=model.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    elif i ==1:\n",
    "        x_train, y_train = x_train1,y_train1\n",
    "        x_test, y_test = x_test1,y_test1\n",
    "        model2.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model2.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model2.predict(x_test))\n",
    "        y_pred=model2.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    elif i ==2:\n",
    "        x_train, y_train = x_train2,y_train2\n",
    "        x_test, y_test = x_test2,y_test2\n",
    "        model3.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model3.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model3.predict(x_test))\n",
    "        y_pred=model3.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    elif i ==3:\n",
    "        x_train, y_train = x_train3,y_train3\n",
    "        x_test, y_test = x_test3,y_test3\n",
    "        model4.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model4.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model4.predict(x_test))\n",
    "        y_pred=model4.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    else:\n",
    "        x_train, y_train = x_train4,y_train4\n",
    "        x_test, y_test = x_test4,y_test4\n",
    "        model5.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model5.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model5.predict(x_test))\n",
    "        y_pred=model5.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    auck[i] = auc(fpr, tpr)\n",
    "    tprs.append(interp(mean_fpr,fpr,tpr))\n",
    "    tprs[-1][0]=0.0\n",
    "scores=np.array(scores)\n",
    "interval = stats.t.interval(0.95, scores.shape[0] - 1, scores.mean(), scores.std() / np.sqrt(scores.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fc5b3882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence interval：(0.8510153967816868, 0.8997714322130642)\n",
      "scores: 0.8753934144973755\n",
      "AUC: 0.9516936968023926\n"
     ]
    }
   ],
   "source": [
    "print(\"confidence interval：{}\".format(interval))\n",
    "print('scores:',np.mean(scores))\n",
    "print('AUC:',np.mean(auck))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "53c4f776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recalls: 0.929192546583851\n",
      "F1score: 0.9113070833771044\n"
     ]
    }
   ],
   "source": [
    "print('Recalls:',np.mean(Recalls))\n",
    "print('F1score:',np.mean(F1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "bb4f042a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9466398984629731, 0.956747495141812)\n"
     ]
    }
   ],
   "source": [
    "conf = sms.DescrStatsW(auck).tconfint_mean(0.05)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b671583a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2005f931ae0>]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.grid(alpha=0.4)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.plot([0,1],[0,1],linestyle='--',lw=2,color='r',alpha=0.1)\n",
    "plt.xlabel('False Positive Rate', fontsize=13)\n",
    "plt.ylabel('True Positive Rate', fontsize=13)\n",
    "mean_tpr=np.mean(tprs,axis=0)\n",
    "mean_tpr[-1]=1.0\n",
    "std_auc=np.std(tprs,axis=0)\n",
    "plt.plot(mean_fpr,mean_tpr,color='b',label = u'AUC=%.3f' % (sum(auck)/5),lw=2,alpha=0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "3c06e3e46abf38078fe4dac36a0085ec2b134ebbd73dd076183d243eeca6918f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
