{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "452b9946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T12:59:35.081622Z",
     "start_time": "2022-07-05T12:59:35.077621Z"
    }
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "8cf216bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:46.997604Z",
     "start_time": "2022-07-07T13:19:42.857680Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from pandas import read_csv, unique\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import mode\n",
    "from scipy import interp\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,roc_curve,auc\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow import stack\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling1D, BatchNormalization, MaxPool1D, Reshape, Activation\n",
    "from keras.layers import Conv1D, LSTM\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56be0860",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "f4351ece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:47.013608Z",
     "start_time": "2022-07-07T13:19:46.998607Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(filepath):\n",
    "    df = read_csv(filepath, header=None, names=['user-id',\n",
    "                                               'activity',\n",
    "                                               'timestamp',\n",
    "                                               'sex',\n",
    "                                               'age',\n",
    "                                               'BMI',\n",
    "                                               'A',\n",
    "                                               'B',\n",
    "                                               'C',\n",
    "                                               'X',\n",
    "                                               'Y',\n",
    "                                               'Z'])\n",
    "    ## removing ';' from last column and converting it to float\n",
    "    df['Z'].replace(regex=True, inplace=True, to_replace=r';', value=r'')\n",
    "    df['Z'] = df['Z'].apply(convert_to_float)\n",
    "#     df.dropna(axis=0, how='any', inplace=True)\n",
    "    return df\n",
    "\n",
    "def convert_to_float(x):\n",
    "    try:\n",
    "        return np.float64(x)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "fe14cbaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:48.655211Z",
     "start_time": "2022-07-07T13:19:47.014608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.842979</td>\n",
       "      <td>142.253244</td>\n",
       "      <td>110.183184</td>\n",
       "      <td>132.892332</td>\n",
       "      <td>100.336497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.036722</td>\n",
       "      <td>141.564971</td>\n",
       "      <td>109.963102</td>\n",
       "      <td>132.264821</td>\n",
       "      <td>99.724264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.025532</td>\n",
       "      <td>141.226818</td>\n",
       "      <td>110.076491</td>\n",
       "      <td>131.910252</td>\n",
       "      <td>99.841460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.055731</td>\n",
       "      <td>139.674749</td>\n",
       "      <td>109.314311</td>\n",
       "      <td>130.638475</td>\n",
       "      <td>99.437923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39.286753</td>\n",
       "      <td>138.646791</td>\n",
       "      <td>109.321849</td>\n",
       "      <td>129.840633</td>\n",
       "      <td>99.368373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142795</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>395</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>395.0</td>\n",
       "      <td>53.054386</td>\n",
       "      <td>101.282433</td>\n",
       "      <td>98.437307</td>\n",
       "      <td>91.694820</td>\n",
       "      <td>95.570696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142796</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>396</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>396.0</td>\n",
       "      <td>51.566923</td>\n",
       "      <td>104.802220</td>\n",
       "      <td>100.029568</td>\n",
       "      <td>98.373605</td>\n",
       "      <td>98.261446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142797</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>397</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>397.0</td>\n",
       "      <td>50.444408</td>\n",
       "      <td>106.489055</td>\n",
       "      <td>101.999649</td>\n",
       "      <td>101.329230</td>\n",
       "      <td>100.532071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142798</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>398</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>398.0</td>\n",
       "      <td>50.424259</td>\n",
       "      <td>106.749087</td>\n",
       "      <td>102.629601</td>\n",
       "      <td>101.878083</td>\n",
       "      <td>101.378611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142799</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>399</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>399.0</td>\n",
       "      <td>50.404110</td>\n",
       "      <td>107.009119</td>\n",
       "      <td>103.259553</td>\n",
       "      <td>102.426936</td>\n",
       "      <td>102.225152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp  sex  age        BMI      A          B  \\\n",
       "0             1      Yes          0    1   57  24.212293    0.0  38.842979   \n",
       "1             1      Yes          1    1   57  24.212293    1.0  39.036722   \n",
       "2             1      Yes          2    1   57  24.212293    2.0  39.025532   \n",
       "3             1      Yes          3    1   57  24.212293    3.0  39.055731   \n",
       "4             1      Yes          4    1   57  24.212293    4.0  39.286753   \n",
       "...         ...      ...        ...  ...  ...        ...    ...        ...   \n",
       "142795      357      Yes        395    1   54  25.402816  395.0  53.054386   \n",
       "142796      357      Yes        396    1   54  25.402816  396.0  51.566923   \n",
       "142797      357      Yes        397    1   54  25.402816  397.0  50.444408   \n",
       "142798      357      Yes        398    1   54  25.402816  398.0  50.424259   \n",
       "142799      357      Yes        399    1   54  25.402816  399.0  50.404110   \n",
       "\n",
       "                 C           X           Y           Z  \n",
       "0       142.253244  110.183184  132.892332  100.336497  \n",
       "1       141.564971  109.963102  132.264821   99.724264  \n",
       "2       141.226818  110.076491  131.910252   99.841460  \n",
       "3       139.674749  109.314311  130.638475   99.437923  \n",
       "4       138.646791  109.321849  129.840633   99.368373  \n",
       "...            ...         ...         ...         ...  \n",
       "142795  101.282433   98.437307   91.694820   95.570696  \n",
       "142796  104.802220  100.029568   98.373605   98.261446  \n",
       "142797  106.489055  101.999649  101.329230  100.532071  \n",
       "142798  106.749087  102.629601  101.878083  101.378611  \n",
       "142799  107.009119  103.259553  102.426936  102.225152  \n",
       "\n",
       "[142800 rows x 12 columns]"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_data('Dataset/Angel_and_Baseline/Angel_data_STS_order.txt')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cfc0f2",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "78699eb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.436290Z",
     "start_time": "2022-07-07T13:19:50.281071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>activityEncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.842979</td>\n",
       "      <td>142.253244</td>\n",
       "      <td>110.183184</td>\n",
       "      <td>132.892332</td>\n",
       "      <td>100.336497</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.036722</td>\n",
       "      <td>141.564971</td>\n",
       "      <td>109.963102</td>\n",
       "      <td>132.264821</td>\n",
       "      <td>99.724264</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.025532</td>\n",
       "      <td>141.226818</td>\n",
       "      <td>110.076491</td>\n",
       "      <td>131.910252</td>\n",
       "      <td>99.841460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.055731</td>\n",
       "      <td>139.674749</td>\n",
       "      <td>109.314311</td>\n",
       "      <td>130.638475</td>\n",
       "      <td>99.437923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39.286753</td>\n",
       "      <td>138.646791</td>\n",
       "      <td>109.321849</td>\n",
       "      <td>129.840633</td>\n",
       "      <td>99.368373</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142795</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>395</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>395.0</td>\n",
       "      <td>53.054386</td>\n",
       "      <td>101.282433</td>\n",
       "      <td>98.437307</td>\n",
       "      <td>91.694820</td>\n",
       "      <td>95.570696</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142796</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>396</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>396.0</td>\n",
       "      <td>51.566923</td>\n",
       "      <td>104.802220</td>\n",
       "      <td>100.029568</td>\n",
       "      <td>98.373605</td>\n",
       "      <td>98.261446</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142797</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>397</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>397.0</td>\n",
       "      <td>50.444408</td>\n",
       "      <td>106.489055</td>\n",
       "      <td>101.999649</td>\n",
       "      <td>101.329230</td>\n",
       "      <td>100.532071</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142798</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>398</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>398.0</td>\n",
       "      <td>50.424259</td>\n",
       "      <td>106.749087</td>\n",
       "      <td>102.629601</td>\n",
       "      <td>101.878083</td>\n",
       "      <td>101.378611</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142799</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>399</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>399.0</td>\n",
       "      <td>50.404110</td>\n",
       "      <td>107.009119</td>\n",
       "      <td>103.259553</td>\n",
       "      <td>102.426936</td>\n",
       "      <td>102.225152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142800 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp  sex  age        BMI      A          B  \\\n",
       "0             1      Yes          0    1   57  24.212293    0.0  38.842979   \n",
       "1             1      Yes          1    1   57  24.212293    1.0  39.036722   \n",
       "2             1      Yes          2    1   57  24.212293    2.0  39.025532   \n",
       "3             1      Yes          3    1   57  24.212293    3.0  39.055731   \n",
       "4             1      Yes          4    1   57  24.212293    4.0  39.286753   \n",
       "...         ...      ...        ...  ...  ...        ...    ...        ...   \n",
       "142795      357      Yes        395    1   54  25.402816  395.0  53.054386   \n",
       "142796      357      Yes        396    1   54  25.402816  396.0  51.566923   \n",
       "142797      357      Yes        397    1   54  25.402816  397.0  50.444408   \n",
       "142798      357      Yes        398    1   54  25.402816  398.0  50.424259   \n",
       "142799      357      Yes        399    1   54  25.402816  399.0  50.404110   \n",
       "\n",
       "                 C           X           Y           Z  activityEncode  \n",
       "0       142.253244  110.183184  132.892332  100.336497               1  \n",
       "1       141.564971  109.963102  132.264821   99.724264               1  \n",
       "2       141.226818  110.076491  131.910252   99.841460               1  \n",
       "3       139.674749  109.314311  130.638475   99.437923               1  \n",
       "4       138.646791  109.321849  129.840633   99.368373               1  \n",
       "...            ...         ...         ...         ...             ...  \n",
       "142795  101.282433   98.437307   91.694820   95.570696               1  \n",
       "142796  104.802220  100.029568   98.373605   98.261446               1  \n",
       "142797  106.489055  101.999649  101.329230  100.532071               1  \n",
       "142798  106.749087  102.629601  101.878083  101.378611               1  \n",
       "142799  107.009119  103.259553  102.426936  102.225152               1  \n",
       "\n",
       "[142800 rows x 13 columns]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encode = LabelEncoder()\n",
    "df['activityEncode'] = label_encode.fit_transform(df['activity'].values.ravel())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3be5152",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T16:53:26.834976Z",
     "start_time": "2022-07-04T16:53:26.823973Z"
    }
   },
   "source": [
    "## Linear Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "7951cd31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.484301Z",
     "start_time": "2022-07-07T13:19:50.437290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user-id           0\n",
       "activity          0\n",
       "timestamp         0\n",
       "sex               0\n",
       "age               0\n",
       "BMI               0\n",
       "A                 0\n",
       "B                 0\n",
       "C                 0\n",
       "X                 0\n",
       "Y                 0\n",
       "Z                 0\n",
       "activityEncode    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "b6d9e58d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.532284Z",
     "start_time": "2022-07-07T13:19:50.485302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scipy.interpolate._interpolate.interp1d at 0x1f800c7f240>"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation_fn = interp1d(df['activityEncode'] ,df['Z'], kind='linear')\n",
    "interpolation_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "4f8ea8cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.548288Z",
     "start_time": "2022-07-07T13:19:50.534285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_list = df[df['Z'].isnull()].index.tolist()\n",
    "null_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "f002bca0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.580295Z",
     "start_time": "2022-07-07T13:19:50.549289Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in null_list:\n",
    "    y = df['activityEncode'][i]\n",
    "    value = interpolation_fn(y)\n",
    "    df['Z']=df['Z'].fillna(value)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "b4349e1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.627795Z",
     "start_time": "2022-07-07T13:19:50.581295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user-id           0\n",
       "activity          0\n",
       "timestamp         0\n",
       "sex               0\n",
       "age               0\n",
       "BMI               0\n",
       "A                 0\n",
       "B                 0\n",
       "C                 0\n",
       "X                 0\n",
       "Y                 0\n",
       "Z                 0\n",
       "activityEncode    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69abe57c",
   "metadata": {},
   "source": [
    "## Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "a24a047f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>activityEncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433618</td>\n",
       "      <td>0.712609</td>\n",
       "      <td>0.423799</td>\n",
       "      <td>0.650296</td>\n",
       "      <td>0.335294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.436683</td>\n",
       "      <td>0.707362</td>\n",
       "      <td>0.421885</td>\n",
       "      <td>0.645632</td>\n",
       "      <td>0.329743</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.436506</td>\n",
       "      <td>0.704784</td>\n",
       "      <td>0.422871</td>\n",
       "      <td>0.642997</td>\n",
       "      <td>0.330805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.436984</td>\n",
       "      <td>0.692951</td>\n",
       "      <td>0.416241</td>\n",
       "      <td>0.633544</td>\n",
       "      <td>0.327147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>0.440639</td>\n",
       "      <td>0.685113</td>\n",
       "      <td>0.416307</td>\n",
       "      <td>0.627614</td>\n",
       "      <td>0.326516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142795</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.989975</td>\n",
       "      <td>0.658435</td>\n",
       "      <td>0.400242</td>\n",
       "      <td>0.321626</td>\n",
       "      <td>0.344084</td>\n",
       "      <td>0.292085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142796</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.992481</td>\n",
       "      <td>0.634904</td>\n",
       "      <td>0.427078</td>\n",
       "      <td>0.335476</td>\n",
       "      <td>0.393726</td>\n",
       "      <td>0.316480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142797</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.994987</td>\n",
       "      <td>0.617146</td>\n",
       "      <td>0.439938</td>\n",
       "      <td>0.352614</td>\n",
       "      <td>0.415694</td>\n",
       "      <td>0.337067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142798</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.997494</td>\n",
       "      <td>0.616828</td>\n",
       "      <td>0.441921</td>\n",
       "      <td>0.358093</td>\n",
       "      <td>0.419774</td>\n",
       "      <td>0.344742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142799</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.616509</td>\n",
       "      <td>0.443904</td>\n",
       "      <td>0.363573</td>\n",
       "      <td>0.423853</td>\n",
       "      <td>0.352417</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142800 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp  sex       age       BMI         A  \\\n",
       "0             1      Yes          0  0.0  0.225806  0.398781  0.000000   \n",
       "1             1      Yes          1  0.0  0.225806  0.398781  0.002506   \n",
       "2             1      Yes          2  0.0  0.225806  0.398781  0.005013   \n",
       "3             1      Yes          3  0.0  0.225806  0.398781  0.007519   \n",
       "4             1      Yes          4  0.0  0.225806  0.398781  0.010025   \n",
       "...         ...      ...        ...  ...       ...       ...       ...   \n",
       "142795      357      Yes        395  0.0  0.129032  0.460572  0.989975   \n",
       "142796      357      Yes        396  0.0  0.129032  0.460572  0.992481   \n",
       "142797      357      Yes        397  0.0  0.129032  0.460572  0.994987   \n",
       "142798      357      Yes        398  0.0  0.129032  0.460572  0.997494   \n",
       "142799      357      Yes        399  0.0  0.129032  0.460572  1.000000   \n",
       "\n",
       "               B         C         X         Y         Z  activityEncode  \n",
       "0       0.433618  0.712609  0.423799  0.650296  0.335294               1  \n",
       "1       0.436683  0.707362  0.421885  0.645632  0.329743               1  \n",
       "2       0.436506  0.704784  0.422871  0.642997  0.330805               1  \n",
       "3       0.436984  0.692951  0.416241  0.633544  0.327147               1  \n",
       "4       0.440639  0.685113  0.416307  0.627614  0.326516               1  \n",
       "...          ...       ...       ...       ...       ...             ...  \n",
       "142795  0.658435  0.400242  0.321626  0.344084  0.292085               1  \n",
       "142796  0.634904  0.427078  0.335476  0.393726  0.316480               1  \n",
       "142797  0.617146  0.439938  0.352614  0.415694  0.337067               1  \n",
       "142798  0.616828  0.441921  0.358093  0.419774  0.344742               1  \n",
       "142799  0.616509  0.443904  0.363573  0.423853  0.352417               1  \n",
       "\n",
       "[142800 rows x 13 columns]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'] = (df['age']-df['age'].min())/(df['age'].max()-df['age'].min())\n",
    "df['BMI'] = (df['BMI']-df['BMI'].min())/(df['BMI'].max()-df['BMI'].min())\n",
    "df['A'] = (df['A']-df['A'].min())/(df['A'].max()-df['A'].min())\n",
    "df['B'] = (df['B']-df['B'].min())/(df['B'].max()-df['B'].min())\n",
    "df['C'] = (df['C']-df['C'].min())/(df['C'].max()-df['C'].min())\n",
    "df['X'] = (df['X']-df['X'].min())/(df['X'].max()-df['X'].min())\n",
    "df['Y'] = (df['Y']-df['Y'].min())/(df['Y'].max()-df['Y'].min())\n",
    "df['Z'] = (df['Z']-df['Z'].min())/(df['Z'].max()-df['Z'].min())\n",
    "df['sex'] = (df['sex']-df['sex'].min())/(df['sex'].max()-df['sex'].min())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "a31ec3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segments(df, time_steps, step, label_name):\n",
    "    N_FEATURES = 9\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "        xs = df['X'].values[i:i+time_steps]\n",
    "        ys = df['Y'].values[i:i+time_steps]\n",
    "        zs = df['Z'].values[i:i+time_steps]\n",
    "        aas = df['A'].values[i:i+time_steps]\n",
    "        bs = df['B'].values[i:i+time_steps]\n",
    "        cs = df['C'].values[i:i+time_steps]\n",
    "        sexs = df['sex'].values[i:i+time_steps]\n",
    "        ages = df['age'].values[i:i+time_steps]\n",
    "        bmis = df['BMI'].values[i:i+time_steps]\n",
    "        label = mode(df[label_name][i:i+time_steps])[0][0]\n",
    "        segments.append([sexs,ages,bmis,aas,bs,cs,xs, ys, zs])\n",
    "        labels.append(label)\n",
    "    reshaped_segments = np.asarray(segments, dtype=np.float32).reshape(-1, time_steps, N_FEATURES)\n",
    "    labels = np.asarray(labels)\n",
    "    return reshaped_segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "987cccea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>activityEncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.433618</td>\n",
       "      <td>0.712609</td>\n",
       "      <td>0.423799</td>\n",
       "      <td>0.650296</td>\n",
       "      <td>0.335294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.436683</td>\n",
       "      <td>0.707362</td>\n",
       "      <td>0.421885</td>\n",
       "      <td>0.645632</td>\n",
       "      <td>0.329743</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.436506</td>\n",
       "      <td>0.704784</td>\n",
       "      <td>0.422871</td>\n",
       "      <td>0.642997</td>\n",
       "      <td>0.330805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.436984</td>\n",
       "      <td>0.692951</td>\n",
       "      <td>0.416241</td>\n",
       "      <td>0.633544</td>\n",
       "      <td>0.327147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>0.440639</td>\n",
       "      <td>0.685113</td>\n",
       "      <td>0.416307</td>\n",
       "      <td>0.627614</td>\n",
       "      <td>0.326516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142795</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.989975</td>\n",
       "      <td>0.658435</td>\n",
       "      <td>0.400242</td>\n",
       "      <td>0.321626</td>\n",
       "      <td>0.344084</td>\n",
       "      <td>0.292085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142796</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.992481</td>\n",
       "      <td>0.634904</td>\n",
       "      <td>0.427078</td>\n",
       "      <td>0.335476</td>\n",
       "      <td>0.393726</td>\n",
       "      <td>0.316480</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142797</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.994987</td>\n",
       "      <td>0.617146</td>\n",
       "      <td>0.439938</td>\n",
       "      <td>0.352614</td>\n",
       "      <td>0.415694</td>\n",
       "      <td>0.337067</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142798</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.997494</td>\n",
       "      <td>0.616828</td>\n",
       "      <td>0.441921</td>\n",
       "      <td>0.358093</td>\n",
       "      <td>0.419774</td>\n",
       "      <td>0.344742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142799</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.616509</td>\n",
       "      <td>0.443904</td>\n",
       "      <td>0.363573</td>\n",
       "      <td>0.423853</td>\n",
       "      <td>0.352417</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142800 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp  sex       age       BMI         A  \\\n",
       "0             1      Yes          0  0.0  0.225806  0.398781  0.000000   \n",
       "1             1      Yes          1  0.0  0.225806  0.398781  0.002506   \n",
       "2             1      Yes          2  0.0  0.225806  0.398781  0.005013   \n",
       "3             1      Yes          3  0.0  0.225806  0.398781  0.007519   \n",
       "4             1      Yes          4  0.0  0.225806  0.398781  0.010025   \n",
       "...         ...      ...        ...  ...       ...       ...       ...   \n",
       "142795      357      Yes        395  0.0  0.129032  0.460572  0.989975   \n",
       "142796      357      Yes        396  0.0  0.129032  0.460572  0.992481   \n",
       "142797      357      Yes        397  0.0  0.129032  0.460572  0.994987   \n",
       "142798      357      Yes        398  0.0  0.129032  0.460572  0.997494   \n",
       "142799      357      Yes        399  0.0  0.129032  0.460572  1.000000   \n",
       "\n",
       "               B         C         X         Y         Z  activityEncode  \n",
       "0       0.433618  0.712609  0.423799  0.650296  0.335294               1  \n",
       "1       0.436683  0.707362  0.421885  0.645632  0.329743               1  \n",
       "2       0.436506  0.704784  0.422871  0.642997  0.330805               1  \n",
       "3       0.436984  0.692951  0.416241  0.633544  0.327147               1  \n",
       "4       0.440639  0.685113  0.416307  0.627614  0.326516               1  \n",
       "...          ...       ...       ...       ...       ...             ...  \n",
       "142795  0.658435  0.400242  0.321626  0.344084  0.292085               1  \n",
       "142796  0.634904  0.427078  0.335476  0.393726  0.316480               1  \n",
       "142797  0.617146  0.439938  0.352614  0.415694  0.337067               1  \n",
       "142798  0.616828  0.441921  0.358093  0.419774  0.344742               1  \n",
       "142799  0.616509  0.443904  0.363573  0.423853  0.352417               1  \n",
       "\n",
       "[142800 rows x 13 columns]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "7b783875",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_PERIOD = 80\n",
    "STEP_DISTANCE = 40\n",
    "LABEL = 'activityEncode'\n",
    "\n",
    "df1=df[df['user-id']>70]\n",
    "df2=df[df['user-id']>140]\n",
    "df3=df[df['user-id']>210]\n",
    "df4=df[df['user-id']>280]\n",
    "\n",
    "a1=df.shape[0]\n",
    "b2=df1.shape[0]\n",
    "c3=df2.shape[0]\n",
    "d4=df3.shape[0]\n",
    "e5=df4.shape[0]\n",
    "\n",
    "df_test0 = df.iloc[0:a1-b2,:]\n",
    "df_train0 = df.iloc[a1-b2:a1,:]\n",
    "x_train0, y_train0 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test0, y_test0 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train0.shape[1], x_train0.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train0 = x_train0.reshape(x_train0.shape[0], input_shape)\n",
    "x_train0 = x_train0.astype('float32')\n",
    "y_train0=np.asarray(y_train0).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test0.shape[1], x_test0.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test0 = x_test0.reshape(x_test0.shape[0], input_shape)\n",
    "x_test0 = x_test0.astype('float32')\n",
    "y_test0=np.asarray(y_test0).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test1 = df.iloc[a1-b2:a1-c3,:]\n",
    "df_train1 = pd.concat([df_test0,df.iloc[a1-c3:a1,]])\n",
    "x_train1, y_train1 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test1, y_test1 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train1.shape[1], x_train1.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train1 = x_train1.reshape(x_train1.shape[0], input_shape)\n",
    "x_train1 = x_train1.astype('float32')\n",
    "y_train1=np.asarray(y_train1).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test1.shape[1], x_test1.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test1 = x_test1.reshape(x_test1.shape[0], input_shape)\n",
    "x_test1 = x_test1.astype('float32')\n",
    "y_test1=np.asarray(y_test1).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test2 = df.iloc[a1-c3:a1-d4,:]\n",
    "df_train2 = pd.concat([df.iloc[0:a1-c3,:],df.iloc[a1-d4:a1,]])\n",
    "x_train2, y_train2 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test2, y_test2 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train2.shape[1], x_train2.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train2 = x_train2.reshape(x_train2.shape[0], input_shape)\n",
    "x_train2 = x_train2.astype('float32')\n",
    "y_train2=np.asarray(y_train2).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test2.shape[1], x_test2.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test2 = x_test2.reshape(x_test2.shape[0], input_shape)\n",
    "x_test2 = x_test2.astype('float32')\n",
    "y_test2=np.asarray(y_test2).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test3 = df.iloc[a1-d4:a1-e5,:]\n",
    "df_train3 = pd.concat([df.iloc[0:a1-d4,:],df.iloc[a1-e5:a1,]])\n",
    "x_train3, y_train3 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test3, y_test3 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train3.shape[1], x_train3.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train3 = x_train3.reshape(x_train3.shape[0], input_shape)\n",
    "x_train3 = x_train3.astype('float32')\n",
    "y_train3=np.asarray(y_train3).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test3.shape[1], x_test3.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test3 = x_test3.reshape(x_test3.shape[0], input_shape)\n",
    "x_test3 = x_test3.astype('float32')\n",
    "y_test3=np.asarray(y_test3).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test4 = df.iloc[a1-e5:a1,:]\n",
    "df_train4 = df.iloc[0:a1-e5,:]\n",
    "x_train4, y_train4 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test4, y_test4 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train4.shape[1], x_train4.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train4 = x_train4.reshape(x_train4.shape[0], input_shape)\n",
    "x_train4 = x_train4.astype('float32')\n",
    "y_train4=np.asarray(y_train4).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test4.shape[1], x_test4.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test4 = x_test4.reshape(x_test4.shape[0], input_shape)\n",
    "x_test4 = x_test4.astype('float32')\n",
    "y_test4=np.asarray(y_test4).astype('float32').reshape((-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "40c9e344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_96\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_192 (LSTM)             (None, 720, 32)           4352      \n",
      "                                                                 \n",
      " lstm_193 (LSTM)             (None, 720, 32)           8320      \n",
      "                                                                 \n",
      " reshape_288 (Reshape)       (None, 1, 720, 32)        0         \n",
      "                                                                 \n",
      " conv1d_192 (Conv1D)         (None, 1, 360, 64)        4160      \n",
      "                                                                 \n",
      " reshape_289 (Reshape)       (None, 360, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d_96 (MaxPoolin  (None, 90, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_193 (Conv1D)         (None, 89, 192)           24768     \n",
      "                                                                 \n",
      " reshape_290 (Reshape)       (None, 89, 192)           0         \n",
      "                                                                 \n",
      " global_average_pooling1d_96  (None, 192)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " batch_normalization_96 (Bat  (None, 192)              768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_96 (Dense)            (None, 1)                 193       \n",
      "                                                                 \n",
      " activation_96 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,561\n",
      "Trainable params: 42,177\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model.add(Reshape((1, 720, 32)))\n",
    "model.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model.add(Reshape((360, 64)))\n",
    "model.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model.add(Reshape((89, 192)))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(BatchNormalization(epsilon=1e-06))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "f1538a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_metric(optimizer):  # printing the value of the learning rate\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "def step_decay(epoch):\n",
    "\tinitial_lrate = 0.0001\n",
    "\tdrop = 0.5\n",
    "\tepochs_drop = 5.0\n",
    "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lrate\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "sgd = SGD(lr=0.0, momentum=0.9, decay=0.0, nesterov=False)\n",
    "adam=optimizers.Adam(lr=0.00013, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=False)\n",
    "#lr_metric = get_lr_metric(adam)\n",
    "lr_metric = get_lr_metric(adam)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "model1 = Sequential()\n",
    "model1.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model1.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model1.add(Reshape((1, 720, 32)))\n",
    "model1.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model1.add(Reshape((360, 64)))\n",
    "model1.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model1.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model1.add(Reshape((89, 192)))\n",
    "model1.add(GlobalAveragePooling1D())\n",
    "model1.add(BatchNormalization(epsilon=1e-06))\n",
    "model1.add(Dense(1))\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model2.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model2.add(Reshape((1, 720, 32)))\n",
    "model2.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model2.add(Reshape((360, 64)))\n",
    "model2.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model2.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model2.add(Reshape((89, 192)))\n",
    "model2.add(GlobalAveragePooling1D())\n",
    "model2.add(BatchNormalization(epsilon=1e-06))\n",
    "model2.add(Dense(1))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model3.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model3.add(Reshape((1, 720, 32)))\n",
    "model3.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model3.add(Reshape((360, 64)))\n",
    "model3.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model3.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model3.add(Reshape((89, 192)))\n",
    "model3.add(GlobalAveragePooling1D())\n",
    "model3.add(BatchNormalization(epsilon=1e-06))\n",
    "model3.add(Dense(1))\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model4.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model4.add(Reshape((1, 720, 32)))\n",
    "model4.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model4.add(Reshape((360, 64)))\n",
    "model4.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model4.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model4.add(Reshape((89, 192)))\n",
    "model4.add(GlobalAveragePooling1D())\n",
    "model4.add(BatchNormalization(epsilon=1e-06))\n",
    "model4.add(Dense(1))\n",
    "model4.add(Activation('sigmoid'))\n",
    "model4.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model5.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model5.add(Reshape((1, 720, 32)))\n",
    "model5.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model5.add(Reshape((360, 64)))\n",
    "model5.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model5.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model5.add(Reshape((89, 192)))\n",
    "model5.add(GlobalAveragePooling1D())\n",
    "model5.add(BatchNormalization(epsilon=1e-06))\n",
    "model5.add(Dense(1))\n",
    "model5.add(Activation('sigmoid'))\n",
    "model5.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "2047136b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 11s 328ms/step - loss: 0.6388 - accuracy: 0.6363 - lr: 1.3000e-04\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.5812 - accuracy: 0.6970 - lr: 1.3000e-04\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.5434 - accuracy: 0.7326 - lr: 1.3000e-04\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.5176 - accuracy: 0.7556 - lr: 1.3000e-04\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.4965 - accuracy: 0.7632 - lr: 1.3000e-04\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.4743 - accuracy: 0.7765 - lr: 1.3000e-04\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.4554 - accuracy: 0.7901 - lr: 1.3000e-04\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 9s 315ms/step - loss: 0.4392 - accuracy: 0.8054 - lr: 1.3000e-04\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.4232 - accuracy: 0.8128 - lr: 1.3000e-04\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.4120 - accuracy: 0.8173 - lr: 1.3000e-04\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.4003 - accuracy: 0.8197 - lr: 1.3000e-04\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.3901 - accuracy: 0.8285 - lr: 1.3000e-04\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.3778 - accuracy: 0.8389 - lr: 1.3000e-04\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.3734 - accuracy: 0.8358 - lr: 1.3000e-04\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.3694 - accuracy: 0.8400 - lr: 1.3000e-04\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 9s 310ms/step - loss: 0.3574 - accuracy: 0.8490 - lr: 1.3000e-04\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.3624 - accuracy: 0.8452 - lr: 1.3000e-04\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.3514 - accuracy: 0.8525 - lr: 1.3000e-04\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 9s 310ms/step - loss: 0.3504 - accuracy: 0.8501 - lr: 1.3000e-04\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.3433 - accuracy: 0.8612 - lr: 1.3000e-04\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.3426 - accuracy: 0.8560 - lr: 1.3000e-04\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.3310 - accuracy: 0.8647 - lr: 1.3000e-04\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.3291 - accuracy: 0.8588 - lr: 1.3000e-04\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.3255 - accuracy: 0.8647 - lr: 1.3000e-04\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.3236 - accuracy: 0.8584 - lr: 1.3000e-04\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.3194 - accuracy: 0.8699 - lr: 1.3000e-04\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.3147 - accuracy: 0.8679 - lr: 1.3000e-04\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.3130 - accuracy: 0.8699 - lr: 1.3000e-04\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.3133 - accuracy: 0.8672 - lr: 1.3000e-04\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.3097 - accuracy: 0.8675 - lr: 1.3000e-04\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.3053 - accuracy: 0.8741 - lr: 1.3000e-04\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.3080 - accuracy: 0.8696 - lr: 1.3000e-04\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 9s 310ms/step - loss: 0.2982 - accuracy: 0.8780 - lr: 1.3000e-04\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.3006 - accuracy: 0.8717 - lr: 1.3000e-04\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 9s 310ms/step - loss: 0.2979 - accuracy: 0.8731 - lr: 1.3000e-04\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.3022 - accuracy: 0.8713 - lr: 1.3000e-04\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.3021 - accuracy: 0.8710 - lr: 1.3000e-04\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.2987 - accuracy: 0.8769 - lr: 1.3000e-04\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.3012 - accuracy: 0.8710 - lr: 1.3000e-04\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.2890 - accuracy: 0.8835 - lr: 1.3000e-04\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.2930 - accuracy: 0.8731 - lr: 1.3000e-04\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2902 - accuracy: 0.8776 - lr: 1.3000e-04\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 9s 315ms/step - loss: 0.2831 - accuracy: 0.8863 - lr: 1.3000e-04\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.2902 - accuracy: 0.8727 - lr: 1.3000e-04\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2888 - accuracy: 0.8811 - lr: 1.3000e-04\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.2845 - accuracy: 0.8776 - lr: 1.3000e-04\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2814 - accuracy: 0.8832 - lr: 1.3000e-04\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 9s 315ms/step - loss: 0.2790 - accuracy: 0.8846 - lr: 1.3000e-04\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2810 - accuracy: 0.8797 - lr: 1.3000e-04\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 9s 315ms/step - loss: 0.2787 - accuracy: 0.8821 - lr: 1.3000e-04\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2749 - accuracy: 0.8821 - lr: 1.3000e-04\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 9s 315ms/step - loss: 0.2797 - accuracy: 0.8842 - lr: 1.3000e-04\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2814 - accuracy: 0.8787 - lr: 1.3000e-04\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.2771 - accuracy: 0.8821 - lr: 1.3000e-04\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 9s 315ms/step - loss: 0.2695 - accuracy: 0.8867 - lr: 1.3000e-04\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.2782 - accuracy: 0.8794 - lr: 1.3000e-04\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 9s 315ms/step - loss: 0.2700 - accuracy: 0.8874 - lr: 1.3000e-04\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2750 - accuracy: 0.8856 - lr: 1.3000e-04\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.2771 - accuracy: 0.8839 - lr: 1.3000e-04\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 9s 310ms/step - loss: 0.2714 - accuracy: 0.8905 - lr: 1.3000e-04\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2699 - accuracy: 0.8846 - lr: 1.3000e-04\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.2753 - accuracy: 0.8811 - lr: 1.3000e-04\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2798 - accuracy: 0.8776 - lr: 1.3000e-04\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2733 - accuracy: 0.8828 - lr: 1.3000e-04\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.2644 - accuracy: 0.8891 - lr: 1.3000e-04\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.2695 - accuracy: 0.8853 - lr: 1.3000e-04\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 9s 310ms/step - loss: 0.2781 - accuracy: 0.8776 - lr: 1.3000e-04\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2753 - accuracy: 0.8766 - lr: 1.3000e-04\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.2700 - accuracy: 0.8790 - lr: 1.3000e-04\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2651 - accuracy: 0.8815 - lr: 1.3000e-04\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.2730 - accuracy: 0.8808 - lr: 1.3000e-04\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 9s 309ms/step - loss: 0.2716 - accuracy: 0.8832 - lr: 1.3000e-04\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.2679 - accuracy: 0.8870 - lr: 1.3000e-04\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 9s 309ms/step - loss: 0.2627 - accuracy: 0.8898 - lr: 1.3000e-04\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.2641 - accuracy: 0.8842 - lr: 1.3000e-04\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 9s 309ms/step - loss: 0.2620 - accuracy: 0.8912 - lr: 1.3000e-04\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 9s 310ms/step - loss: 0.2658 - accuracy: 0.8860 - lr: 1.3000e-04\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 9s 309ms/step - loss: 0.2600 - accuracy: 0.8916 - lr: 1.3000e-04\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 9s 310ms/step - loss: 0.2681 - accuracy: 0.8867 - lr: 1.3000e-04\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 9s 310ms/step - loss: 0.2567 - accuracy: 0.8881 - lr: 1.3000e-04\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 9s 308ms/step - loss: 0.2593 - accuracy: 0.8957 - lr: 1.3000e-04\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.2617 - accuracy: 0.8919 - lr: 1.3000e-04\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 9s 308ms/step - loss: 0.2719 - accuracy: 0.8860 - lr: 1.3000e-04\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2589 - accuracy: 0.8944 - lr: 1.3000e-04\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 9s 308ms/step - loss: 0.2583 - accuracy: 0.8884 - lr: 1.3000e-04\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 9s 310ms/step - loss: 0.2572 - accuracy: 0.8954 - lr: 1.3000e-04\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 9s 310ms/step - loss: 0.2589 - accuracy: 0.8909 - lr: 1.3000e-04\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 9s 308ms/step - loss: 0.2574 - accuracy: 0.8940 - lr: 1.3000e-04\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 9s 309ms/step - loss: 0.2562 - accuracy: 0.8884 - lr: 1.3000e-04\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 9s 308ms/step - loss: 0.2725 - accuracy: 0.8808 - lr: 1.3000e-04\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 9s 309ms/step - loss: 0.2550 - accuracy: 0.8933 - lr: 1.3000e-04\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 9s 307ms/step - loss: 0.2618 - accuracy: 0.8863 - lr: 1.3000e-04\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.2597 - accuracy: 0.8905 - lr: 1.3000e-04\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 9s 308ms/step - loss: 0.2556 - accuracy: 0.8902 - lr: 1.3000e-04\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 9s 308ms/step - loss: 0.2510 - accuracy: 0.8982 - lr: 1.3000e-04\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 9s 309ms/step - loss: 0.2571 - accuracy: 0.8919 - lr: 1.3000e-04\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 9s 308ms/step - loss: 0.2562 - accuracy: 0.8923 - lr: 1.3000e-04\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 9s 310ms/step - loss: 0.2562 - accuracy: 0.8933 - lr: 1.3000e-04\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 9s 307ms/step - loss: 0.2564 - accuracy: 0.8937 - lr: 1.3000e-04\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.2542 - accuracy: 0.8954 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 49ms/step - loss: 0.6708 - accuracy: 0.7607 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 50ms/step\n",
      "22/22 [==============================] - 1s 50ms/step\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 10s 304ms/step - loss: 0.5974 - accuracy: 0.6684 - lr: 1.3000e-04\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.4925 - accuracy: 0.7636 - lr: 1.3000e-04\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.4476 - accuracy: 0.7873 - lr: 1.3000e-04\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.4309 - accuracy: 0.7939 - lr: 1.3000e-04\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.4153 - accuracy: 0.7974 - lr: 1.3000e-04\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.3974 - accuracy: 0.8149 - lr: 1.3000e-04\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.3904 - accuracy: 0.8187 - lr: 1.3000e-04\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.3847 - accuracy: 0.8201 - lr: 1.3000e-04\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.3753 - accuracy: 0.8305 - lr: 1.3000e-04\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 9s 304ms/step - loss: 0.3624 - accuracy: 0.8319 - lr: 1.3000e-04\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.3589 - accuracy: 0.8347 - lr: 1.3000e-04\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 9s 306ms/step - loss: 0.3518 - accuracy: 0.8438 - lr: 1.3000e-04\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.3442 - accuracy: 0.8462 - lr: 1.3000e-04\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 9s 306ms/step - loss: 0.3406 - accuracy: 0.8525 - lr: 1.3000e-04\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.3397 - accuracy: 0.8459 - lr: 1.3000e-04\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 9s 306ms/step - loss: 0.3242 - accuracy: 0.8658 - lr: 1.3000e-04\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.3238 - accuracy: 0.8546 - lr: 1.3000e-04\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.3192 - accuracy: 0.8626 - lr: 1.3000e-04\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 9s 306ms/step - loss: 0.3080 - accuracy: 0.8665 - lr: 1.3000e-04\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.3047 - accuracy: 0.8696 - lr: 1.3000e-04\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 9s 304ms/step - loss: 0.3079 - accuracy: 0.8713 - lr: 1.3000e-04\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.3068 - accuracy: 0.8699 - lr: 1.3000e-04\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.3016 - accuracy: 0.8699 - lr: 1.3000e-04\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.3007 - accuracy: 0.8710 - lr: 1.3000e-04\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 9s 307ms/step - loss: 0.2925 - accuracy: 0.8766 - lr: 1.3000e-04\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.2885 - accuracy: 0.8780 - lr: 1.3000e-04\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.2869 - accuracy: 0.8755 - lr: 1.3000e-04\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 9s 306ms/step - loss: 0.2940 - accuracy: 0.8741 - lr: 1.3000e-04\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.2811 - accuracy: 0.8815 - lr: 1.3000e-04\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 9s 307ms/step - loss: 0.2838 - accuracy: 0.8790 - lr: 1.3000e-04\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.2760 - accuracy: 0.8846 - lr: 1.3000e-04\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.2871 - accuracy: 0.8727 - lr: 1.3000e-04\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.2800 - accuracy: 0.8794 - lr: 1.3000e-04\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 9s 304ms/step - loss: 0.2757 - accuracy: 0.8832 - lr: 1.3000e-04\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.2749 - accuracy: 0.8863 - lr: 1.3000e-04\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 9s 304ms/step - loss: 0.2745 - accuracy: 0.8797 - lr: 1.3000e-04\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 9s 307ms/step - loss: 0.2825 - accuracy: 0.8769 - lr: 1.3000e-04\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.2765 - accuracy: 0.8825 - lr: 1.3000e-04\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.2690 - accuracy: 0.8877 - lr: 1.3000e-04\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.2646 - accuracy: 0.8905 - lr: 1.3000e-04\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 9s 304ms/step - loss: 0.2708 - accuracy: 0.8849 - lr: 1.3000e-04\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.2657 - accuracy: 0.8912 - lr: 1.3000e-04\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 9s 304ms/step - loss: 0.2693 - accuracy: 0.8905 - lr: 1.3000e-04\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.2682 - accuracy: 0.8916 - lr: 1.3000e-04\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.2688 - accuracy: 0.8849 - lr: 1.3000e-04\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.2646 - accuracy: 0.8888 - lr: 1.3000e-04\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.2643 - accuracy: 0.8957 - lr: 1.3000e-04\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.2774 - accuracy: 0.8783 - lr: 1.3000e-04\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2720 - accuracy: 0.8804 - lr: 1.3000e-04\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.2636 - accuracy: 0.8891 - lr: 1.3000e-04\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.2698 - accuracy: 0.8839 - lr: 1.3000e-04\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.2644 - accuracy: 0.8832 - lr: 1.3000e-04\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.2680 - accuracy: 0.8923 - lr: 1.3000e-04\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 9s 304ms/step - loss: 0.2631 - accuracy: 0.8874 - lr: 1.3000e-04\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2591 - accuracy: 0.8971 - lr: 1.3000e-04\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.2641 - accuracy: 0.8874 - lr: 1.3000e-04\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.2557 - accuracy: 0.8923 - lr: 1.3000e-04\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.2594 - accuracy: 0.8916 - lr: 1.3000e-04\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.2646 - accuracy: 0.8860 - lr: 1.3000e-04\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.2603 - accuracy: 0.8919 - lr: 1.3000e-04\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.2576 - accuracy: 0.8975 - lr: 1.3000e-04\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.2547 - accuracy: 0.8937 - lr: 1.3000e-04\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.2518 - accuracy: 0.9003 - lr: 1.3000e-04\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2536 - accuracy: 0.8954 - lr: 1.3000e-04\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.2527 - accuracy: 0.8954 - lr: 1.3000e-04\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.2515 - accuracy: 0.8957 - lr: 1.3000e-04\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.2565 - accuracy: 0.8954 - lr: 1.3000e-04\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2579 - accuracy: 0.8902 - lr: 1.3000e-04\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2575 - accuracy: 0.8968 - lr: 1.3000e-04\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.2572 - accuracy: 0.8870 - lr: 1.3000e-04\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.2530 - accuracy: 0.8978 - lr: 1.3000e-04\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.2581 - accuracy: 0.8947 - lr: 1.3000e-04\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.2636 - accuracy: 0.8902 - lr: 1.3000e-04\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.2490 - accuracy: 0.8930 - lr: 1.3000e-04\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.2594 - accuracy: 0.8846 - lr: 1.3000e-04\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.2490 - accuracy: 0.8971 - lr: 1.3000e-04\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.2460 - accuracy: 0.8971 - lr: 1.3000e-04\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.2581 - accuracy: 0.8909 - lr: 1.3000e-04\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.2481 - accuracy: 0.8957 - lr: 1.3000e-04\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.2488 - accuracy: 0.8944 - lr: 1.3000e-04\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.2508 - accuracy: 0.8975 - lr: 1.3000e-04\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.2480 - accuracy: 0.9003 - lr: 1.3000e-04\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.2512 - accuracy: 0.8909 - lr: 1.3000e-04\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.2527 - accuracy: 0.8954 - lr: 1.3000e-04\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2533 - accuracy: 0.8950 - lr: 1.3000e-04\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.2518 - accuracy: 0.8964 - lr: 1.3000e-04\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.2528 - accuracy: 0.8968 - lr: 1.3000e-04\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.2541 - accuracy: 0.8944 - lr: 1.3000e-04\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.2555 - accuracy: 0.8937 - lr: 1.3000e-04\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.2530 - accuracy: 0.8916 - lr: 1.3000e-04\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2400 - accuracy: 0.9013 - lr: 1.3000e-04\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 9s 293ms/step - loss: 0.2480 - accuracy: 0.8961 - lr: 1.3000e-04\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2450 - accuracy: 0.9006 - lr: 1.3000e-04\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.2450 - accuracy: 0.8975 - lr: 1.3000e-04\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.2465 - accuracy: 0.9010 - lr: 1.3000e-04\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.2578 - accuracy: 0.8846 - lr: 1.3000e-04\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.2522 - accuracy: 0.8916 - lr: 1.3000e-04\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2452 - accuracy: 0.8937 - lr: 1.3000e-04\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.2485 - accuracy: 0.8989 - lr: 1.3000e-04\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.2482 - accuracy: 0.8954 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 51ms/step - loss: 0.1905 - accuracy: 0.9226 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 49ms/step\n",
      "22/22 [==============================] - 1s 49ms/step\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 10s 289ms/step - loss: 0.5674 - accuracy: 0.7061 - lr: 1.3000e-04\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 8s 289ms/step - loss: 0.4604 - accuracy: 0.7793 - lr: 1.3000e-04\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.4363 - accuracy: 0.7946 - lr: 1.3000e-04\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 8s 291ms/step - loss: 0.4073 - accuracy: 0.8135 - lr: 1.3000e-04\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.3833 - accuracy: 0.8222 - lr: 1.3000e-04\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.3710 - accuracy: 0.8379 - lr: 1.3000e-04\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.3718 - accuracy: 0.8281 - lr: 1.3000e-04\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.3528 - accuracy: 0.8455 - lr: 1.3000e-04\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.3522 - accuracy: 0.8448 - lr: 1.3000e-04\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.3447 - accuracy: 0.8497 - lr: 1.3000e-04\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.3550 - accuracy: 0.8389 - lr: 1.3000e-04\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 9s 293ms/step - loss: 0.3396 - accuracy: 0.8483 - lr: 1.3000e-04\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.3268 - accuracy: 0.8623 - lr: 1.3000e-04\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.3245 - accuracy: 0.8543 - lr: 1.3000e-04\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.3262 - accuracy: 0.8550 - lr: 1.3000e-04\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.3271 - accuracy: 0.8595 - lr: 1.3000e-04\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 9s 294ms/step - loss: 0.3177 - accuracy: 0.8591 - lr: 1.3000e-04\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.3111 - accuracy: 0.8658 - lr: 1.3000e-04\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.3176 - accuracy: 0.8570 - lr: 1.3000e-04\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.3060 - accuracy: 0.8696 - lr: 1.3000e-04\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.3006 - accuracy: 0.8731 - lr: 1.3000e-04\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.3068 - accuracy: 0.8644 - lr: 1.3000e-04\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 8s 292ms/step - loss: 0.2942 - accuracy: 0.8741 - lr: 1.3000e-04\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.3033 - accuracy: 0.8727 - lr: 1.3000e-04\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.2984 - accuracy: 0.8692 - lr: 1.3000e-04\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.2976 - accuracy: 0.8731 - lr: 1.3000e-04\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2960 - accuracy: 0.8738 - lr: 1.3000e-04\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.2993 - accuracy: 0.8703 - lr: 1.3000e-04\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2861 - accuracy: 0.8762 - lr: 1.3000e-04\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.2916 - accuracy: 0.8703 - lr: 1.3000e-04\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.2798 - accuracy: 0.8821 - lr: 1.3000e-04\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.2849 - accuracy: 0.8839 - lr: 1.3000e-04\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.3126 - accuracy: 0.8637 - lr: 1.3000e-04\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.2877 - accuracy: 0.8745 - lr: 1.3000e-04\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.2783 - accuracy: 0.8888 - lr: 1.3000e-04\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.2843 - accuracy: 0.8762 - lr: 1.3000e-04\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2841 - accuracy: 0.8776 - lr: 1.3000e-04\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.2825 - accuracy: 0.8776 - lr: 1.3000e-04\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.2820 - accuracy: 0.8699 - lr: 1.3000e-04\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2770 - accuracy: 0.8821 - lr: 1.3000e-04\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2790 - accuracy: 0.8804 - lr: 1.3000e-04\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.2745 - accuracy: 0.8867 - lr: 1.3000e-04\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.2843 - accuracy: 0.8811 - lr: 1.3000e-04\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.2798 - accuracy: 0.8790 - lr: 1.3000e-04\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2786 - accuracy: 0.8815 - lr: 1.3000e-04\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.2689 - accuracy: 0.8821 - lr: 1.3000e-04\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.2795 - accuracy: 0.8776 - lr: 1.3000e-04\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.2864 - accuracy: 0.8787 - lr: 1.3000e-04\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.2927 - accuracy: 0.8752 - lr: 1.3000e-04\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2786 - accuracy: 0.8783 - lr: 1.3000e-04\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.2735 - accuracy: 0.8808 - lr: 1.3000e-04\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.2712 - accuracy: 0.8863 - lr: 1.3000e-04\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2699 - accuracy: 0.8835 - lr: 1.3000e-04\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 9s 293ms/step - loss: 0.2690 - accuracy: 0.8842 - lr: 1.3000e-04\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.2755 - accuracy: 0.8821 - lr: 1.3000e-04\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 9s 293ms/step - loss: 0.2792 - accuracy: 0.8776 - lr: 1.3000e-04\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.2680 - accuracy: 0.8881 - lr: 1.3000e-04\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.2679 - accuracy: 0.8870 - lr: 1.3000e-04\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.2749 - accuracy: 0.8773 - lr: 1.3000e-04\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 9s 295ms/step - loss: 0.2748 - accuracy: 0.8783 - lr: 1.3000e-04\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.2634 - accuracy: 0.8867 - lr: 1.3000e-04\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.2682 - accuracy: 0.8846 - lr: 1.3000e-04\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.2645 - accuracy: 0.8902 - lr: 1.3000e-04\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.2664 - accuracy: 0.8863 - lr: 1.3000e-04\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.2624 - accuracy: 0.8853 - lr: 1.3000e-04\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2658 - accuracy: 0.8881 - lr: 1.3000e-04\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.2662 - accuracy: 0.8898 - lr: 1.3000e-04\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2660 - accuracy: 0.8895 - lr: 1.3000e-04\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.2632 - accuracy: 0.8856 - lr: 1.3000e-04\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 9s 327ms/step - loss: 0.2663 - accuracy: 0.8825 - lr: 1.3000e-04\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 9s 320ms/step - loss: 0.2674 - accuracy: 0.8835 - lr: 1.3000e-04\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 10s 329ms/step - loss: 0.2671 - accuracy: 0.8846 - lr: 1.3000e-04\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 12s 423ms/step - loss: 0.2607 - accuracy: 0.8895 - lr: 1.3000e-04\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 10s 338ms/step - loss: 0.2613 - accuracy: 0.8863 - lr: 1.3000e-04\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 10s 333ms/step - loss: 0.2682 - accuracy: 0.8884 - lr: 1.3000e-04\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 9s 327ms/step - loss: 0.2670 - accuracy: 0.8832 - lr: 1.3000e-04\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 10s 342ms/step - loss: 0.2631 - accuracy: 0.8916 - lr: 1.3000e-04\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 9s 324ms/step - loss: 0.2689 - accuracy: 0.8856 - lr: 1.3000e-04\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 10s 329ms/step - loss: 0.2619 - accuracy: 0.8888 - lr: 1.3000e-04\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 10s 345ms/step - loss: 0.2628 - accuracy: 0.8808 - lr: 1.3000e-04\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 10s 337ms/step - loss: 0.2562 - accuracy: 0.8944 - lr: 1.3000e-04\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 10s 350ms/step - loss: 0.2580 - accuracy: 0.8930 - lr: 1.3000e-04\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 9s 326ms/step - loss: 0.2613 - accuracy: 0.8870 - lr: 1.3000e-04\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 9s 317ms/step - loss: 0.2626 - accuracy: 0.8853 - lr: 1.3000e-04\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 9s 325ms/step - loss: 0.2607 - accuracy: 0.8912 - lr: 1.3000e-04\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.2539 - accuracy: 0.8916 - lr: 1.3000e-04\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.2565 - accuracy: 0.8930 - lr: 1.3000e-04\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 9s 325ms/step - loss: 0.2563 - accuracy: 0.8898 - lr: 1.3000e-04\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.2584 - accuracy: 0.8909 - lr: 1.3000e-04\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.2542 - accuracy: 0.8916 - lr: 1.3000e-04\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 9s 298ms/step - loss: 0.2544 - accuracy: 0.8975 - lr: 1.3000e-04\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.2636 - accuracy: 0.8898 - lr: 1.3000e-04\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.2563 - accuracy: 0.8964 - lr: 1.3000e-04\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 9s 300ms/step - loss: 0.2665 - accuracy: 0.8808 - lr: 1.3000e-04\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 9s 297ms/step - loss: 0.2528 - accuracy: 0.8954 - lr: 1.3000e-04\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.2524 - accuracy: 0.8940 - lr: 1.3000e-04\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.2645 - accuracy: 0.8888 - lr: 1.3000e-04\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 9s 299ms/step - loss: 0.2567 - accuracy: 0.8891 - lr: 1.3000e-04\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.2517 - accuracy: 0.8937 - lr: 1.3000e-04\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 9s 296ms/step - loss: 0.2545 - accuracy: 0.8940 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 51ms/step - loss: 0.1841 - accuracy: 0.9226 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 49ms/step\n",
      "22/22 [==============================] - 1s 51ms/step\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 12s 345ms/step - loss: 0.5677 - accuracy: 0.7026 - lr: 1.3000e-04\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 10s 347ms/step - loss: 0.4689 - accuracy: 0.7779 - lr: 1.3000e-04\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 10s 345ms/step - loss: 0.4234 - accuracy: 0.8040 - lr: 1.3000e-04\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 10s 345ms/step - loss: 0.4105 - accuracy: 0.8082 - lr: 1.3000e-04\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 10s 346ms/step - loss: 0.3874 - accuracy: 0.8176 - lr: 1.3000e-04\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 10s 344ms/step - loss: 0.3881 - accuracy: 0.8166 - lr: 1.3000e-04\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 10s 346ms/step - loss: 0.3730 - accuracy: 0.8298 - lr: 1.3000e-04\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 10s 346ms/step - loss: 0.3707 - accuracy: 0.8260 - lr: 1.3000e-04\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 10s 344ms/step - loss: 0.3615 - accuracy: 0.8340 - lr: 1.3000e-04\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 10s 347ms/step - loss: 0.3554 - accuracy: 0.8407 - lr: 1.3000e-04\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 10s 345ms/step - loss: 0.3523 - accuracy: 0.8445 - lr: 1.3000e-04\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 10s 346ms/step - loss: 0.3310 - accuracy: 0.8588 - lr: 1.3000e-04\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 10s 347ms/step - loss: 0.3296 - accuracy: 0.8536 - lr: 1.3000e-04\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 10s 345ms/step - loss: 0.3278 - accuracy: 0.8518 - lr: 1.3000e-04\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 10s 347ms/step - loss: 0.3285 - accuracy: 0.8577 - lr: 1.3000e-04\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 10s 346ms/step - loss: 0.3086 - accuracy: 0.8685 - lr: 1.3000e-04\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 10s 345ms/step - loss: 0.3066 - accuracy: 0.8640 - lr: 1.3000e-04\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 10s 346ms/step - loss: 0.3040 - accuracy: 0.8644 - lr: 1.3000e-04\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 10s 344ms/step - loss: 0.2961 - accuracy: 0.8672 - lr: 1.3000e-04\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 10s 346ms/step - loss: 0.2962 - accuracy: 0.8689 - lr: 1.3000e-04\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 10s 347ms/step - loss: 0.2894 - accuracy: 0.8769 - lr: 1.3000e-04\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 10s 344ms/step - loss: 0.2898 - accuracy: 0.8748 - lr: 1.3000e-04\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 10s 346ms/step - loss: 0.2877 - accuracy: 0.8713 - lr: 1.3000e-04\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 10s 346ms/step - loss: 0.2822 - accuracy: 0.8759 - lr: 1.3000e-04\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 10s 345ms/step - loss: 0.2837 - accuracy: 0.8780 - lr: 1.3000e-04\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 10s 347ms/step - loss: 0.2834 - accuracy: 0.8759 - lr: 1.3000e-04\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 10s 345ms/step - loss: 0.2824 - accuracy: 0.8748 - lr: 1.3000e-04\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 10s 345ms/step - loss: 0.2756 - accuracy: 0.8811 - lr: 1.3000e-04\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 10s 346ms/step - loss: 0.2725 - accuracy: 0.8849 - lr: 1.3000e-04\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 10s 345ms/step - loss: 0.2633 - accuracy: 0.8884 - lr: 1.3000e-04\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 10s 346ms/step - loss: 0.2735 - accuracy: 0.8804 - lr: 1.3000e-04\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 10s 344ms/step - loss: 0.2666 - accuracy: 0.8926 - lr: 1.3000e-04\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 10s 343ms/step - loss: 0.2692 - accuracy: 0.8863 - lr: 1.3000e-04\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 10s 345ms/step - loss: 0.2739 - accuracy: 0.8828 - lr: 1.3000e-04\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 10s 343ms/step - loss: 0.2640 - accuracy: 0.8870 - lr: 1.3000e-04\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 10s 344ms/step - loss: 0.2727 - accuracy: 0.8842 - lr: 1.3000e-04\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 10s 344ms/step - loss: 0.2665 - accuracy: 0.8877 - lr: 1.3000e-04\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 10s 342ms/step - loss: 0.2640 - accuracy: 0.8891 - lr: 1.3000e-04\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 10s 344ms/step - loss: 0.2731 - accuracy: 0.8828 - lr: 1.3000e-04\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 10s 343ms/step - loss: 0.2643 - accuracy: 0.8860 - lr: 1.3000e-04\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 10s 341ms/step - loss: 0.2603 - accuracy: 0.8902 - lr: 1.3000e-04\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 10s 342ms/step - loss: 0.2599 - accuracy: 0.8888 - lr: 1.3000e-04\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 10s 342ms/step - loss: 0.2580 - accuracy: 0.8923 - lr: 1.3000e-04\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 10s 342ms/step - loss: 0.2607 - accuracy: 0.8912 - lr: 1.3000e-04\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 10s 342ms/step - loss: 0.2632 - accuracy: 0.8957 - lr: 1.3000e-04\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 10s 340ms/step - loss: 0.2569 - accuracy: 0.8940 - lr: 1.3000e-04\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 10s 342ms/step - loss: 0.2763 - accuracy: 0.8818 - lr: 1.3000e-04\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 10s 341ms/step - loss: 0.2645 - accuracy: 0.8902 - lr: 1.3000e-04\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 10s 340ms/step - loss: 0.2521 - accuracy: 0.8964 - lr: 1.3000e-04\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 10s 341ms/step - loss: 0.2526 - accuracy: 0.8912 - lr: 1.3000e-04\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 10s 341ms/step - loss: 0.2531 - accuracy: 0.8957 - lr: 1.3000e-04\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 10s 340ms/step - loss: 0.2588 - accuracy: 0.8902 - lr: 1.3000e-04\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 10s 340ms/step - loss: 0.2597 - accuracy: 0.8919 - lr: 1.3000e-04\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 10s 339ms/step - loss: 0.2549 - accuracy: 0.8881 - lr: 1.3000e-04\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 10s 342ms/step - loss: 0.2568 - accuracy: 0.8940 - lr: 1.3000e-04\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 10s 338ms/step - loss: 0.2618 - accuracy: 0.8849 - lr: 1.3000e-04\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 10s 340ms/step - loss: 0.2553 - accuracy: 0.8950 - lr: 1.3000e-04\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 10s 340ms/step - loss: 0.2489 - accuracy: 0.8919 - lr: 1.3000e-04\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 10s 339ms/step - loss: 0.2612 - accuracy: 0.8881 - lr: 1.3000e-04\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 10s 340ms/step - loss: 0.2505 - accuracy: 0.8940 - lr: 1.3000e-04\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 10s 339ms/step - loss: 0.2610 - accuracy: 0.8895 - lr: 1.3000e-04\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 10s 337ms/step - loss: 0.2599 - accuracy: 0.8916 - lr: 1.3000e-04\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 10s 339ms/step - loss: 0.2554 - accuracy: 0.8874 - lr: 1.3000e-04\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 10s 336ms/step - loss: 0.2527 - accuracy: 0.8944 - lr: 1.3000e-04\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 10s 339ms/step - loss: 0.2634 - accuracy: 0.8853 - lr: 1.3000e-04\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 10s 338ms/step - loss: 0.2449 - accuracy: 0.8992 - lr: 1.3000e-04\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 10s 335ms/step - loss: 0.2507 - accuracy: 0.8982 - lr: 1.3000e-04\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 10s 339ms/step - loss: 0.2632 - accuracy: 0.8828 - lr: 1.3000e-04\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 10s 335ms/step - loss: 0.2561 - accuracy: 0.8891 - lr: 1.3000e-04\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 10s 337ms/step - loss: 0.2425 - accuracy: 0.8926 - lr: 1.3000e-04\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 10s 338ms/step - loss: 0.2522 - accuracy: 0.8902 - lr: 1.3000e-04\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 10s 335ms/step - loss: 0.2530 - accuracy: 0.8912 - lr: 1.3000e-04\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 10s 336ms/step - loss: 0.2427 - accuracy: 0.8961 - lr: 1.3000e-04\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 10s 335ms/step - loss: 0.2498 - accuracy: 0.8989 - lr: 1.3000e-04\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 10s 335ms/step - loss: 0.2507 - accuracy: 0.8926 - lr: 1.3000e-04\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 10s 335ms/step - loss: 0.2511 - accuracy: 0.8930 - lr: 1.3000e-04\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 10s 333ms/step - loss: 0.2446 - accuracy: 0.8968 - lr: 1.3000e-04\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 10s 335ms/step - loss: 0.2450 - accuracy: 0.8985 - lr: 1.3000e-04\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 10s 334ms/step - loss: 0.2490 - accuracy: 0.8964 - lr: 1.3000e-04\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 10s 333ms/step - loss: 0.2438 - accuracy: 0.8964 - lr: 1.3000e-04\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 10s 334ms/step - loss: 0.2458 - accuracy: 0.8999 - lr: 1.3000e-04\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 10s 331ms/step - loss: 0.2432 - accuracy: 0.8989 - lr: 1.3000e-04\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 10s 333ms/step - loss: 0.2418 - accuracy: 0.8975 - lr: 1.3000e-04\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 10s 334ms/step - loss: 0.2512 - accuracy: 0.8895 - lr: 1.3000e-04\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 10s 331ms/step - loss: 0.2530 - accuracy: 0.8916 - lr: 1.3000e-04\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 10s 333ms/step - loss: 0.2462 - accuracy: 0.8933 - lr: 1.3000e-04\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 10s 331ms/step - loss: 0.2440 - accuracy: 0.8916 - lr: 1.3000e-04\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 10s 335ms/step - loss: 0.2409 - accuracy: 0.9034 - lr: 1.3000e-04\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 10s 332ms/step - loss: 0.2460 - accuracy: 0.8996 - lr: 1.3000e-04\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 10s 330ms/step - loss: 0.2387 - accuracy: 0.8996 - lr: 1.3000e-04\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 10s 330ms/step - loss: 0.2440 - accuracy: 0.9003 - lr: 1.3000e-04\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 10s 331ms/step - loss: 0.2507 - accuracy: 0.8996 - lr: 1.3000e-04\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 10s 330ms/step - loss: 0.2485 - accuracy: 0.8895 - lr: 1.3000e-04\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 10s 332ms/step - loss: 0.2544 - accuracy: 0.8912 - lr: 1.3000e-04\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 10s 330ms/step - loss: 0.2424 - accuracy: 0.8937 - lr: 1.3000e-04\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 10s 333ms/step - loss: 0.2380 - accuracy: 0.9010 - lr: 1.3000e-04\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 10s 329ms/step - loss: 0.2414 - accuracy: 0.8985 - lr: 1.3000e-04\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 10s 331ms/step - loss: 0.2429 - accuracy: 0.8978 - lr: 1.3000e-04\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 10s 330ms/step - loss: 0.2380 - accuracy: 0.9055 - lr: 1.3000e-04\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 10s 329ms/step - loss: 0.2428 - accuracy: 0.9006 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 46ms/step - loss: 0.1746 - accuracy: 0.9169 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 46ms/step\n",
      "22/22 [==============================] - 1s 46ms/step\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 10s 320ms/step - loss: 0.5698 - accuracy: 0.7022 - lr: 1.3000e-04\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 9s 319ms/step - loss: 0.4753 - accuracy: 0.7734 - lr: 1.3000e-04\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 9s 318ms/step - loss: 0.4326 - accuracy: 0.7929 - lr: 1.3000e-04\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 9s 318ms/step - loss: 0.4131 - accuracy: 0.8033 - lr: 1.3000e-04\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 9s 317ms/step - loss: 0.3972 - accuracy: 0.8128 - lr: 1.3000e-04\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 9s 319ms/step - loss: 0.3964 - accuracy: 0.8138 - lr: 1.3000e-04\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 9s 319ms/step - loss: 0.3819 - accuracy: 0.8288 - lr: 1.3000e-04\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 9s 318ms/step - loss: 0.3733 - accuracy: 0.8319 - lr: 1.3000e-04\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 9s 320ms/step - loss: 0.3679 - accuracy: 0.8410 - lr: 1.3000e-04\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 9s 317ms/step - loss: 0.3579 - accuracy: 0.8368 - lr: 1.3000e-04\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 9s 317ms/step - loss: 0.3667 - accuracy: 0.8312 - lr: 1.3000e-04\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 9s 316ms/step - loss: 0.3648 - accuracy: 0.8379 - lr: 1.3000e-04\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 9s 318ms/step - loss: 0.3505 - accuracy: 0.8483 - lr: 1.3000e-04\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 9s 319ms/step - loss: 0.3429 - accuracy: 0.8469 - lr: 1.3000e-04\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 9s 316ms/step - loss: 0.3398 - accuracy: 0.8529 - lr: 1.3000e-04\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 9s 318ms/step - loss: 0.3410 - accuracy: 0.8504 - lr: 1.3000e-04\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.3333 - accuracy: 0.8550 - lr: 1.3000e-04\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 9s 320ms/step - loss: 0.3260 - accuracy: 0.8570 - lr: 1.3000e-04\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.3207 - accuracy: 0.8574 - lr: 1.3000e-04\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 9s 315ms/step - loss: 0.3182 - accuracy: 0.8591 - lr: 1.3000e-04\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 9s 315ms/step - loss: 0.3240 - accuracy: 0.8525 - lr: 1.3000e-04\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.3119 - accuracy: 0.8623 - lr: 1.3000e-04\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 9s 315ms/step - loss: 0.3094 - accuracy: 0.8623 - lr: 1.3000e-04\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.3119 - accuracy: 0.8630 - lr: 1.3000e-04\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 9s 316ms/step - loss: 0.3004 - accuracy: 0.8706 - lr: 1.3000e-04\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.3000 - accuracy: 0.8658 - lr: 1.3000e-04\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.2939 - accuracy: 0.8703 - lr: 1.3000e-04\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.2992 - accuracy: 0.8647 - lr: 1.3000e-04\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2951 - accuracy: 0.8745 - lr: 1.3000e-04\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.2936 - accuracy: 0.8685 - lr: 1.3000e-04\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2962 - accuracy: 0.8745 - lr: 1.3000e-04\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.2944 - accuracy: 0.8703 - lr: 1.3000e-04\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.2955 - accuracy: 0.8689 - lr: 1.3000e-04\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.2926 - accuracy: 0.8679 - lr: 1.3000e-04\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.2850 - accuracy: 0.8731 - lr: 1.3000e-04\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2847 - accuracy: 0.8804 - lr: 1.3000e-04\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 9s 314ms/step - loss: 0.2875 - accuracy: 0.8717 - lr: 1.3000e-04\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.2966 - accuracy: 0.8623 - lr: 1.3000e-04\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.2917 - accuracy: 0.8720 - lr: 1.3000e-04\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 9s 310ms/step - loss: 0.2893 - accuracy: 0.8731 - lr: 1.3000e-04\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2853 - accuracy: 0.8780 - lr: 1.3000e-04\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2859 - accuracy: 0.8752 - lr: 1.3000e-04\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 9s 313ms/step - loss: 0.2873 - accuracy: 0.8762 - lr: 1.3000e-04\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 9s 315ms/step - loss: 0.2825 - accuracy: 0.8773 - lr: 1.3000e-04\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 9s 309ms/step - loss: 0.2792 - accuracy: 0.8741 - lr: 1.3000e-04\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2742 - accuracy: 0.8815 - lr: 1.3000e-04\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.2806 - accuracy: 0.8790 - lr: 1.3000e-04\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 9s 315ms/step - loss: 0.2839 - accuracy: 0.8731 - lr: 1.3000e-04\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 9s 308ms/step - loss: 0.2758 - accuracy: 0.8797 - lr: 1.3000e-04\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.2746 - accuracy: 0.8794 - lr: 1.3000e-04\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 9s 311ms/step - loss: 0.2821 - accuracy: 0.8703 - lr: 1.3000e-04\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 9s 307ms/step - loss: 0.2791 - accuracy: 0.8808 - lr: 1.3000e-04\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 9s 308ms/step - loss: 0.2789 - accuracy: 0.8783 - lr: 1.3000e-04\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 9s 307ms/step - loss: 0.2738 - accuracy: 0.8821 - lr: 1.3000e-04\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 9s 312ms/step - loss: 0.2706 - accuracy: 0.8832 - lr: 1.3000e-04\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 9s 306ms/step - loss: 0.2734 - accuracy: 0.8790 - lr: 1.3000e-04\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 9s 309ms/step - loss: 0.2773 - accuracy: 0.8808 - lr: 1.3000e-04\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 9s 307ms/step - loss: 0.2843 - accuracy: 0.8773 - lr: 1.3000e-04\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 9s 307ms/step - loss: 0.2732 - accuracy: 0.8818 - lr: 1.3000e-04\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 9s 309ms/step - loss: 0.2735 - accuracy: 0.8797 - lr: 1.3000e-04\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 9s 306ms/step - loss: 0.2818 - accuracy: 0.8727 - lr: 1.3000e-04\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 9s 309ms/step - loss: 0.2654 - accuracy: 0.8853 - lr: 1.3000e-04\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.2719 - accuracy: 0.8738 - lr: 1.3000e-04\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 9s 309ms/step - loss: 0.2705 - accuracy: 0.8881 - lr: 1.3000e-04\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.2658 - accuracy: 0.8846 - lr: 1.3000e-04\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 9s 307ms/step - loss: 0.2696 - accuracy: 0.8846 - lr: 1.3000e-04\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 9s 307ms/step - loss: 0.2719 - accuracy: 0.8769 - lr: 1.3000e-04\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.2619 - accuracy: 0.8912 - lr: 1.3000e-04\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 9s 306ms/step - loss: 0.2641 - accuracy: 0.8846 - lr: 1.3000e-04\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.2722 - accuracy: 0.8821 - lr: 1.3000e-04\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 9s 306ms/step - loss: 0.2691 - accuracy: 0.8825 - lr: 1.3000e-04\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.2603 - accuracy: 0.8860 - lr: 1.3000e-04\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 10s 341ms/step - loss: 0.2606 - accuracy: 0.8881 - lr: 1.3000e-04\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 9s 321ms/step - loss: 0.2605 - accuracy: 0.8895 - lr: 1.3000e-04\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 9s 322ms/step - loss: 0.2632 - accuracy: 0.8867 - lr: 1.3000e-04\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 9s 324ms/step - loss: 0.2653 - accuracy: 0.8888 - lr: 1.3000e-04\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 9s 326ms/step - loss: 0.2618 - accuracy: 0.8916 - lr: 1.3000e-04\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 10s 333ms/step - loss: 0.2611 - accuracy: 0.8867 - lr: 1.3000e-04\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 9s 321ms/step - loss: 0.2584 - accuracy: 0.8888 - lr: 1.3000e-04\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 9s 326ms/step - loss: 0.2573 - accuracy: 0.8891 - lr: 1.3000e-04\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 10s 330ms/step - loss: 0.2533 - accuracy: 0.8933 - lr: 1.3000e-04\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 9s 310ms/step - loss: 0.2587 - accuracy: 0.8870 - lr: 1.3000e-04\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.2607 - accuracy: 0.8940 - lr: 1.3000e-04\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.2606 - accuracy: 0.8884 - lr: 1.3000e-04\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 9s 304ms/step - loss: 0.2620 - accuracy: 0.8891 - lr: 1.3000e-04\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.2578 - accuracy: 0.8874 - lr: 1.3000e-04\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 9s 306ms/step - loss: 0.2634 - accuracy: 0.8912 - lr: 1.3000e-04\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.2543 - accuracy: 0.8905 - lr: 1.3000e-04\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.2600 - accuracy: 0.8940 - lr: 1.3000e-04\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 9s 306ms/step - loss: 0.2548 - accuracy: 0.8926 - lr: 1.3000e-04\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 9s 302ms/step - loss: 0.2635 - accuracy: 0.8863 - lr: 1.3000e-04\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 9s 306ms/step - loss: 0.2618 - accuracy: 0.8898 - lr: 1.3000e-04\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.2530 - accuracy: 0.8930 - lr: 1.3000e-04\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 9s 303ms/step - loss: 0.2544 - accuracy: 0.8950 - lr: 1.3000e-04\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.2602 - accuracy: 0.8940 - lr: 1.3000e-04\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 9s 304ms/step - loss: 0.2561 - accuracy: 0.8947 - lr: 1.3000e-04\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 9s 301ms/step - loss: 0.2617 - accuracy: 0.8877 - lr: 1.3000e-04\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 9s 305ms/step - loss: 0.2672 - accuracy: 0.8825 - lr: 1.3000e-04\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 9s 306ms/step - loss: 0.2599 - accuracy: 0.8846 - lr: 1.3000e-04\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 9s 304ms/step - loss: 0.2560 - accuracy: 0.8898 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 50ms/step - loss: 0.1924 - accuracy: 0.9169 - lr: 1.3000e-04\n",
      "22/22 [==============================] - 1s 49ms/step\n",
      "22/22 [==============================] - 1s 50ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "tprs=[]\n",
    "mean_fpr=np.linspace(0,1,100)\n",
    "auck=[0,0,0,0,0]\n",
    "Recalls=[]\n",
    "F1score=[]\n",
    "specificity=[]\n",
    "accuracys = []\n",
    "for i in range(5):\n",
    "    if i==0:\n",
    "        x_train, y_train = x_train0,y_train0\n",
    "        x_test, y_test = x_test0,y_test0\n",
    "        model.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model.predict(x_test))\n",
    "        y_pred=model.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    elif i ==1:\n",
    "        x_train, y_train = x_train1,y_train1\n",
    "        x_test, y_test = x_test1,y_test1\n",
    "        model2.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model2.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model2.predict(x_test))\n",
    "        y_pred=model2.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    elif i ==2:\n",
    "        x_train, y_train = x_train2,y_train2\n",
    "        x_test, y_test = x_test2,y_test2\n",
    "        model3.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model3.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model3.predict(x_test))\n",
    "        y_pred=model3.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    elif i ==3:\n",
    "        x_train, y_train = x_train3,y_train3\n",
    "        x_test, y_test = x_test3,y_test3\n",
    "        model4.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model4.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model4.predict(x_test))\n",
    "        y_pred=model4.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    else:\n",
    "        x_train, y_train = x_train4,y_train4\n",
    "        x_test, y_test = x_test4,y_test4\n",
    "        model5.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model5.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model5.predict(x_test))\n",
    "        y_pred=model5.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    auck[i] = auc(fpr, tpr)\n",
    "    tprs.append(interp(mean_fpr,fpr,tpr))\n",
    "    tprs[-1][0]=0.0\n",
    "scores=np.array(scores)\n",
    "interval = stats.t.interval(0.95, scores.shape[0] - 1, scores.mean(), scores.std() / np.sqrt(scores.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "fc5b3882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence interval：(0.8089189036973181, 0.9670123354307947)\n",
      "scores: 0.8879656195640564\n",
      "AUC: 0.9812154591566357\n"
     ]
    }
   ],
   "source": [
    "print(\"confidence interval：{}\".format(interval))\n",
    "print('scores:',np.mean(scores))\n",
    "print('AUC:',np.mean(auck))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "ea5972b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracys: 0.8879656160458452\n"
     ]
    }
   ],
   "source": [
    "print('Accuracys:',np.mean(accuracys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "53c4f776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recalls: 0.9495798319327731\n",
      "F1score: 0.9228376311709312\n"
     ]
    }
   ],
   "source": [
    "print('Recalls:',np.mean(Recalls))\n",
    "print('F1score:',np.mean(F1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "b671583a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f78a3fa830>]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.grid(alpha=0.4)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.plot([0,1],[0,1],linestyle='--',lw=2,color='r',alpha=0.1)\n",
    "plt.xlabel('False Positive Rate', fontsize=13)\n",
    "plt.ylabel('True Positive Rate', fontsize=13)\n",
    "mean_tpr=np.mean(tprs,axis=0)\n",
    "mean_tpr[-1]=1.0\n",
    "std_auc=np.std(tprs,axis=0)\n",
    "plt.plot(mean_fpr,mean_tpr,color='b',label = u'AUC=%.3f' % (sum(auck)/5),lw=2,alpha=0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 | packaged by Anaconda, Inc. | (main, Mar  8 2023, 10:42:25) [MSC v.1916 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "3c06e3e46abf38078fe4dac36a0085ec2b134ebbd73dd076183d243eeca6918f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
