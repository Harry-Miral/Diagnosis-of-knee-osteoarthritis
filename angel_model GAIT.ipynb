{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "452b9946",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-05T12:59:35.081622Z",
     "start_time": "2022-07-05T12:59:35.077621Z"
    }
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8cf216bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:46.997604Z",
     "start_time": "2022-07-07T13:19:42.857680Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from pandas import read_csv, unique\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.stats import mode\n",
    "from scipy import interp\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,roc_curve,auc\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "\n",
    "from tensorflow import stack\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling1D, BatchNormalization, MaxPool1D, Reshape, Activation\n",
    "from keras.layers import Conv1D, LSTM\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import statsmodels.stats.api as sms\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56be0860",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f4351ece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:47.013608Z",
     "start_time": "2022-07-07T13:19:46.998607Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(filepath):\n",
    "    df = read_csv(filepath, header=None, names=['user-id',\n",
    "                                               'activity',\n",
    "                                               'timestamp',\n",
    "                                               'sex',\n",
    "                                               'age',\n",
    "                                               'BMI',\n",
    "                                               'A',\n",
    "                                               'B',\n",
    "                                               'C',\n",
    "                                               'X',\n",
    "                                               'Y',\n",
    "                                               'Z'])\n",
    "    ## removing ';' from last column and converting it to float\n",
    "    df['Z'].replace(regex=True, inplace=True, to_replace=r';', value=r'')\n",
    "    df['Z'] = df['Z'].apply(convert_to_float)\n",
    "#     df.dropna(axis=0, how='any', inplace=True)\n",
    "    return df\n",
    "\n",
    "def convert_to_float(x):\n",
    "    try:\n",
    "        return np.float64(x)\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fe14cbaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:48.655211Z",
     "start_time": "2022-07-07T13:19:47.014608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.842623</td>\n",
       "      <td>170.059424</td>\n",
       "      <td>171.885206</td>\n",
       "      <td>164.917391</td>\n",
       "      <td>165.412991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.642798</td>\n",
       "      <td>170.228278</td>\n",
       "      <td>172.175605</td>\n",
       "      <td>164.844014</td>\n",
       "      <td>165.337399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.442973</td>\n",
       "      <td>170.397132</td>\n",
       "      <td>172.466004</td>\n",
       "      <td>164.770636</td>\n",
       "      <td>165.261807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.392961</td>\n",
       "      <td>170.137725</td>\n",
       "      <td>171.981197</td>\n",
       "      <td>164.342390</td>\n",
       "      <td>165.068027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.342949</td>\n",
       "      <td>169.878317</td>\n",
       "      <td>171.496389</td>\n",
       "      <td>163.914143</td>\n",
       "      <td>164.874246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142795</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>395</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>395.0</td>\n",
       "      <td>25.100288</td>\n",
       "      <td>175.285201</td>\n",
       "      <td>169.166791</td>\n",
       "      <td>167.176578</td>\n",
       "      <td>143.908137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142796</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>396</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>396.0</td>\n",
       "      <td>24.407383</td>\n",
       "      <td>175.156822</td>\n",
       "      <td>169.516578</td>\n",
       "      <td>166.584673</td>\n",
       "      <td>144.295324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142797</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>397</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>397.0</td>\n",
       "      <td>25.290760</td>\n",
       "      <td>174.922366</td>\n",
       "      <td>169.729140</td>\n",
       "      <td>167.409571</td>\n",
       "      <td>143.100077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142798</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>398</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>398.0</td>\n",
       "      <td>25.732448</td>\n",
       "      <td>174.805139</td>\n",
       "      <td>169.835422</td>\n",
       "      <td>167.822019</td>\n",
       "      <td>142.502453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142799</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>399</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>399.0</td>\n",
       "      <td>26.174136</td>\n",
       "      <td>174.687911</td>\n",
       "      <td>169.941703</td>\n",
       "      <td>168.234468</td>\n",
       "      <td>141.904830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp  sex  age        BMI      A          B  \\\n",
       "0             1      Yes          0    1   57  24.212293    0.0  23.842623   \n",
       "1             1      Yes          1    1   57  24.212293    1.0  23.642798   \n",
       "2             1      Yes          2    1   57  24.212293    2.0  23.442973   \n",
       "3             1      Yes          3    1   57  24.212293    3.0  23.392961   \n",
       "4             1      Yes          4    1   57  24.212293    4.0  23.342949   \n",
       "...         ...      ...        ...  ...  ...        ...    ...        ...   \n",
       "142795      357      Yes        395    1   54  25.402816  395.0  25.100288   \n",
       "142796      357      Yes        396    1   54  25.402816  396.0  24.407383   \n",
       "142797      357      Yes        397    1   54  25.402816  397.0  25.290760   \n",
       "142798      357      Yes        398    1   54  25.402816  398.0  25.732448   \n",
       "142799      357      Yes        399    1   54  25.402816  399.0  26.174136   \n",
       "\n",
       "                 C           X           Y           Z  \n",
       "0       170.059424  171.885206  164.917391  165.412991  \n",
       "1       170.228278  172.175605  164.844014  165.337399  \n",
       "2       170.397132  172.466004  164.770636  165.261807  \n",
       "3       170.137725  171.981197  164.342390  165.068027  \n",
       "4       169.878317  171.496389  163.914143  164.874246  \n",
       "...            ...         ...         ...         ...  \n",
       "142795  175.285201  169.166791  167.176578  143.908137  \n",
       "142796  175.156822  169.516578  166.584673  144.295324  \n",
       "142797  174.922366  169.729140  167.409571  143.100077  \n",
       "142798  174.805139  169.835422  167.822019  142.502453  \n",
       "142799  174.687911  169.941703  168.234468  141.904830  \n",
       "\n",
       "[142800 rows x 12 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_data('Dataset/Angel_and_Baseline/Angel_data_Walk_order.txt')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cfc0f2",
   "metadata": {},
   "source": [
    "## Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "78699eb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.436290Z",
     "start_time": "2022-07-07T13:19:50.281071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>activityEncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.842623</td>\n",
       "      <td>170.059424</td>\n",
       "      <td>171.885206</td>\n",
       "      <td>164.917391</td>\n",
       "      <td>165.412991</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.642798</td>\n",
       "      <td>170.228278</td>\n",
       "      <td>172.175605</td>\n",
       "      <td>164.844014</td>\n",
       "      <td>165.337399</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.442973</td>\n",
       "      <td>170.397132</td>\n",
       "      <td>172.466004</td>\n",
       "      <td>164.770636</td>\n",
       "      <td>165.261807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.392961</td>\n",
       "      <td>170.137725</td>\n",
       "      <td>171.981197</td>\n",
       "      <td>164.342390</td>\n",
       "      <td>165.068027</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>24.212293</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.342949</td>\n",
       "      <td>169.878317</td>\n",
       "      <td>171.496389</td>\n",
       "      <td>163.914143</td>\n",
       "      <td>164.874246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142795</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>395</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>395.0</td>\n",
       "      <td>25.100288</td>\n",
       "      <td>175.285201</td>\n",
       "      <td>169.166791</td>\n",
       "      <td>167.176578</td>\n",
       "      <td>143.908137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142796</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>396</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>396.0</td>\n",
       "      <td>24.407383</td>\n",
       "      <td>175.156822</td>\n",
       "      <td>169.516578</td>\n",
       "      <td>166.584673</td>\n",
       "      <td>144.295324</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142797</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>397</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>397.0</td>\n",
       "      <td>25.290760</td>\n",
       "      <td>174.922366</td>\n",
       "      <td>169.729140</td>\n",
       "      <td>167.409571</td>\n",
       "      <td>143.100077</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142798</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>398</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>398.0</td>\n",
       "      <td>25.732448</td>\n",
       "      <td>174.805139</td>\n",
       "      <td>169.835422</td>\n",
       "      <td>167.822019</td>\n",
       "      <td>142.502453</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142799</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>399</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>25.402816</td>\n",
       "      <td>399.0</td>\n",
       "      <td>26.174136</td>\n",
       "      <td>174.687911</td>\n",
       "      <td>169.941703</td>\n",
       "      <td>168.234468</td>\n",
       "      <td>141.904830</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142800 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp  sex  age        BMI      A          B  \\\n",
       "0             1      Yes          0    1   57  24.212293    0.0  23.842623   \n",
       "1             1      Yes          1    1   57  24.212293    1.0  23.642798   \n",
       "2             1      Yes          2    1   57  24.212293    2.0  23.442973   \n",
       "3             1      Yes          3    1   57  24.212293    3.0  23.392961   \n",
       "4             1      Yes          4    1   57  24.212293    4.0  23.342949   \n",
       "...         ...      ...        ...  ...  ...        ...    ...        ...   \n",
       "142795      357      Yes        395    1   54  25.402816  395.0  25.100288   \n",
       "142796      357      Yes        396    1   54  25.402816  396.0  24.407383   \n",
       "142797      357      Yes        397    1   54  25.402816  397.0  25.290760   \n",
       "142798      357      Yes        398    1   54  25.402816  398.0  25.732448   \n",
       "142799      357      Yes        399    1   54  25.402816  399.0  26.174136   \n",
       "\n",
       "                 C           X           Y           Z  activityEncode  \n",
       "0       170.059424  171.885206  164.917391  165.412991               1  \n",
       "1       170.228278  172.175605  164.844014  165.337399               1  \n",
       "2       170.397132  172.466004  164.770636  165.261807               1  \n",
       "3       170.137725  171.981197  164.342390  165.068027               1  \n",
       "4       169.878317  171.496389  163.914143  164.874246               1  \n",
       "...            ...         ...         ...         ...             ...  \n",
       "142795  175.285201  169.166791  167.176578  143.908137               1  \n",
       "142796  175.156822  169.516578  166.584673  144.295324               1  \n",
       "142797  174.922366  169.729140  167.409571  143.100077               1  \n",
       "142798  174.805139  169.835422  167.822019  142.502453               1  \n",
       "142799  174.687911  169.941703  168.234468  141.904830               1  \n",
       "\n",
       "[142800 rows x 13 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encode = LabelEncoder()\n",
    "df['activityEncode'] = label_encode.fit_transform(df['activity'].values.ravel())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3be5152",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-04T16:53:26.834976Z",
     "start_time": "2022-07-04T16:53:26.823973Z"
    }
   },
   "source": [
    "## Linear Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7951cd31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.484301Z",
     "start_time": "2022-07-07T13:19:50.437290Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user-id           0\n",
       "activity          0\n",
       "timestamp         0\n",
       "sex               0\n",
       "age               0\n",
       "BMI               0\n",
       "A                 0\n",
       "B                 0\n",
       "C                 0\n",
       "X                 0\n",
       "Y                 0\n",
       "Z                 0\n",
       "activityEncode    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b6d9e58d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.532284Z",
     "start_time": "2022-07-07T13:19:50.485302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<scipy.interpolate._interpolate.interp1d at 0x1abb97f3600>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpolation_fn = interp1d(df['activityEncode'] ,df['Z'], kind='linear')\n",
    "interpolation_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4f8ea8cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.548288Z",
     "start_time": "2022-07-07T13:19:50.534285Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_list = df[df['Z'].isnull()].index.tolist()\n",
    "null_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f002bca0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.580295Z",
     "start_time": "2022-07-07T13:19:50.549289Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in null_list:\n",
    "    y = df['activityEncode'][i]\n",
    "    value = interpolation_fn(y)\n",
    "    df['Z']=df['Z'].fillna(value)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b4349e1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-07T13:19:50.627795Z",
     "start_time": "2022-07-07T13:19:50.581295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user-id           0\n",
       "activity          0\n",
       "timestamp         0\n",
       "sex               0\n",
       "age               0\n",
       "BMI               0\n",
       "A                 0\n",
       "B                 0\n",
       "C                 0\n",
       "X                 0\n",
       "Y                 0\n",
       "Z                 0\n",
       "activityEncode    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69abe57c",
   "metadata": {},
   "source": [
    "## Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a24a047f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>activityEncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263467</td>\n",
       "      <td>0.905807</td>\n",
       "      <td>0.915488</td>\n",
       "      <td>0.877280</td>\n",
       "      <td>0.871621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.259558</td>\n",
       "      <td>0.907417</td>\n",
       "      <td>0.918593</td>\n",
       "      <td>0.876677</td>\n",
       "      <td>0.870877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.255649</td>\n",
       "      <td>0.909026</td>\n",
       "      <td>0.921699</td>\n",
       "      <td>0.876075</td>\n",
       "      <td>0.870132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.254671</td>\n",
       "      <td>0.906553</td>\n",
       "      <td>0.916514</td>\n",
       "      <td>0.872557</td>\n",
       "      <td>0.868225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>0.253692</td>\n",
       "      <td>0.904080</td>\n",
       "      <td>0.911329</td>\n",
       "      <td>0.869040</td>\n",
       "      <td>0.866317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142795</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.989975</td>\n",
       "      <td>0.288069</td>\n",
       "      <td>0.955633</td>\n",
       "      <td>0.886416</td>\n",
       "      <td>0.895834</td>\n",
       "      <td>0.659933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142796</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.992481</td>\n",
       "      <td>0.274514</td>\n",
       "      <td>0.954409</td>\n",
       "      <td>0.890157</td>\n",
       "      <td>0.890972</td>\n",
       "      <td>0.663744</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142797</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.994987</td>\n",
       "      <td>0.291795</td>\n",
       "      <td>0.952173</td>\n",
       "      <td>0.892430</td>\n",
       "      <td>0.897747</td>\n",
       "      <td>0.651978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142798</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.997494</td>\n",
       "      <td>0.300435</td>\n",
       "      <td>0.951056</td>\n",
       "      <td>0.893567</td>\n",
       "      <td>0.901134</td>\n",
       "      <td>0.646095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142799</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.309075</td>\n",
       "      <td>0.949938</td>\n",
       "      <td>0.894703</td>\n",
       "      <td>0.904522</td>\n",
       "      <td>0.640213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142800 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp  sex       age       BMI         A  \\\n",
       "0             1      Yes          0  0.0  0.225806  0.398781  0.000000   \n",
       "1             1      Yes          1  0.0  0.225806  0.398781  0.002506   \n",
       "2             1      Yes          2  0.0  0.225806  0.398781  0.005013   \n",
       "3             1      Yes          3  0.0  0.225806  0.398781  0.007519   \n",
       "4             1      Yes          4  0.0  0.225806  0.398781  0.010025   \n",
       "...         ...      ...        ...  ...       ...       ...       ...   \n",
       "142795      357      Yes        395  0.0  0.129032  0.460572  0.989975   \n",
       "142796      357      Yes        396  0.0  0.129032  0.460572  0.992481   \n",
       "142797      357      Yes        397  0.0  0.129032  0.460572  0.994987   \n",
       "142798      357      Yes        398  0.0  0.129032  0.460572  0.997494   \n",
       "142799      357      Yes        399  0.0  0.129032  0.460572  1.000000   \n",
       "\n",
       "               B         C         X         Y         Z  activityEncode  \n",
       "0       0.263467  0.905807  0.915488  0.877280  0.871621               1  \n",
       "1       0.259558  0.907417  0.918593  0.876677  0.870877               1  \n",
       "2       0.255649  0.909026  0.921699  0.876075  0.870132               1  \n",
       "3       0.254671  0.906553  0.916514  0.872557  0.868225               1  \n",
       "4       0.253692  0.904080  0.911329  0.869040  0.866317               1  \n",
       "...          ...       ...       ...       ...       ...             ...  \n",
       "142795  0.288069  0.955633  0.886416  0.895834  0.659933               1  \n",
       "142796  0.274514  0.954409  0.890157  0.890972  0.663744               1  \n",
       "142797  0.291795  0.952173  0.892430  0.897747  0.651978               1  \n",
       "142798  0.300435  0.951056  0.893567  0.901134  0.646095               1  \n",
       "142799  0.309075  0.949938  0.894703  0.904522  0.640213               1  \n",
       "\n",
       "[142800 rows x 13 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['age'] = (df['age']-df['age'].min())/(df['age'].max()-df['age'].min())\n",
    "df['BMI'] = (df['BMI']-df['BMI'].min())/(df['BMI'].max()-df['BMI'].min())\n",
    "df['A'] = (df['A']-df['A'].min())/(df['A'].max()-df['A'].min())\n",
    "df['B'] = (df['B']-df['B'].min())/(df['B'].max()-df['B'].min())\n",
    "df['C'] = (df['C']-df['C'].min())/(df['C'].max()-df['C'].min())\n",
    "df['X'] = (df['X']-df['X'].min())/(df['X'].max()-df['X'].min())\n",
    "df['Y'] = (df['Y']-df['Y'].min())/(df['Y'].max()-df['Y'].min())\n",
    "df['Z'] = (df['Z']-df['Z'].min())/(df['Z'].max()-df['Z'].min())\n",
    "df['sex'] = (df['sex']-df['sex'].min())/(df['sex'].max()-df['sex'].min())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a31ec3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segments(df, time_steps, step, label_name):\n",
    "    N_FEATURES = 9\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "        xs = df['X'].values[i:i+time_steps]\n",
    "        ys = df['Y'].values[i:i+time_steps]\n",
    "        zs = df['Z'].values[i:i+time_steps]\n",
    "        aas = df['A'].values[i:i+time_steps]\n",
    "        bs = df['B'].values[i:i+time_steps]\n",
    "        cs = df['C'].values[i:i+time_steps]\n",
    "        sexs = df['sex'].values[i:i+time_steps]\n",
    "        ages = df['age'].values[i:i+time_steps]\n",
    "        bmis = df['BMI'].values[i:i+time_steps]\n",
    "        label = mode(df[label_name][i:i+time_steps])[0][0]\n",
    "        segments.append([sexs,ages,bmis,aas,bs,cs,xs, ys, zs])\n",
    "        labels.append(label)\n",
    "    reshaped_segments = np.asarray(segments, dtype=np.float32).reshape(-1, time_steps, N_FEATURES)\n",
    "    labels = np.asarray(labels)\n",
    "    return reshaped_segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "987cccea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user-id</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>BMI</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>activityEncode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.263467</td>\n",
       "      <td>0.905807</td>\n",
       "      <td>0.915488</td>\n",
       "      <td>0.877280</td>\n",
       "      <td>0.871621</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.259558</td>\n",
       "      <td>0.907417</td>\n",
       "      <td>0.918593</td>\n",
       "      <td>0.876677</td>\n",
       "      <td>0.870877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.005013</td>\n",
       "      <td>0.255649</td>\n",
       "      <td>0.909026</td>\n",
       "      <td>0.921699</td>\n",
       "      <td>0.876075</td>\n",
       "      <td>0.870132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.007519</td>\n",
       "      <td>0.254671</td>\n",
       "      <td>0.906553</td>\n",
       "      <td>0.916514</td>\n",
       "      <td>0.872557</td>\n",
       "      <td>0.868225</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.225806</td>\n",
       "      <td>0.398781</td>\n",
       "      <td>0.010025</td>\n",
       "      <td>0.253692</td>\n",
       "      <td>0.904080</td>\n",
       "      <td>0.911329</td>\n",
       "      <td>0.869040</td>\n",
       "      <td>0.866317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142795</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>395</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.989975</td>\n",
       "      <td>0.288069</td>\n",
       "      <td>0.955633</td>\n",
       "      <td>0.886416</td>\n",
       "      <td>0.895834</td>\n",
       "      <td>0.659933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142796</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.992481</td>\n",
       "      <td>0.274514</td>\n",
       "      <td>0.954409</td>\n",
       "      <td>0.890157</td>\n",
       "      <td>0.890972</td>\n",
       "      <td>0.663744</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142797</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.994987</td>\n",
       "      <td>0.291795</td>\n",
       "      <td>0.952173</td>\n",
       "      <td>0.892430</td>\n",
       "      <td>0.897747</td>\n",
       "      <td>0.651978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142798</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>398</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>0.997494</td>\n",
       "      <td>0.300435</td>\n",
       "      <td>0.951056</td>\n",
       "      <td>0.893567</td>\n",
       "      <td>0.901134</td>\n",
       "      <td>0.646095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142799</th>\n",
       "      <td>357</td>\n",
       "      <td>Yes</td>\n",
       "      <td>399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.460572</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.309075</td>\n",
       "      <td>0.949938</td>\n",
       "      <td>0.894703</td>\n",
       "      <td>0.904522</td>\n",
       "      <td>0.640213</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142800 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user-id activity  timestamp  sex       age       BMI         A  \\\n",
       "0             1      Yes          0  0.0  0.225806  0.398781  0.000000   \n",
       "1             1      Yes          1  0.0  0.225806  0.398781  0.002506   \n",
       "2             1      Yes          2  0.0  0.225806  0.398781  0.005013   \n",
       "3             1      Yes          3  0.0  0.225806  0.398781  0.007519   \n",
       "4             1      Yes          4  0.0  0.225806  0.398781  0.010025   \n",
       "...         ...      ...        ...  ...       ...       ...       ...   \n",
       "142795      357      Yes        395  0.0  0.129032  0.460572  0.989975   \n",
       "142796      357      Yes        396  0.0  0.129032  0.460572  0.992481   \n",
       "142797      357      Yes        397  0.0  0.129032  0.460572  0.994987   \n",
       "142798      357      Yes        398  0.0  0.129032  0.460572  0.997494   \n",
       "142799      357      Yes        399  0.0  0.129032  0.460572  1.000000   \n",
       "\n",
       "               B         C         X         Y         Z  activityEncode  \n",
       "0       0.263467  0.905807  0.915488  0.877280  0.871621               1  \n",
       "1       0.259558  0.907417  0.918593  0.876677  0.870877               1  \n",
       "2       0.255649  0.909026  0.921699  0.876075  0.870132               1  \n",
       "3       0.254671  0.906553  0.916514  0.872557  0.868225               1  \n",
       "4       0.253692  0.904080  0.911329  0.869040  0.866317               1  \n",
       "...          ...       ...       ...       ...       ...             ...  \n",
       "142795  0.288069  0.955633  0.886416  0.895834  0.659933               1  \n",
       "142796  0.274514  0.954409  0.890157  0.890972  0.663744               1  \n",
       "142797  0.291795  0.952173  0.892430  0.897747  0.651978               1  \n",
       "142798  0.300435  0.951056  0.893567  0.901134  0.646095               1  \n",
       "142799  0.309075  0.949938  0.894703  0.904522  0.640213               1  \n",
       "\n",
       "[142800 rows x 13 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7b783875",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_PERIOD = 80\n",
    "STEP_DISTANCE = 40\n",
    "LABEL = 'activityEncode'\n",
    "\n",
    "df1=df[df['user-id']>70]\n",
    "df2=df[df['user-id']>140]\n",
    "df3=df[df['user-id']>210]\n",
    "df4=df[df['user-id']>280]\n",
    "\n",
    "a1=df.shape[0]\n",
    "b2=df1.shape[0]\n",
    "c3=df2.shape[0]\n",
    "d4=df3.shape[0]\n",
    "e5=df4.shape[0]\n",
    "\n",
    "df_test0 = df.iloc[0:a1-b2,:]\n",
    "df_train0 = df.iloc[a1-b2:a1,:]\n",
    "x_train0, y_train0 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test0, y_test0 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train0.shape[1], x_train0.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train0 = x_train0.reshape(x_train0.shape[0], input_shape)\n",
    "x_train0 = x_train0.astype('float32')\n",
    "y_train0=np.asarray(y_train0).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test0.shape[1], x_test0.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test0 = x_test0.reshape(x_test0.shape[0], input_shape)\n",
    "x_test0 = x_test0.astype('float32')\n",
    "y_test0=np.asarray(y_test0).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test1 = df.iloc[a1-b2:a1-c3,:]\n",
    "df_train1 = pd.concat([df_test0,df.iloc[a1-c3:a1,]])\n",
    "x_train1, y_train1 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test1, y_test1 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train1.shape[1], x_train1.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train1 = x_train1.reshape(x_train1.shape[0], input_shape)\n",
    "x_train1 = x_train1.astype('float32')\n",
    "y_train1=np.asarray(y_train1).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test1.shape[1], x_test1.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test1 = x_test1.reshape(x_test1.shape[0], input_shape)\n",
    "x_test1 = x_test1.astype('float32')\n",
    "y_test1=np.asarray(y_test1).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test2 = df.iloc[a1-c3:a1-d4,:]\n",
    "df_train2 = pd.concat([df.iloc[0:a1-c3,:],df.iloc[a1-d4:a1,]])\n",
    "x_train2, y_train2 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test2, y_test2 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train2.shape[1], x_train2.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train2 = x_train2.reshape(x_train2.shape[0], input_shape)\n",
    "x_train2 = x_train2.astype('float32')\n",
    "y_train2=np.asarray(y_train2).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test2.shape[1], x_test2.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test2 = x_test2.reshape(x_test2.shape[0], input_shape)\n",
    "x_test2 = x_test2.astype('float32')\n",
    "y_test2=np.asarray(y_test2).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test3 = df.iloc[a1-d4:a1-e5,:]\n",
    "df_train3 = pd.concat([df.iloc[0:a1-d4,:],df.iloc[a1-e5:a1,]])\n",
    "x_train3, y_train3 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test3, y_test3 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train3.shape[1], x_train3.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train3 = x_train3.reshape(x_train3.shape[0], input_shape)\n",
    "x_train3 = x_train3.astype('float32')\n",
    "y_train3=np.asarray(y_train3).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test3.shape[1], x_test3.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test3 = x_test3.reshape(x_test3.shape[0], input_shape)\n",
    "x_test3 = x_test3.astype('float32')\n",
    "y_test3=np.asarray(y_test3).astype('float32').reshape((-1,1))\n",
    "\n",
    "df_test4 = df.iloc[a1-e5:a1,:]\n",
    "df_train4 = df.iloc[0:a1-e5,:]\n",
    "x_train4, y_train4 = segments(df_train0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "x_test4, y_test4 = segments(df_test0, TIME_PERIOD, STEP_DISTANCE, LABEL)\n",
    "time_period, sensors = x_train4.shape[1], x_train4.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_train4 = x_train4.reshape(x_train4.shape[0], input_shape)\n",
    "x_train4 = x_train4.astype('float32')\n",
    "y_train4=np.asarray(y_train4).astype('float32').reshape((-1,1))\n",
    "time_period, sensors = x_test4.shape[1], x_test4.shape[2]\n",
    "num_classes = label_encode.classes_.size\n",
    "input_shape = time_period * sensors\n",
    "x_test4 = x_test4.reshape(x_test4.shape[0], input_shape)\n",
    "x_test4 = x_test4.astype('float32')\n",
    "y_test4=np.asarray(y_test4).astype('float32').reshape((-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "40c9e344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_36 (LSTM)              (None, 720, 32)           4352      \n",
      "                                                                 \n",
      " lstm_37 (LSTM)              (None, 720, 32)           8320      \n",
      "                                                                 \n",
      " reshape_54 (Reshape)        (None, 1, 720, 32)        0         \n",
      "                                                                 \n",
      " conv1d_36 (Conv1D)          (None, 1, 360, 64)        4160      \n",
      "                                                                 \n",
      " reshape_55 (Reshape)        (None, 360, 64)           0         \n",
      "                                                                 \n",
      " max_pooling1d_18 (MaxPoolin  (None, 90, 64)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_37 (Conv1D)          (None, 89, 192)           24768     \n",
      "                                                                 \n",
      " reshape_56 (Reshape)        (None, 89, 192)           0         \n",
      "                                                                 \n",
      " global_average_pooling1d_18  (None, 192)              0         \n",
      "  (GlobalAveragePooling1D)                                       \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 192)              768       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 193       \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42,561\n",
      "Trainable params: 42,177\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model.add(Reshape((1, 720, 32)))\n",
    "model.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model.add(Reshape((360, 64)))\n",
    "model.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model.add(Reshape((89, 192)))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(BatchNormalization(epsilon=1e-06))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f1538a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_metric(optimizer):  # printing the value of the learning rate\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "\n",
    "def step_decay(epoch):\n",
    "\tinitial_lrate = 0.001\n",
    "\tdrop = 0.5\n",
    "\tepochs_drop = 5.0\n",
    "\tlrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "\treturn lrate\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "sgd = SGD(lr=0.0, momentum=0.9, decay=0.0, nesterov=False)\n",
    "adam=optimizers.Adam(lr=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-8, decay=0.0, amsgrad=False)\n",
    "#lr_metric = get_lr_metric(adam)\n",
    "lr_metric = get_lr_metric(adam)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "model1 = Sequential()\n",
    "model1.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model1.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model1.add(Reshape((1, 720, 32)))\n",
    "model1.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model1.add(Reshape((360, 64)))\n",
    "model1.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model1.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model1.add(Reshape((89, 192)))\n",
    "model1.add(GlobalAveragePooling1D())\n",
    "model1.add(BatchNormalization(epsilon=1e-06))\n",
    "model1.add(Dense(1))\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model2.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model2.add(Reshape((1, 720, 32)))\n",
    "model2.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model2.add(Reshape((360, 64)))\n",
    "model2.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model2.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model2.add(Reshape((89, 192)))\n",
    "model2.add(GlobalAveragePooling1D())\n",
    "model2.add(BatchNormalization(epsilon=1e-06))\n",
    "model2.add(Dense(1))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model3.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model3.add(Reshape((1, 720, 32)))\n",
    "model3.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model3.add(Reshape((360, 64)))\n",
    "model3.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model3.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model3.add(Reshape((89, 192)))\n",
    "model3.add(GlobalAveragePooling1D())\n",
    "model3.add(BatchNormalization(epsilon=1e-06))\n",
    "model3.add(Dense(1))\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model4.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model4.add(Reshape((1, 720, 32)))\n",
    "model4.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model4.add(Reshape((360, 64)))\n",
    "model4.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model4.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model4.add(Reshape((89, 192)))\n",
    "model4.add(GlobalAveragePooling1D())\n",
    "model4.add(BatchNormalization(epsilon=1e-06))\n",
    "model4.add(Dense(1))\n",
    "model4.add(Activation('sigmoid'))\n",
    "model4.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(LSTM(32, return_sequences=True, input_shape=(input_shape,1), activation='relu'))\n",
    "model5.add(LSTM(32,return_sequences=True, activation='relu'))\n",
    "model5.add(Reshape((1, 720, 32)))\n",
    "model5.add(Conv1D(filters=64,kernel_size=2, activation='relu', strides=2))\n",
    "model5.add(Reshape((360, 64)))\n",
    "model5.add(MaxPool1D(pool_size=4, padding='same'))\n",
    "model5.add(Conv1D(filters=192, kernel_size=2, activation='relu', strides=1))\n",
    "model5.add(Reshape((89, 192)))\n",
    "model5.add(GlobalAveragePooling1D())\n",
    "model5.add(BatchNormalization(epsilon=1e-06))\n",
    "model5.add(Dense(1))\n",
    "model5.add(Activation('sigmoid'))\n",
    "model5.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy',lr_metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2047136b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "29/29 [==============================] - 19s 523ms/step - loss: 0.5776 - accuracy: 0.6893 - lr: 9.0000e-05\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 15s 513ms/step - loss: 0.5513 - accuracy: 0.7099 - lr: 9.0000e-05\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 16s 538ms/step - loss: 0.5435 - accuracy: 0.7130 - lr: 9.0000e-05\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 16s 556ms/step - loss: 0.5327 - accuracy: 0.7232 - lr: 9.0000e-05\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 16s 553ms/step - loss: 0.5271 - accuracy: 0.7326 - lr: 9.0000e-05\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 16s 563ms/step - loss: 0.5191 - accuracy: 0.7409 - lr: 9.0000e-05\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 16s 558ms/step - loss: 0.5098 - accuracy: 0.7409 - lr: 9.0000e-05\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 16s 559ms/step - loss: 0.5043 - accuracy: 0.7483 - lr: 9.0000e-05\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 16s 567ms/step - loss: 0.4962 - accuracy: 0.7587 - lr: 9.0000e-05\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 16s 558ms/step - loss: 0.4908 - accuracy: 0.7573 - lr: 9.0000e-05\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 16s 559ms/step - loss: 0.4858 - accuracy: 0.7695 - lr: 9.0000e-05\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 16s 560ms/step - loss: 0.4793 - accuracy: 0.7730 - lr: 9.0000e-05\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 16s 563ms/step - loss: 0.4737 - accuracy: 0.7775 - lr: 9.0000e-05\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 16s 567ms/step - loss: 0.4665 - accuracy: 0.7852 - lr: 9.0000e-05\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 16s 563ms/step - loss: 0.4603 - accuracy: 0.7824 - lr: 9.0000e-05\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 16s 559ms/step - loss: 0.4560 - accuracy: 0.7842 - lr: 9.0000e-05\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 16s 561ms/step - loss: 0.4505 - accuracy: 0.7880 - lr: 9.0000e-05\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 16s 562ms/step - loss: 0.4447 - accuracy: 0.7932 - lr: 9.0000e-05\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 16s 564ms/step - loss: 0.4412 - accuracy: 0.7964 - lr: 9.0000e-05\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 16s 561ms/step - loss: 0.4396 - accuracy: 0.7936 - lr: 9.0000e-05\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 16s 562ms/step - loss: 0.4360 - accuracy: 0.7908 - lr: 9.0000e-05\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 16s 559ms/step - loss: 0.4303 - accuracy: 0.7992 - lr: 9.0000e-05\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 16s 563ms/step - loss: 0.4289 - accuracy: 0.7953 - lr: 9.0000e-05\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 16s 556ms/step - loss: 0.4263 - accuracy: 0.7978 - lr: 9.0000e-05\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 16s 562ms/step - loss: 0.4223 - accuracy: 0.7974 - lr: 9.0000e-05\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 16s 561ms/step - loss: 0.4154 - accuracy: 0.8026 - lr: 9.0000e-05\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 16s 563ms/step - loss: 0.4141 - accuracy: 0.8065 - lr: 9.0000e-05\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 16s 562ms/step - loss: 0.4133 - accuracy: 0.8065 - lr: 9.0000e-05\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 16s 564ms/step - loss: 0.4067 - accuracy: 0.8051 - lr: 9.0000e-05\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 16s 554ms/step - loss: 0.4061 - accuracy: 0.8051 - lr: 9.0000e-05\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 16s 561ms/step - loss: 0.4016 - accuracy: 0.8103 - lr: 9.0000e-05\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 16s 563ms/step - loss: 0.4128 - accuracy: 0.8054 - lr: 9.0000e-05\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 16s 561ms/step - loss: 0.4019 - accuracy: 0.8103 - lr: 9.0000e-05\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 16s 558ms/step - loss: 0.3931 - accuracy: 0.8201 - lr: 9.0000e-05\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 16s 559ms/step - loss: 0.3879 - accuracy: 0.8173 - lr: 9.0000e-05\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 16s 561ms/step - loss: 0.3893 - accuracy: 0.8183 - lr: 9.0000e-05\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 16s 561ms/step - loss: 0.3843 - accuracy: 0.8201 - lr: 9.0000e-05\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 16s 560ms/step - loss: 0.3884 - accuracy: 0.8096 - lr: 9.0000e-05\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 16s 559ms/step - loss: 0.3738 - accuracy: 0.8239 - lr: 9.0000e-05\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 16s 558ms/step - loss: 0.3673 - accuracy: 0.8323 - lr: 9.0000e-05\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 16s 561ms/step - loss: 0.3692 - accuracy: 0.8285 - lr: 9.0000e-05\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 16s 557ms/step - loss: 0.3665 - accuracy: 0.8340 - lr: 9.0000e-05\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 16s 561ms/step - loss: 0.3592 - accuracy: 0.8330 - lr: 9.0000e-05\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 16s 557ms/step - loss: 0.3477 - accuracy: 0.8469 - lr: 9.0000e-05\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 16s 561ms/step - loss: 0.3461 - accuracy: 0.8431 - lr: 9.0000e-05\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 16s 559ms/step - loss: 0.3454 - accuracy: 0.8462 - lr: 9.0000e-05\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 16s 561ms/step - loss: 0.3464 - accuracy: 0.8490 - lr: 9.0000e-05\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 16s 562ms/step - loss: 0.3298 - accuracy: 0.8609 - lr: 9.0000e-05\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 16s 560ms/step - loss: 0.3331 - accuracy: 0.8560 - lr: 9.0000e-05\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 16s 561ms/step - loss: 0.3270 - accuracy: 0.8619 - lr: 9.0000e-05\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 16s 559ms/step - loss: 0.3319 - accuracy: 0.8522 - lr: 9.0000e-05\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 16s 563ms/step - loss: 0.3250 - accuracy: 0.8567 - lr: 9.0000e-05\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 16s 561ms/step - loss: 0.3232 - accuracy: 0.8560 - lr: 9.0000e-05\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 16s 560ms/step - loss: 0.3186 - accuracy: 0.8658 - lr: 9.0000e-05\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 16s 562ms/step - loss: 0.3148 - accuracy: 0.8602 - lr: 9.0000e-05\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 16s 564ms/step - loss: 0.3257 - accuracy: 0.8563 - lr: 9.0000e-05\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 16s 559ms/step - loss: 0.3215 - accuracy: 0.8591 - lr: 9.0000e-05\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 16s 563ms/step - loss: 0.3075 - accuracy: 0.8692 - lr: 9.0000e-05\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 16s 557ms/step - loss: 0.3037 - accuracy: 0.8692 - lr: 9.0000e-05\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 16s 559ms/step - loss: 0.3084 - accuracy: 0.8675 - lr: 9.0000e-05\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 16s 557ms/step - loss: 0.3203 - accuracy: 0.8619 - lr: 9.0000e-05\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 16s 557ms/step - loss: 0.3013 - accuracy: 0.8752 - lr: 9.0000e-05\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 16s 561ms/step - loss: 0.3011 - accuracy: 0.8769 - lr: 9.0000e-05\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 16s 558ms/step - loss: 0.3057 - accuracy: 0.8640 - lr: 9.0000e-05\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 16s 559ms/step - loss: 0.3014 - accuracy: 0.8745 - lr: 9.0000e-05\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 16s 560ms/step - loss: 0.2949 - accuracy: 0.8783 - lr: 9.0000e-05\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 16s 555ms/step - loss: 0.2931 - accuracy: 0.8780 - lr: 9.0000e-05\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 16s 558ms/step - loss: 0.2890 - accuracy: 0.8839 - lr: 9.0000e-05\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 16s 557ms/step - loss: 0.2988 - accuracy: 0.8755 - lr: 9.0000e-05\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 16s 561ms/step - loss: 0.2878 - accuracy: 0.8808 - lr: 9.0000e-05\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 14s 468ms/step - loss: 0.2906 - accuracy: 0.8769 - lr: 9.0000e-05\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 12s 421ms/step - loss: 0.2937 - accuracy: 0.8745 - lr: 9.0000e-05\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 12s 422ms/step - loss: 0.2860 - accuracy: 0.8821 - lr: 9.0000e-05\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2964 - accuracy: 0.8748 - lr: 9.0000e-05\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 12s 419ms/step - loss: 0.2897 - accuracy: 0.8734 - lr: 9.0000e-05\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 12s 420ms/step - loss: 0.2868 - accuracy: 0.8818 - lr: 9.0000e-05\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 12s 421ms/step - loss: 0.2836 - accuracy: 0.8794 - lr: 9.0000e-05\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2819 - accuracy: 0.8815 - lr: 9.0000e-05\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 12s 418ms/step - loss: 0.2854 - accuracy: 0.8790 - lr: 9.0000e-05\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 12s 418ms/step - loss: 0.2890 - accuracy: 0.8734 - lr: 9.0000e-05\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 12s 418ms/step - loss: 0.2752 - accuracy: 0.8884 - lr: 9.0000e-05\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 12s 415ms/step - loss: 0.2842 - accuracy: 0.8825 - lr: 9.0000e-05\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 12s 420ms/step - loss: 0.2792 - accuracy: 0.8804 - lr: 9.0000e-05\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 12s 418ms/step - loss: 0.2961 - accuracy: 0.8766 - lr: 9.0000e-05\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 12s 419ms/step - loss: 0.2742 - accuracy: 0.8863 - lr: 9.0000e-05\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2770 - accuracy: 0.8811 - lr: 9.0000e-05\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 12s 424ms/step - loss: 0.2778 - accuracy: 0.8853 - lr: 9.0000e-05\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 12s 422ms/step - loss: 0.2795 - accuracy: 0.8801 - lr: 9.0000e-05\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 12s 421ms/step - loss: 0.2715 - accuracy: 0.8912 - lr: 9.0000e-05\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2809 - accuracy: 0.8804 - lr: 9.0000e-05\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2772 - accuracy: 0.8808 - lr: 9.0000e-05\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 12s 418ms/step - loss: 0.2757 - accuracy: 0.8839 - lr: 9.0000e-05\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 12s 421ms/step - loss: 0.2720 - accuracy: 0.8846 - lr: 9.0000e-05\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 12s 421ms/step - loss: 0.2725 - accuracy: 0.8888 - lr: 9.0000e-05\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 12s 416ms/step - loss: 0.2684 - accuracy: 0.8884 - lr: 9.0000e-05\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 12s 421ms/step - loss: 0.2811 - accuracy: 0.8787 - lr: 9.0000e-05\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 12s 421ms/step - loss: 0.2741 - accuracy: 0.8853 - lr: 9.0000e-05\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 12s 424ms/step - loss: 0.2764 - accuracy: 0.8842 - lr: 9.0000e-05\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 12s 417ms/step - loss: 0.2767 - accuracy: 0.8821 - lr: 9.0000e-05\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 12s 424ms/step - loss: 0.2759 - accuracy: 0.8839 - lr: 9.0000e-05\n",
      "22/22 [==============================] - 2s 60ms/step - loss: 0.2524 - accuracy: 0.8983 - lr: 9.0000e-05\n",
      "22/22 [==============================] - 2s 61ms/step\n",
      "22/22 [==============================] - 1s 61ms/step\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 13s 413ms/step - loss: 0.5475 - accuracy: 0.7190 - lr: 9.0000e-05\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 12s 420ms/step - loss: 0.4994 - accuracy: 0.7598 - lr: 9.0000e-05\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 12s 421ms/step - loss: 0.4766 - accuracy: 0.7748 - lr: 9.0000e-05\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 12s 426ms/step - loss: 0.4571 - accuracy: 0.7856 - lr: 9.0000e-05\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 12s 420ms/step - loss: 0.4470 - accuracy: 0.7908 - lr: 9.0000e-05\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 12s 426ms/step - loss: 0.4390 - accuracy: 0.7922 - lr: 9.0000e-05\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 12s 425ms/step - loss: 0.4308 - accuracy: 0.7932 - lr: 9.0000e-05\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 12s 426ms/step - loss: 0.4264 - accuracy: 0.7929 - lr: 9.0000e-05\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 12s 420ms/step - loss: 0.4192 - accuracy: 0.8023 - lr: 9.0000e-05\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 12s 427ms/step - loss: 0.4141 - accuracy: 0.8061 - lr: 9.0000e-05\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 12s 425ms/step - loss: 0.4095 - accuracy: 0.8054 - lr: 9.0000e-05\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 12s 428ms/step - loss: 0.4023 - accuracy: 0.8096 - lr: 9.0000e-05\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 12s 423ms/step - loss: 0.3986 - accuracy: 0.8103 - lr: 9.0000e-05\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 12s 427ms/step - loss: 0.3912 - accuracy: 0.8114 - lr: 9.0000e-05\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 12s 428ms/step - loss: 0.3862 - accuracy: 0.8253 - lr: 9.0000e-05\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 12s 425ms/step - loss: 0.3858 - accuracy: 0.8176 - lr: 9.0000e-05\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.3744 - accuracy: 0.8243 - lr: 9.0000e-05\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 12s 426ms/step - loss: 0.3679 - accuracy: 0.8302 - lr: 9.0000e-05\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.3585 - accuracy: 0.8403 - lr: 9.0000e-05\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.3574 - accuracy: 0.8410 - lr: 9.0000e-05\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 12s 428ms/step - loss: 0.3478 - accuracy: 0.8438 - lr: 9.0000e-05\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 12s 430ms/step - loss: 0.3411 - accuracy: 0.8525 - lr: 9.0000e-05\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 12s 427ms/step - loss: 0.3336 - accuracy: 0.8546 - lr: 9.0000e-05\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 12s 428ms/step - loss: 0.3368 - accuracy: 0.8501 - lr: 9.0000e-05\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 12s 430ms/step - loss: 0.3265 - accuracy: 0.8602 - lr: 9.0000e-05\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.3347 - accuracy: 0.8584 - lr: 9.0000e-05\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 12s 428ms/step - loss: 0.3248 - accuracy: 0.8584 - lr: 9.0000e-05\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 12s 430ms/step - loss: 0.3268 - accuracy: 0.8609 - lr: 9.0000e-05\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 12s 431ms/step - loss: 0.3163 - accuracy: 0.8651 - lr: 9.0000e-05\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 13s 433ms/step - loss: 0.3179 - accuracy: 0.8546 - lr: 9.0000e-05\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 12s 426ms/step - loss: 0.3240 - accuracy: 0.8630 - lr: 9.0000e-05\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 13s 430ms/step - loss: 0.3213 - accuracy: 0.8595 - lr: 9.0000e-05\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 12s 431ms/step - loss: 0.3162 - accuracy: 0.8623 - lr: 9.0000e-05\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 13s 432ms/step - loss: 0.3144 - accuracy: 0.8654 - lr: 9.0000e-05\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 13s 434ms/step - loss: 0.3129 - accuracy: 0.8619 - lr: 9.0000e-05\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 12s 428ms/step - loss: 0.3120 - accuracy: 0.8668 - lr: 9.0000e-05\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 13s 432ms/step - loss: 0.3031 - accuracy: 0.8724 - lr: 9.0000e-05\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 13s 431ms/step - loss: 0.3024 - accuracy: 0.8682 - lr: 9.0000e-05\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 12s 430ms/step - loss: 0.3096 - accuracy: 0.8647 - lr: 9.0000e-05\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 13s 432ms/step - loss: 0.2974 - accuracy: 0.8759 - lr: 9.0000e-05\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 12s 430ms/step - loss: 0.3118 - accuracy: 0.8605 - lr: 9.0000e-05\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 13s 433ms/step - loss: 0.2984 - accuracy: 0.8755 - lr: 9.0000e-05\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 13s 431ms/step - loss: 0.2943 - accuracy: 0.8755 - lr: 9.0000e-05\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 12s 430ms/step - loss: 0.3026 - accuracy: 0.8692 - lr: 9.0000e-05\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 12s 426ms/step - loss: 0.2957 - accuracy: 0.8720 - lr: 9.0000e-05\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 13s 432ms/step - loss: 0.2965 - accuracy: 0.8696 - lr: 9.0000e-05\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 13s 433ms/step - loss: 0.2882 - accuracy: 0.8766 - lr: 9.0000e-05\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.2939 - accuracy: 0.8797 - lr: 9.0000e-05\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.2957 - accuracy: 0.8748 - lr: 9.0000e-05\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.2913 - accuracy: 0.8755 - lr: 9.0000e-05\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 13s 433ms/step - loss: 0.2977 - accuracy: 0.8703 - lr: 9.0000e-05\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 12s 430ms/step - loss: 0.2880 - accuracy: 0.8801 - lr: 9.0000e-05\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.2921 - accuracy: 0.8731 - lr: 9.0000e-05\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 12s 425ms/step - loss: 0.2836 - accuracy: 0.8842 - lr: 9.0000e-05\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 13s 431ms/step - loss: 0.2872 - accuracy: 0.8808 - lr: 9.0000e-05\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 13s 432ms/step - loss: 0.2867 - accuracy: 0.8780 - lr: 9.0000e-05\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 12s 428ms/step - loss: 0.2917 - accuracy: 0.8801 - lr: 9.0000e-05\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 12s 427ms/step - loss: 0.2878 - accuracy: 0.8703 - lr: 9.0000e-05\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 12s 428ms/step - loss: 0.2858 - accuracy: 0.8815 - lr: 9.0000e-05\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 12s 431ms/step - loss: 0.2870 - accuracy: 0.8797 - lr: 9.0000e-05\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 12s 430ms/step - loss: 0.2860 - accuracy: 0.8787 - lr: 9.0000e-05\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 12s 431ms/step - loss: 0.2897 - accuracy: 0.8783 - lr: 9.0000e-05\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 12s 425ms/step - loss: 0.2874 - accuracy: 0.8776 - lr: 9.0000e-05\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 12s 428ms/step - loss: 0.2808 - accuracy: 0.8863 - lr: 9.0000e-05\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 12s 430ms/step - loss: 0.2808 - accuracy: 0.8780 - lr: 9.0000e-05\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 13s 431ms/step - loss: 0.3031 - accuracy: 0.8626 - lr: 9.0000e-05\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 13s 432ms/step - loss: 0.2813 - accuracy: 0.8815 - lr: 9.0000e-05\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 12s 424ms/step - loss: 0.2787 - accuracy: 0.8818 - lr: 9.0000e-05\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.2783 - accuracy: 0.8842 - lr: 9.0000e-05\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 13s 433ms/step - loss: 0.2825 - accuracy: 0.8849 - lr: 9.0000e-05\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 13s 434ms/step - loss: 0.2747 - accuracy: 0.8881 - lr: 9.0000e-05\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 12s 427ms/step - loss: 0.2774 - accuracy: 0.8815 - lr: 9.0000e-05\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 12s 428ms/step - loss: 0.2843 - accuracy: 0.8870 - lr: 9.0000e-05\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 12s 430ms/step - loss: 0.2785 - accuracy: 0.8801 - lr: 9.0000e-05\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 13s 432ms/step - loss: 0.2751 - accuracy: 0.8856 - lr: 9.0000e-05\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 12s 428ms/step - loss: 0.2841 - accuracy: 0.8846 - lr: 9.0000e-05\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 12s 427ms/step - loss: 0.2752 - accuracy: 0.8842 - lr: 9.0000e-05\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 12s 428ms/step - loss: 0.2740 - accuracy: 0.8842 - lr: 9.0000e-05\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.2795 - accuracy: 0.8853 - lr: 9.0000e-05\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.2789 - accuracy: 0.8790 - lr: 9.0000e-05\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 12s 425ms/step - loss: 0.2813 - accuracy: 0.8811 - lr: 9.0000e-05\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.2789 - accuracy: 0.8804 - lr: 9.0000e-05\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 12s 430ms/step - loss: 0.2809 - accuracy: 0.8794 - lr: 9.0000e-05\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 12s 431ms/step - loss: 0.2779 - accuracy: 0.8860 - lr: 9.0000e-05\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.2742 - accuracy: 0.8870 - lr: 9.0000e-05\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 12s 425ms/step - loss: 0.2684 - accuracy: 0.8895 - lr: 9.0000e-05\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 13s 433ms/step - loss: 0.2713 - accuracy: 0.8888 - lr: 9.0000e-05\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.2693 - accuracy: 0.8905 - lr: 9.0000e-05\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 12s 428ms/step - loss: 0.2802 - accuracy: 0.8776 - lr: 9.0000e-05\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 12s 425ms/step - loss: 0.2706 - accuracy: 0.8849 - lr: 9.0000e-05\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.2791 - accuracy: 0.8815 - lr: 9.0000e-05\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.2710 - accuracy: 0.8870 - lr: 9.0000e-05\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.2667 - accuracy: 0.8909 - lr: 9.0000e-05\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 12s 426ms/step - loss: 0.2691 - accuracy: 0.8891 - lr: 9.0000e-05\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 12s 426ms/step - loss: 0.2707 - accuracy: 0.8821 - lr: 9.0000e-05\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 12s 429ms/step - loss: 0.2751 - accuracy: 0.8832 - lr: 9.0000e-05\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 12s 431ms/step - loss: 0.2732 - accuracy: 0.8821 - lr: 9.0000e-05\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 12s 427ms/step - loss: 0.2740 - accuracy: 0.8839 - lr: 9.0000e-05\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 12s 423ms/step - loss: 0.2711 - accuracy: 0.8877 - lr: 9.0000e-05\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 13s 432ms/step - loss: 0.2734 - accuracy: 0.8828 - lr: 9.0000e-05\n",
      "22/22 [==============================] - 2s 61ms/step - loss: 0.2375 - accuracy: 0.9083 - lr: 9.0000e-05\n",
      "22/22 [==============================] - 2s 61ms/step\n",
      "22/22 [==============================] - 1s 62ms/step\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 18s 542ms/step - loss: 0.5531 - accuracy: 0.7096 - lr: 9.0000e-05\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.5085 - accuracy: 0.7469 - lr: 9.0000e-05\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 16s 546ms/step - loss: 0.4837 - accuracy: 0.7657 - lr: 9.0000e-05\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 16s 548ms/step - loss: 0.4668 - accuracy: 0.7831 - lr: 9.0000e-05\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 16s 548ms/step - loss: 0.4557 - accuracy: 0.7859 - lr: 9.0000e-05\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 16s 551ms/step - loss: 0.4470 - accuracy: 0.7925 - lr: 9.0000e-05\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 16s 543ms/step - loss: 0.4383 - accuracy: 0.7946 - lr: 9.0000e-05\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 16s 543ms/step - loss: 0.4294 - accuracy: 0.8013 - lr: 9.0000e-05\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 16s 549ms/step - loss: 0.4274 - accuracy: 0.8006 - lr: 9.0000e-05\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 16s 540ms/step - loss: 0.4137 - accuracy: 0.8145 - lr: 9.0000e-05\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 16s 541ms/step - loss: 0.3943 - accuracy: 0.8166 - lr: 9.0000e-05\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 16s 547ms/step - loss: 0.3759 - accuracy: 0.8305 - lr: 9.0000e-05\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.3737 - accuracy: 0.8298 - lr: 9.0000e-05\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 16s 542ms/step - loss: 0.3577 - accuracy: 0.8379 - lr: 9.0000e-05\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 16s 547ms/step - loss: 0.3494 - accuracy: 0.8452 - lr: 9.0000e-05\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 16s 552ms/step - loss: 0.3440 - accuracy: 0.8501 - lr: 9.0000e-05\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 16s 543ms/step - loss: 0.3454 - accuracy: 0.8448 - lr: 9.0000e-05\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.3475 - accuracy: 0.8487 - lr: 9.0000e-05\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.3399 - accuracy: 0.8494 - lr: 9.0000e-05\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 16s 542ms/step - loss: 0.3421 - accuracy: 0.8546 - lr: 9.0000e-05\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 16s 550ms/step - loss: 0.3418 - accuracy: 0.8480 - lr: 9.0000e-05\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 16s 547ms/step - loss: 0.3281 - accuracy: 0.8574 - lr: 9.0000e-05\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.3234 - accuracy: 0.8619 - lr: 9.0000e-05\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 16s 546ms/step - loss: 0.3294 - accuracy: 0.8567 - lr: 9.0000e-05\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 16s 551ms/step - loss: 0.3313 - accuracy: 0.8567 - lr: 9.0000e-05\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 16s 549ms/step - loss: 0.3284 - accuracy: 0.8588 - lr: 9.0000e-05\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.3217 - accuracy: 0.8658 - lr: 9.0000e-05\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 16s 544ms/step - loss: 0.3229 - accuracy: 0.8626 - lr: 9.0000e-05\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 16s 546ms/step - loss: 0.3276 - accuracy: 0.8581 - lr: 9.0000e-05\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 16s 546ms/step - loss: 0.3134 - accuracy: 0.8647 - lr: 9.0000e-05\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 16s 543ms/step - loss: 0.3125 - accuracy: 0.8644 - lr: 9.0000e-05\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.3087 - accuracy: 0.8658 - lr: 9.0000e-05\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 16s 546ms/step - loss: 0.3082 - accuracy: 0.8696 - lr: 9.0000e-05\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 16s 547ms/step - loss: 0.3094 - accuracy: 0.8616 - lr: 9.0000e-05\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 16s 549ms/step - loss: 0.3140 - accuracy: 0.8637 - lr: 9.0000e-05\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.3082 - accuracy: 0.8633 - lr: 9.0000e-05\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.3059 - accuracy: 0.8640 - lr: 9.0000e-05\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 16s 549ms/step - loss: 0.3022 - accuracy: 0.8699 - lr: 9.0000e-05\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 16s 548ms/step - loss: 0.3012 - accuracy: 0.8720 - lr: 9.0000e-05\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.2988 - accuracy: 0.8724 - lr: 9.0000e-05\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 16s 546ms/step - loss: 0.2994 - accuracy: 0.8713 - lr: 9.0000e-05\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 16s 548ms/step - loss: 0.2933 - accuracy: 0.8745 - lr: 9.0000e-05\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 16s 547ms/step - loss: 0.3012 - accuracy: 0.8752 - lr: 9.0000e-05\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 16s 544ms/step - loss: 0.3127 - accuracy: 0.8640 - lr: 9.0000e-05\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 16s 550ms/step - loss: 0.2990 - accuracy: 0.8710 - lr: 9.0000e-05\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 16s 546ms/step - loss: 0.2957 - accuracy: 0.8741 - lr: 9.0000e-05\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.2989 - accuracy: 0.8706 - lr: 9.0000e-05\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 16s 543ms/step - loss: 0.2945 - accuracy: 0.8668 - lr: 9.0000e-05\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.2847 - accuracy: 0.8849 - lr: 9.0000e-05\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.2878 - accuracy: 0.8794 - lr: 9.0000e-05\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 16s 549ms/step - loss: 0.2957 - accuracy: 0.8727 - lr: 9.0000e-05\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 16s 546ms/step - loss: 0.2895 - accuracy: 0.8766 - lr: 9.0000e-05\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 16s 543ms/step - loss: 0.2868 - accuracy: 0.8797 - lr: 9.0000e-05\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 16s 544ms/step - loss: 0.2822 - accuracy: 0.8828 - lr: 9.0000e-05\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 16s 542ms/step - loss: 0.2866 - accuracy: 0.8804 - lr: 9.0000e-05\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 16s 546ms/step - loss: 0.2832 - accuracy: 0.8783 - lr: 9.0000e-05\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.2838 - accuracy: 0.8839 - lr: 9.0000e-05\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 16s 546ms/step - loss: 0.2833 - accuracy: 0.8821 - lr: 9.0000e-05\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 16s 548ms/step - loss: 0.2855 - accuracy: 0.8780 - lr: 9.0000e-05\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 16s 548ms/step - loss: 0.2808 - accuracy: 0.8783 - lr: 9.0000e-05\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 16s 547ms/step - loss: 0.2836 - accuracy: 0.8797 - lr: 9.0000e-05\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.2837 - accuracy: 0.8706 - lr: 9.0000e-05\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.2886 - accuracy: 0.8745 - lr: 9.0000e-05\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 16s 546ms/step - loss: 0.2808 - accuracy: 0.8815 - lr: 9.0000e-05\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.2826 - accuracy: 0.8797 - lr: 9.0000e-05\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 16s 541ms/step - loss: 0.2819 - accuracy: 0.8780 - lr: 9.0000e-05\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 16s 543ms/step - loss: 0.2840 - accuracy: 0.8794 - lr: 9.0000e-05\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.2780 - accuracy: 0.8842 - lr: 9.0000e-05\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 16s 544ms/step - loss: 0.2750 - accuracy: 0.8863 - lr: 9.0000e-05\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 16s 543ms/step - loss: 0.2811 - accuracy: 0.8769 - lr: 9.0000e-05\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 16s 547ms/step - loss: 0.2739 - accuracy: 0.8860 - lr: 9.0000e-05\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 16s 543ms/step - loss: 0.2799 - accuracy: 0.8815 - lr: 9.0000e-05\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 16s 546ms/step - loss: 0.2777 - accuracy: 0.8801 - lr: 9.0000e-05\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 16s 544ms/step - loss: 0.2790 - accuracy: 0.8821 - lr: 9.0000e-05\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 16s 546ms/step - loss: 0.2740 - accuracy: 0.8804 - lr: 9.0000e-05\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 16s 544ms/step - loss: 0.2716 - accuracy: 0.8881 - lr: 9.0000e-05\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 16s 547ms/step - loss: 0.2696 - accuracy: 0.8828 - lr: 9.0000e-05\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 16s 544ms/step - loss: 0.2742 - accuracy: 0.8818 - lr: 9.0000e-05\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 16s 546ms/step - loss: 0.2692 - accuracy: 0.8839 - lr: 9.0000e-05\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 16s 548ms/step - loss: 0.2668 - accuracy: 0.8856 - lr: 9.0000e-05\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 16s 550ms/step - loss: 0.2607 - accuracy: 0.8888 - lr: 9.0000e-05\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 16s 543ms/step - loss: 0.2689 - accuracy: 0.8860 - lr: 9.0000e-05\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 16s 544ms/step - loss: 0.2609 - accuracy: 0.8944 - lr: 9.0000e-05\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.2695 - accuracy: 0.8853 - lr: 9.0000e-05\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 16s 543ms/step - loss: 0.2617 - accuracy: 0.8895 - lr: 9.0000e-05\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.2708 - accuracy: 0.8877 - lr: 9.0000e-05\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 16s 542ms/step - loss: 0.2664 - accuracy: 0.8909 - lr: 9.0000e-05\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 16s 542ms/step - loss: 0.2666 - accuracy: 0.8884 - lr: 9.0000e-05\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.2726 - accuracy: 0.8839 - lr: 9.0000e-05\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 16s 543ms/step - loss: 0.2698 - accuracy: 0.8818 - lr: 9.0000e-05\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 16s 546ms/step - loss: 0.2622 - accuracy: 0.8891 - lr: 9.0000e-05\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 16s 542ms/step - loss: 0.2648 - accuracy: 0.8860 - lr: 9.0000e-05\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 16s 546ms/step - loss: 0.2570 - accuracy: 0.8954 - lr: 9.0000e-05\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.2613 - accuracy: 0.8940 - lr: 9.0000e-05\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 16s 537ms/step - loss: 0.2579 - accuracy: 0.8863 - lr: 9.0000e-05\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 16s 546ms/step - loss: 0.2723 - accuracy: 0.8881 - lr: 9.0000e-05\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.2689 - accuracy: 0.8891 - lr: 9.0000e-05\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.2635 - accuracy: 0.8849 - lr: 9.0000e-05\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.2551 - accuracy: 0.8895 - lr: 9.0000e-05\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 16s 545ms/step - loss: 0.2654 - accuracy: 0.8860 - lr: 9.0000e-05\n",
      "22/22 [==============================] - 2s 77ms/step - loss: 0.2487 - accuracy: 0.9097 - lr: 9.0000e-05\n",
      "22/22 [==============================] - 2s 78ms/step\n",
      "22/22 [==============================] - 2s 77ms/step\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 17s 531ms/step - loss: 0.5561 - accuracy: 0.7022 - lr: 9.0000e-05\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 16s 540ms/step - loss: 0.5039 - accuracy: 0.7517 - lr: 9.0000e-05\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 16s 539ms/step - loss: 0.4823 - accuracy: 0.7678 - lr: 9.0000e-05\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 16s 538ms/step - loss: 0.4669 - accuracy: 0.7782 - lr: 9.0000e-05\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 15s 533ms/step - loss: 0.4599 - accuracy: 0.7873 - lr: 9.0000e-05\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 15s 533ms/step - loss: 0.4524 - accuracy: 0.7856 - lr: 9.0000e-05\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 16s 537ms/step - loss: 0.4419 - accuracy: 0.7932 - lr: 9.0000e-05\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 15s 534ms/step - loss: 0.4397 - accuracy: 0.7870 - lr: 9.0000e-05\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 15s 534ms/step - loss: 0.4373 - accuracy: 0.7884 - lr: 9.0000e-05\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 15s 534ms/step - loss: 0.4314 - accuracy: 0.7999 - lr: 9.0000e-05\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 16s 535ms/step - loss: 0.4275 - accuracy: 0.7981 - lr: 9.0000e-05\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 16s 536ms/step - loss: 0.4173 - accuracy: 0.8068 - lr: 9.0000e-05\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 15s 533ms/step - loss: 0.4126 - accuracy: 0.8061 - lr: 9.0000e-05\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 16s 536ms/step - loss: 0.4056 - accuracy: 0.8079 - lr: 9.0000e-05\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 16s 535ms/step - loss: 0.4022 - accuracy: 0.8086 - lr: 9.0000e-05\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 16s 537ms/step - loss: 0.3971 - accuracy: 0.8173 - lr: 9.0000e-05\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 16s 536ms/step - loss: 0.3859 - accuracy: 0.8194 - lr: 9.0000e-05\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 15s 530ms/step - loss: 0.3820 - accuracy: 0.8250 - lr: 9.0000e-05\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 16s 536ms/step - loss: 0.3755 - accuracy: 0.8326 - lr: 9.0000e-05\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 15s 532ms/step - loss: 0.3722 - accuracy: 0.8305 - lr: 9.0000e-05\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 16s 536ms/step - loss: 0.3693 - accuracy: 0.8354 - lr: 9.0000e-05\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 16s 539ms/step - loss: 0.3680 - accuracy: 0.8305 - lr: 9.0000e-05\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 16s 538ms/step - loss: 0.3574 - accuracy: 0.8323 - lr: 9.0000e-05\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 16s 537ms/step - loss: 0.3584 - accuracy: 0.8421 - lr: 9.0000e-05\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 16s 538ms/step - loss: 0.3535 - accuracy: 0.8455 - lr: 9.0000e-05\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 16s 535ms/step - loss: 0.3497 - accuracy: 0.8448 - lr: 9.0000e-05\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 16s 547ms/step - loss: 0.3419 - accuracy: 0.8483 - lr: 9.0000e-05\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 16s 539ms/step - loss: 0.3418 - accuracy: 0.8529 - lr: 9.0000e-05\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 16s 538ms/step - loss: 0.3344 - accuracy: 0.8553 - lr: 9.0000e-05\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 15s 533ms/step - loss: 0.3312 - accuracy: 0.8550 - lr: 9.0000e-05\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 15s 533ms/step - loss: 0.3311 - accuracy: 0.8515 - lr: 9.0000e-05\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 16s 539ms/step - loss: 0.3317 - accuracy: 0.8529 - lr: 9.0000e-05\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 16s 538ms/step - loss: 0.3383 - accuracy: 0.8494 - lr: 9.0000e-05\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 16s 536ms/step - loss: 0.3309 - accuracy: 0.8550 - lr: 9.0000e-05\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 16s 539ms/step - loss: 0.3305 - accuracy: 0.8550 - lr: 9.0000e-05\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 16s 540ms/step - loss: 0.3202 - accuracy: 0.8605 - lr: 9.0000e-05\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 16s 535ms/step - loss: 0.3246 - accuracy: 0.8588 - lr: 9.0000e-05\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 16s 535ms/step - loss: 0.3252 - accuracy: 0.8574 - lr: 9.0000e-05\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 16s 542ms/step - loss: 0.3203 - accuracy: 0.8623 - lr: 9.0000e-05\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 16s 537ms/step - loss: 0.3228 - accuracy: 0.8560 - lr: 9.0000e-05\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 16s 537ms/step - loss: 0.3124 - accuracy: 0.8696 - lr: 9.0000e-05\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 16s 536ms/step - loss: 0.3132 - accuracy: 0.8672 - lr: 9.0000e-05\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 16s 536ms/step - loss: 0.3110 - accuracy: 0.8675 - lr: 9.0000e-05\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 16s 537ms/step - loss: 0.3147 - accuracy: 0.8654 - lr: 9.0000e-05\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 15s 532ms/step - loss: 0.3239 - accuracy: 0.8591 - lr: 9.0000e-05\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 16s 538ms/step - loss: 0.3066 - accuracy: 0.8759 - lr: 9.0000e-05\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 16s 537ms/step - loss: 0.3038 - accuracy: 0.8703 - lr: 9.0000e-05\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 16s 540ms/step - loss: 0.3074 - accuracy: 0.8640 - lr: 9.0000e-05\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 15s 534ms/step - loss: 0.3011 - accuracy: 0.8727 - lr: 9.0000e-05\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 16s 534ms/step - loss: 0.3075 - accuracy: 0.8661 - lr: 9.0000e-05\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 16s 539ms/step - loss: 0.3065 - accuracy: 0.8668 - lr: 9.0000e-05\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 16s 541ms/step - loss: 0.3000 - accuracy: 0.8699 - lr: 9.0000e-05\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 16s 537ms/step - loss: 0.3029 - accuracy: 0.8679 - lr: 9.0000e-05\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 16s 537ms/step - loss: 0.3033 - accuracy: 0.8682 - lr: 9.0000e-05\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 16s 534ms/step - loss: 0.3074 - accuracy: 0.8654 - lr: 9.0000e-05\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 16s 539ms/step - loss: 0.2958 - accuracy: 0.8766 - lr: 9.0000e-05\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 16s 533ms/step - loss: 0.2942 - accuracy: 0.8755 - lr: 9.0000e-05\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 16s 535ms/step - loss: 0.2943 - accuracy: 0.8717 - lr: 9.0000e-05\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 16s 539ms/step - loss: 0.2871 - accuracy: 0.8748 - lr: 9.0000e-05\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 16s 538ms/step - loss: 0.2936 - accuracy: 0.8790 - lr: 9.0000e-05\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 16s 536ms/step - loss: 0.2877 - accuracy: 0.8801 - lr: 9.0000e-05\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 15s 533ms/step - loss: 0.2988 - accuracy: 0.8703 - lr: 9.0000e-05\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 16s 538ms/step - loss: 0.2890 - accuracy: 0.8755 - lr: 9.0000e-05\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 16s 542ms/step - loss: 0.2856 - accuracy: 0.8821 - lr: 9.0000e-05\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 16s 535ms/step - loss: 0.2864 - accuracy: 0.8811 - lr: 9.0000e-05\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 16s 537ms/step - loss: 0.2843 - accuracy: 0.8790 - lr: 9.0000e-05\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 16s 539ms/step - loss: 0.2782 - accuracy: 0.8863 - lr: 9.0000e-05\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 15s 534ms/step - loss: 0.2855 - accuracy: 0.8787 - lr: 9.0000e-05\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 16s 539ms/step - loss: 0.2910 - accuracy: 0.8815 - lr: 9.0000e-05\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 16s 536ms/step - loss: 0.2748 - accuracy: 0.8828 - lr: 9.0000e-05\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 16s 536ms/step - loss: 0.2764 - accuracy: 0.8867 - lr: 9.0000e-05\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 16s 534ms/step - loss: 0.2825 - accuracy: 0.8877 - lr: 9.0000e-05\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 16s 538ms/step - loss: 0.2920 - accuracy: 0.8720 - lr: 9.0000e-05\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 16s 535ms/step - loss: 0.2705 - accuracy: 0.8888 - lr: 9.0000e-05\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 16s 535ms/step - loss: 0.2753 - accuracy: 0.8839 - lr: 9.0000e-05\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 16s 541ms/step - loss: 0.2762 - accuracy: 0.8881 - lr: 9.0000e-05\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 16s 536ms/step - loss: 0.2766 - accuracy: 0.8839 - lr: 9.0000e-05\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 16s 535ms/step - loss: 0.2812 - accuracy: 0.8804 - lr: 9.0000e-05\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 16s 537ms/step - loss: 0.2703 - accuracy: 0.8905 - lr: 9.0000e-05\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 16s 538ms/step - loss: 0.2790 - accuracy: 0.8860 - lr: 9.0000e-05\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 16s 536ms/step - loss: 0.2689 - accuracy: 0.8881 - lr: 9.0000e-05\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 16s 536ms/step - loss: 0.2661 - accuracy: 0.8895 - lr: 9.0000e-05\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 16s 543ms/step - loss: 0.2652 - accuracy: 0.8905 - lr: 9.0000e-05\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 16s 539ms/step - loss: 0.2684 - accuracy: 0.8933 - lr: 9.0000e-05\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 15s 534ms/step - loss: 0.2748 - accuracy: 0.8811 - lr: 9.0000e-05\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 15s 533ms/step - loss: 0.2718 - accuracy: 0.8888 - lr: 9.0000e-05\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 16s 538ms/step - loss: 0.2721 - accuracy: 0.8832 - lr: 9.0000e-05\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 16s 536ms/step - loss: 0.2729 - accuracy: 0.8821 - lr: 9.0000e-05\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 16s 538ms/step - loss: 0.2615 - accuracy: 0.8912 - lr: 9.0000e-05\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 16s 537ms/step - loss: 0.2644 - accuracy: 0.8888 - lr: 9.0000e-05\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 16s 539ms/step - loss: 0.2690 - accuracy: 0.8853 - lr: 9.0000e-05\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 15s 532ms/step - loss: 0.2647 - accuracy: 0.8916 - lr: 9.0000e-05\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 15s 532ms/step - loss: 0.2614 - accuracy: 0.8863 - lr: 9.0000e-05\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 15s 530ms/step - loss: 0.2669 - accuracy: 0.8916 - lr: 9.0000e-05\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 16s 534ms/step - loss: 0.2603 - accuracy: 0.8912 - lr: 9.0000e-05\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 16s 536ms/step - loss: 0.2626 - accuracy: 0.8863 - lr: 9.0000e-05\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 16s 537ms/step - loss: 0.2601 - accuracy: 0.8978 - lr: 9.0000e-05\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 16s 538ms/step - loss: 0.2568 - accuracy: 0.8888 - lr: 9.0000e-05\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 16s 537ms/step - loss: 0.2652 - accuracy: 0.8881 - lr: 9.0000e-05\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 16s 539ms/step - loss: 0.2627 - accuracy: 0.8891 - lr: 9.0000e-05\n",
      "22/22 [==============================] - 2s 77ms/step - loss: 0.3153 - accuracy: 0.8639 - lr: 9.0000e-05\n",
      "22/22 [==============================] - 2s 78ms/step\n",
      "22/22 [==============================] - 2s 77ms/step\n",
      "Epoch 1/100\n",
      "29/29 [==============================] - 16s 514ms/step - loss: 0.5595 - accuracy: 0.6904 - lr: 9.0000e-05\n",
      "Epoch 2/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.5054 - accuracy: 0.7503 - lr: 9.0000e-05\n",
      "Epoch 3/100\n",
      "29/29 [==============================] - 15s 517ms/step - loss: 0.4803 - accuracy: 0.7737 - lr: 9.0000e-05\n",
      "Epoch 4/100\n",
      "29/29 [==============================] - 15s 513ms/step - loss: 0.4632 - accuracy: 0.7807 - lr: 9.0000e-05\n",
      "Epoch 5/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.4559 - accuracy: 0.7877 - lr: 9.0000e-05\n",
      "Epoch 6/100\n",
      "29/29 [==============================] - 15s 517ms/step - loss: 0.4452 - accuracy: 0.7929 - lr: 9.0000e-05\n",
      "Epoch 7/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.4328 - accuracy: 0.8016 - lr: 9.0000e-05\n",
      "Epoch 8/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.4244 - accuracy: 0.8033 - lr: 9.0000e-05\n",
      "Epoch 9/100\n",
      "29/29 [==============================] - 15s 521ms/step - loss: 0.4108 - accuracy: 0.8156 - lr: 9.0000e-05\n",
      "Epoch 10/100\n",
      "29/29 [==============================] - 15s 521ms/step - loss: 0.3988 - accuracy: 0.8169 - lr: 9.0000e-05\n",
      "Epoch 11/100\n",
      "29/29 [==============================] - 15s 518ms/step - loss: 0.3879 - accuracy: 0.8243 - lr: 9.0000e-05\n",
      "Epoch 12/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.3876 - accuracy: 0.8197 - lr: 9.0000e-05\n",
      "Epoch 13/100\n",
      "29/29 [==============================] - 15s 518ms/step - loss: 0.3781 - accuracy: 0.8291 - lr: 9.0000e-05\n",
      "Epoch 14/100\n",
      "29/29 [==============================] - 15s 518ms/step - loss: 0.3752 - accuracy: 0.8288 - lr: 9.0000e-05\n",
      "Epoch 15/100\n",
      "29/29 [==============================] - 15s 521ms/step - loss: 0.3794 - accuracy: 0.8278 - lr: 9.0000e-05\n",
      "Epoch 16/100\n",
      "29/29 [==============================] - 15s 523ms/step - loss: 0.3656 - accuracy: 0.8361 - lr: 9.0000e-05\n",
      "Epoch 17/100\n",
      "29/29 [==============================] - 15s 516ms/step - loss: 0.3592 - accuracy: 0.8389 - lr: 9.0000e-05\n",
      "Epoch 18/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.3639 - accuracy: 0.8375 - lr: 9.0000e-05\n",
      "Epoch 19/100\n",
      "29/29 [==============================] - 15s 522ms/step - loss: 0.3494 - accuracy: 0.8438 - lr: 9.0000e-05\n",
      "Epoch 20/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.3485 - accuracy: 0.8431 - lr: 9.0000e-05\n",
      "Epoch 21/100\n",
      "29/29 [==============================] - 15s 518ms/step - loss: 0.3524 - accuracy: 0.8459 - lr: 9.0000e-05\n",
      "Epoch 22/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.3501 - accuracy: 0.8445 - lr: 9.0000e-05\n",
      "Epoch 23/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.3522 - accuracy: 0.8434 - lr: 9.0000e-05\n",
      "Epoch 24/100\n",
      "29/29 [==============================] - 15s 517ms/step - loss: 0.3480 - accuracy: 0.8434 - lr: 9.0000e-05\n",
      "Epoch 25/100\n",
      "29/29 [==============================] - 15s 518ms/step - loss: 0.3341 - accuracy: 0.8518 - lr: 9.0000e-05\n",
      "Epoch 26/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.3342 - accuracy: 0.8536 - lr: 9.0000e-05\n",
      "Epoch 27/100\n",
      "29/29 [==============================] - 15s 517ms/step - loss: 0.3372 - accuracy: 0.8539 - lr: 9.0000e-05\n",
      "Epoch 28/100\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.3360 - accuracy: 0.8560 - lr: 9.0000e-05\n",
      "Epoch 29/100\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.3317 - accuracy: 0.8532 - lr: 9.0000e-05\n",
      "Epoch 30/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.3266 - accuracy: 0.8546 - lr: 9.0000e-05\n",
      "Epoch 31/100\n",
      "29/29 [==============================] - 15s 522ms/step - loss: 0.3219 - accuracy: 0.8570 - lr: 9.0000e-05\n",
      "Epoch 32/100\n",
      "29/29 [==============================] - 15s 517ms/step - loss: 0.3246 - accuracy: 0.8584 - lr: 9.0000e-05\n",
      "Epoch 33/100\n",
      "29/29 [==============================] - 15s 517ms/step - loss: 0.3201 - accuracy: 0.8633 - lr: 9.0000e-05\n",
      "Epoch 34/100\n",
      "29/29 [==============================] - 15s 522ms/step - loss: 0.3235 - accuracy: 0.8612 - lr: 9.0000e-05\n",
      "Epoch 35/100\n",
      "29/29 [==============================] - 15s 523ms/step - loss: 0.3251 - accuracy: 0.8640 - lr: 9.0000e-05\n",
      "Epoch 36/100\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.3135 - accuracy: 0.8661 - lr: 9.0000e-05\n",
      "Epoch 37/100\n",
      "29/29 [==============================] - 15s 518ms/step - loss: 0.3153 - accuracy: 0.8633 - lr: 9.0000e-05\n",
      "Epoch 38/100\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.3112 - accuracy: 0.8665 - lr: 9.0000e-05\n",
      "Epoch 39/100\n",
      "29/29 [==============================] - 15s 516ms/step - loss: 0.3186 - accuracy: 0.8633 - lr: 9.0000e-05\n",
      "Epoch 40/100\n",
      "29/29 [==============================] - 15s 521ms/step - loss: 0.3185 - accuracy: 0.8616 - lr: 9.0000e-05\n",
      "Epoch 41/100\n",
      "29/29 [==============================] - 15s 531ms/step - loss: 0.3168 - accuracy: 0.8577 - lr: 9.0000e-05\n",
      "Epoch 42/100\n",
      "29/29 [==============================] - 18s 631ms/step - loss: 0.3133 - accuracy: 0.8665 - lr: 9.0000e-05\n",
      "Epoch 43/100\n",
      "29/29 [==============================] - 16s 537ms/step - loss: 0.3081 - accuracy: 0.8661 - lr: 9.0000e-05\n",
      "Epoch 44/100\n",
      "29/29 [==============================] - 15s 522ms/step - loss: 0.3112 - accuracy: 0.8699 - lr: 9.0000e-05\n",
      "Epoch 45/100\n",
      "29/29 [==============================] - 15s 524ms/step - loss: 0.3150 - accuracy: 0.8644 - lr: 9.0000e-05\n",
      "Epoch 46/100\n",
      "29/29 [==============================] - 15s 524ms/step - loss: 0.3149 - accuracy: 0.8626 - lr: 9.0000e-05\n",
      "Epoch 47/100\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.3110 - accuracy: 0.8647 - lr: 9.0000e-05\n",
      "Epoch 48/100\n",
      "29/29 [==============================] - 15s 518ms/step - loss: 0.3158 - accuracy: 0.8647 - lr: 9.0000e-05\n",
      "Epoch 49/100\n",
      "29/29 [==============================] - 15s 526ms/step - loss: 0.3061 - accuracy: 0.8717 - lr: 9.0000e-05\n",
      "Epoch 50/100\n",
      "29/29 [==============================] - 15s 521ms/step - loss: 0.3037 - accuracy: 0.8727 - lr: 9.0000e-05\n",
      "Epoch 51/100\n",
      "29/29 [==============================] - 15s 522ms/step - loss: 0.3050 - accuracy: 0.8699 - lr: 9.0000e-05\n",
      "Epoch 52/100\n",
      "29/29 [==============================] - 15s 521ms/step - loss: 0.3039 - accuracy: 0.8713 - lr: 9.0000e-05\n",
      "Epoch 53/100\n",
      "29/29 [==============================] - 15s 523ms/step - loss: 0.3053 - accuracy: 0.8706 - lr: 9.0000e-05\n",
      "Epoch 54/100\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.3045 - accuracy: 0.8668 - lr: 9.0000e-05\n",
      "Epoch 55/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.3021 - accuracy: 0.8734 - lr: 9.0000e-05\n",
      "Epoch 56/100\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.3051 - accuracy: 0.8727 - lr: 9.0000e-05\n",
      "Epoch 57/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.3008 - accuracy: 0.8752 - lr: 9.0000e-05\n",
      "Epoch 58/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.3003 - accuracy: 0.8731 - lr: 9.0000e-05\n",
      "Epoch 59/100\n",
      "29/29 [==============================] - 15s 516ms/step - loss: 0.3016 - accuracy: 0.8748 - lr: 9.0000e-05\n",
      "Epoch 60/100\n",
      "29/29 [==============================] - 15s 518ms/step - loss: 0.3012 - accuracy: 0.8734 - lr: 9.0000e-05\n",
      "Epoch 61/100\n",
      "29/29 [==============================] - 15s 515ms/step - loss: 0.3013 - accuracy: 0.8703 - lr: 9.0000e-05\n",
      "Epoch 62/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.2973 - accuracy: 0.8734 - lr: 9.0000e-05\n",
      "Epoch 63/100\n",
      "29/29 [==============================] - 15s 518ms/step - loss: 0.3006 - accuracy: 0.8734 - lr: 9.0000e-05\n",
      "Epoch 64/100\n",
      "29/29 [==============================] - 15s 516ms/step - loss: 0.2963 - accuracy: 0.8741 - lr: 9.0000e-05\n",
      "Epoch 65/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.3012 - accuracy: 0.8755 - lr: 9.0000e-05\n",
      "Epoch 66/100\n",
      "29/29 [==============================] - 15s 513ms/step - loss: 0.3144 - accuracy: 0.8654 - lr: 9.0000e-05\n",
      "Epoch 67/100\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.2996 - accuracy: 0.8759 - lr: 9.0000e-05\n",
      "Epoch 68/100\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.2927 - accuracy: 0.8815 - lr: 9.0000e-05\n",
      "Epoch 69/100\n",
      "29/29 [==============================] - 15s 522ms/step - loss: 0.2962 - accuracy: 0.8776 - lr: 9.0000e-05\n",
      "Epoch 70/100\n",
      "29/29 [==============================] - 15s 523ms/step - loss: 0.2960 - accuracy: 0.8741 - lr: 9.0000e-05\n",
      "Epoch 71/100\n",
      "29/29 [==============================] - 15s 521ms/step - loss: 0.2970 - accuracy: 0.8797 - lr: 9.0000e-05\n",
      "Epoch 72/100\n",
      "29/29 [==============================] - 15s 524ms/step - loss: 0.2888 - accuracy: 0.8797 - lr: 9.0000e-05\n",
      "Epoch 73/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.2946 - accuracy: 0.8776 - lr: 9.0000e-05\n",
      "Epoch 74/100\n",
      "29/29 [==============================] - 15s 515ms/step - loss: 0.2901 - accuracy: 0.8783 - lr: 9.0000e-05\n",
      "Epoch 75/100\n",
      "29/29 [==============================] - 15s 522ms/step - loss: 0.3009 - accuracy: 0.8727 - lr: 9.0000e-05\n",
      "Epoch 76/100\n",
      "29/29 [==============================] - 15s 522ms/step - loss: 0.2980 - accuracy: 0.8762 - lr: 9.0000e-05\n",
      "Epoch 77/100\n",
      "29/29 [==============================] - 15s 521ms/step - loss: 0.2900 - accuracy: 0.8846 - lr: 9.0000e-05\n",
      "Epoch 78/100\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.2915 - accuracy: 0.8818 - lr: 9.0000e-05\n",
      "Epoch 79/100\n",
      "29/29 [==============================] - 15s 518ms/step - loss: 0.2901 - accuracy: 0.8804 - lr: 9.0000e-05\n",
      "Epoch 80/100\n",
      "29/29 [==============================] - 15s 515ms/step - loss: 0.2934 - accuracy: 0.8790 - lr: 9.0000e-05\n",
      "Epoch 81/100\n",
      "29/29 [==============================] - 15s 517ms/step - loss: 0.3018 - accuracy: 0.8755 - lr: 9.0000e-05\n",
      "Epoch 82/100\n",
      "29/29 [==============================] - 15s 522ms/step - loss: 0.2919 - accuracy: 0.8821 - lr: 9.0000e-05\n",
      "Epoch 83/100\n",
      "29/29 [==============================] - 15s 522ms/step - loss: 0.2906 - accuracy: 0.8710 - lr: 9.0000e-05\n",
      "Epoch 84/100\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.2922 - accuracy: 0.8773 - lr: 9.0000e-05\n",
      "Epoch 85/100\n",
      "29/29 [==============================] - 15s 517ms/step - loss: 0.2841 - accuracy: 0.8804 - lr: 9.0000e-05\n",
      "Epoch 86/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.2968 - accuracy: 0.8787 - lr: 9.0000e-05\n",
      "Epoch 87/100\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.2888 - accuracy: 0.8821 - lr: 9.0000e-05\n",
      "Epoch 88/100\n",
      "29/29 [==============================] - 15s 521ms/step - loss: 0.2870 - accuracy: 0.8790 - lr: 9.0000e-05\n",
      "Epoch 89/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.2859 - accuracy: 0.8776 - lr: 9.0000e-05\n",
      "Epoch 90/100\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.2826 - accuracy: 0.8804 - lr: 9.0000e-05\n",
      "Epoch 91/100\n",
      "29/29 [==============================] - 15s 520ms/step - loss: 0.2979 - accuracy: 0.8748 - lr: 9.0000e-05\n",
      "Epoch 92/100\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.2973 - accuracy: 0.8724 - lr: 9.0000e-05\n",
      "Epoch 93/100\n",
      "29/29 [==============================] - 15s 524ms/step - loss: 0.2905 - accuracy: 0.8787 - lr: 9.0000e-05\n",
      "Epoch 94/100\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.2827 - accuracy: 0.8863 - lr: 9.0000e-05\n",
      "Epoch 95/100\n",
      "29/29 [==============================] - 15s 518ms/step - loss: 0.2866 - accuracy: 0.8808 - lr: 9.0000e-05\n",
      "Epoch 96/100\n",
      "29/29 [==============================] - 15s 515ms/step - loss: 0.2866 - accuracy: 0.8801 - lr: 9.0000e-05\n",
      "Epoch 97/100\n",
      "29/29 [==============================] - 15s 519ms/step - loss: 0.2837 - accuracy: 0.8860 - lr: 9.0000e-05\n",
      "Epoch 98/100\n",
      "29/29 [==============================] - 15s 526ms/step - loss: 0.2825 - accuracy: 0.8853 - lr: 9.0000e-05\n",
      "Epoch 99/100\n",
      "29/29 [==============================] - 15s 517ms/step - loss: 0.2830 - accuracy: 0.8853 - lr: 9.0000e-05\n",
      "Epoch 100/100\n",
      "29/29 [==============================] - 15s 532ms/step - loss: 0.2890 - accuracy: 0.8856 - lr: 9.0000e-05\n",
      "22/22 [==============================] - 2s 73ms/step - loss: 0.4225 - accuracy: 0.7994 - lr: 9.0000e-05\n",
      "22/22 [==============================] - 2s 73ms/step\n",
      "22/22 [==============================] - 2s 76ms/step\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "tprs=[]\n",
    "mean_fpr=np.linspace(0,1,100)\n",
    "auck=[0,0,0,0,0]\n",
    "Recalls=[]\n",
    "F1score=[]\n",
    "specificity=[]\n",
    "accuracys = []\n",
    "for i in range(5):\n",
    "    if i==0:\n",
    "        x_train, y_train = x_train0,y_train0\n",
    "        x_test, y_test = x_test0,y_test0\n",
    "        model.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model.predict(x_test))\n",
    "        y_pred=model.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    elif i ==1:\n",
    "        x_train, y_train = x_train1,y_train1\n",
    "        x_test, y_test = x_test1,y_test1\n",
    "        model2.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model2.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model2.predict(x_test))\n",
    "        y_pred=model2.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    elif i ==2:\n",
    "        x_train, y_train = x_train2,y_train2\n",
    "        x_test, y_test = x_test2,y_test2\n",
    "        model3.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model3.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model3.predict(x_test))\n",
    "        y_pred=model3.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    elif i ==3:\n",
    "        x_train, y_train = x_train3,y_train3\n",
    "        x_test, y_test = x_test3,y_test3\n",
    "        model4.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model4.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model4.predict(x_test))\n",
    "        y_pred=model4.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    else:\n",
    "        x_train, y_train = x_train4,y_train4\n",
    "        x_test, y_test = x_test4,y_test4\n",
    "        model5.fit(x_train, y_train,batch_size=100,epochs=100)\n",
    "        score = model5.evaluate(x_test, y_test)[1]\n",
    "        scores.append(score)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test,model5.predict(x_test))\n",
    "        y_pred=model5.predict(x_test)\n",
    "        y_pred = (y_pred >= 0.5)*1  \n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        specificity.append(tn / (tn + fp))\n",
    "        accuracys.append(accuracy_score(y_test, y_pred))\n",
    "        Recalls.append(metrics.recall_score(y_test, y_pred))\n",
    "        F1score.append(metrics.f1_score(y_test, y_pred))\n",
    "    auck[i] = auc(fpr, tpr)\n",
    "    tprs.append(interp(mean_fpr,fpr,tpr))\n",
    "    tprs[-1][0]=0.0\n",
    "scores=np.array(scores)\n",
    "interval = stats.t.interval(0.95, scores.shape[0] - 1, scores.mean(), scores.std() / np.sqrt(scores.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fc5b3882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence interval：(0.8241707661606713, 0.9276916882536964)\n",
      "scores: 0.8759312272071839\n",
      "AUC: 0.9555076084487849\n"
     ]
    }
   ],
   "source": [
    "print(\"confidence interval：{}\".format(interval))\n",
    "print('scores:',np.mean(scores))\n",
    "print('AUC:',np.mean(auck))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "53c4f776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recalls: 0.8756302521008404\n",
      "F1score: 0.9035852680151066\n"
     ]
    }
   ],
   "source": [
    "print('Recalls:',np.mean(Recalls))\n",
    "print('F1score:',np.mean(F1score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5af3fee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9484112030321145, 0.9626040138654554)\n"
     ]
    }
   ],
   "source": [
    "conf = sms.DescrStatsW(auck).tconfint_mean(0.05)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b671583a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1abfcd9fe20>]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.grid(alpha=0.4)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.set_aspect(1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.plot([0,1],[0,1],linestyle='--',lw=2,color='r',alpha=0.1)\n",
    "plt.xlabel('False Positive Rate', fontsize=13)\n",
    "plt.ylabel('True Positive Rate', fontsize=13)\n",
    "mean_tpr=np.mean(tprs,axis=0)\n",
    "mean_tpr[-1]=1.0\n",
    "std_auc=np.std(tprs,axis=0)\n",
    "plt.plot(mean_fpr,mean_tpr,color='b',label = u'AUC=%.3f' % (sum(auck)/5),lw=2,alpha=0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 | packaged by Anaconda, Inc. | (main, Mar  8 2023, 10:42:25) [MSC v.1916 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "3c06e3e46abf38078fe4dac36a0085ec2b134ebbd73dd076183d243eeca6918f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
